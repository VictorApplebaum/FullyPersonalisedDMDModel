{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "above-scout",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Build a basic version of our model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1976b6df-23df-4cc5-95fc-cdcfe31c5328",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amber-effort",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(caret)\n",
    "library(dplyr) #install.packages(\"tidyverse\")\n",
    "library(tidyr) \n",
    "library(ggplot2)\n",
    "library(purrr)  \n",
    "library(zoo) #install.packages(\"zoo\")\n",
    "library(parallel)\n",
    "library(nimble) #install.packages(\"nimble\")\n",
    "library(abind) #install.packages(\"abind\")\n",
    "library(coda)\n",
    "#library(caret) #install.packages(\"caret\")\n",
    "library(reticulate) #install.packages(\"reticulate\")\n",
    "library(data.table) #install.packages(\"data.table)\n",
    "use_python(\"/usr/bin/python3\")\n",
    "#np = import(\"numpy\") #py_install(\"numpy\")\n",
    "#pd = import(\"pandas\") #py_install(\"pandas\")\n",
    "\n",
    "library(lcmm)\n",
    "\n",
    ".libPaths('~/R_packages')\n",
    "\n",
    "library(philentropy)\n",
    "library(plgp)\n",
    "\n",
    "\n",
    "\n",
    "setwd('~/northstar-trajectories/HierarchicalGaussianProcess/091023Run/HibmaModel')\n",
    "\n",
    "set.seed(12345)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dress-marijuana",
   "metadata": {},
   "source": [
    "## Load in Data (and tidy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "burning-excitement",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read.csv(file = 'in.csv')\n",
    "#N_data_used = 1000\n",
    "#data = data[0:N_data_used,]\n",
    "\n",
    "N_patients_pre_split = length(unique(data$PatID))\n",
    "N_valid = round(0.3*N_patients_pre_split) #30% of patients become the validaiton patients (data is pre-randomised)\n",
    "validation_pats = unique(data$PatID)[1:N_valid]\n",
    "training_pats = unique(data$PatID)[(N_valid+1):N_patients_pre_split]\n",
    "\n",
    "data_validation = data[data$PatID %in% validation_pats,]\n",
    "data = data[data$PatID %in% training_pats,]\n",
    "\n",
    "#FIt model from scratch, or load in previously obtained model fits? \n",
    "#(The latter requires the data and inputs to not have been changed, but does allow new plots and predictions to be done)\n",
    "Fit_from_scratch = FALSE\n",
    "load_results <- FALSE\n",
    "plot_preds <- TRUE\n",
    "save_results <- TRUE\n",
    "\n",
    "#which columns do we want in the model?\n",
    "inputs =  c(\"steroids_regime\")\n",
    "outputs = c(\"Calculated_nsaa_score\", \"nsaa_walk_time\", \"nsaa_rise_from_floor_time\")\n",
    "\n",
    "#make data in terms of 3 month intervals\n",
    "every_x_months = 3\n",
    "data$fup_age_at_date_of_assessment = round(data$fup_age_at_date_of_assessment/every_x_months)\n",
    "\n",
    "#Delete rows where the patients age aren't known (alternatively, we could re-infer it from the time?)\n",
    "data = data[!is.na(data$fup_age_at_date_of_assessment), ]\n",
    "\n",
    "#fill in missing timesteps (monthly)\n",
    "data = complete(data, fup_age_at_date_of_assessment = 0:(25*12/every_x_months), nesting(PatID))\n",
    "\n",
    "#also make sure we only have one data row per patID per appointment time:\n",
    "data = data %>%\n",
    "  group_by(PatID, fup_age_at_date_of_assessment) %>%\n",
    "  filter(row_number()==1) %>%\n",
    "  ungroup()\n",
    "\n",
    "#inputs (i.e. treatments / X in the model) cannot have any missing values at any time step.\n",
    "#This shouldn't be a problem as they dont need to be specially observed (clinicians should be dictating them)\n",
    "#but they may not have been written down for each timestep\n",
    "\n",
    "#sometimes data steroids is input as \"\" rather than NA\n",
    "data$steroids_used[which(data$steroids_used == \"\")] = NA\n",
    "data$steroids_regime[which(data$steroids_regime == \"\")] = NA\n",
    "\n",
    "#for the treatments, which we don't expect to change regularly, use the previous value if there is one\n",
    "data <- data %>% group_by(PatID) %>%\n",
    "  fill(age_at_km_steroids_start, .direction = \"downup\") %>%\n",
    "  fill(names(select(data, all_of(c(inputs, \"steroids_dose\")))), .direction = \"down\") %>%\n",
    "  dplyr::ungroup()\n",
    "\n",
    "#if the patient's age is after the age they started steroids, we can also use later values to interpolate\n",
    "#Note that this will only do so if the date they started steroids is recorded (at any point, and is why its interpolated up and down earlier)\n",
    "data <- data %>% group_by(PatID) %>%\n",
    "  mutate(steroids_dose = ifelse(is.na(steroids_dose) & fup_age_at_date_of_assessment> age_at_km_steroids_start, na.locf(steroids_dose, fromLast = TRUE), steroids_dose)) %>%\n",
    "  mutate(steroids_used = ifelse(is.na(steroids_used) & fup_age_at_date_of_assessment> age_at_km_steroids_start, na.locf(steroids_used, fromLast = TRUE, coredata = TRUE), steroids_used)) %>%\n",
    "  mutate(steroids_regime = ifelse(is.na(steroids_regime) & fup_age_at_date_of_assessment> age_at_km_steroids_start, na.locf(steroids_regime, fromLast = TRUE, coredata = TRUE), steroids_regime)) %>%\n",
    "  dplyr::ungroup()\n",
    "\n",
    "#and if any steroids dose are still NA, make them 0\n",
    "data <- data %>% mutate(steroids_dose = replace_na(steroids_dose, 0))\n",
    "#and then, if any steroids dose are 0, force the other steroid information to be NA\n",
    "data$steroids_used[data$steroids_dose == 0] = NA\n",
    "data$steroids_regime[data$steroids_dose == 0] = NA\n",
    "\n",
    "#for the other steroid information, replace NA with \"Unknown\" if steroids dose > 0, and \"None\" if steroids_dose = 0\n",
    "which_missing_used = is.na(data$steroids_used) & (data$steroids_dose > 0)\n",
    "which_none_used = is.na(data$steroids_used) & (data$steroids_dose == 0)\n",
    "which_missing_regime = is.na(data$steroids_regime) & (data$steroids_dose > 0)\n",
    "which_none_regime = is.na(data$steroids_regime) & (data$steroids_dose == 0)\n",
    "\n",
    "data$steroids_used <- as.character(data$steroids_used)\n",
    "data$steroids_used[which_none_used] = \"None\"\n",
    "if(sum(which_missing_used) > 0){\n",
    "  data$steroids_used[which_missing_used] = \"Unknown\"\n",
    "}\n",
    "\n",
    "data$steroids_regime <- as.character(data$steroids_regime)\n",
    "data$steroids_regime[which_none_regime] = \"None\"\n",
    "if(sum(which_missing_regime) > 0){\n",
    "  data$steroids_regime[which_missing_regime] = \"Unknown\"\n",
    "}\n",
    "\n",
    "\n",
    "#convert other information to factors, and force \"no steroids\" to be the baseline intercept\n",
    "data$steroids_used <- as.factor(data$steroids_used)\n",
    "data$steroids_used <- relevel(data$steroids_used, \"None\") #make \"None\" first\n",
    "data$steroids_regime <- as.factor(data$steroids_regime)\n",
    "data$steroids_regime <- relevel(data$steroids_regime, \"None\") #make \"None\" first\n",
    "\n",
    "\n",
    "#sometimes a walk time or rise time of 0 is recorded. This is impossible, so replace with NA\n",
    "\n",
    "data$nsaa_walk_time[which(data$nsaa_walk_time == 0)] = NA\n",
    "data$nsaa_rise_from_floor_time[which(data$nsaa_rise_from_floor_time == 0)] = NA\n",
    "\n",
    "#convert dataframe into 3d arrays (time, patient, column)\n",
    "N_patients = n_distinct(data$PatID)\n",
    "N_timesteps = n_distinct(data$fup_age_at_date_of_assessment)\n",
    "\n",
    "#which columns do we want (first set should be PatID and fup_age, second should be inputs, third should be outputs)\n",
    "data <-select(data, all_of(c(c(\"PatID\", \"fup_age_at_date_of_assessment\"), inputs, outputs)))\n",
    "\n",
    "#change format of data to allow conversion\n",
    "data = arrange(data, PatID, fup_age_at_date_of_assessment)\n",
    "data$PatID <- as.integer(as.numeric(factor(data$PatID)))\n",
    "data = data.frame(data)\n",
    "\n",
    "#convert categorical variables to one hot variables (\"None\" is the base example)\n",
    "dmy <- dummyVars(\" ~ .\", data = data, fullRank = TRUE)\n",
    "data <- data.frame(predict(dmy, newdata = data))\n",
    "\n",
    "N_cols = dim(select(data,contains(outputs)))[2] #number of outputs\n",
    "N_covs = dim(select(data,contains(inputs)))[2] #number of inputs\n",
    "Xnames = colnames(data)[2+(1:N_covs)] #names of covariates (for posterity)\n",
    "\n",
    "#convert to 3d array\n",
    "data <- data %>%\n",
    "  nest(-PatID) %>%    # collapse other columns to list column of data frames\n",
    "  mutate(data = map(data, ~as.matrix(.x[-1]))) %>%    # drop dates from nested data frames and coerce each to matrix\n",
    "  pull(data) %>%    # extract matrix list\n",
    "  invoke(abind::abind, ., along = 3) %>%    # abind in 3rd dimension\n",
    "  `dimnames<-`(list(as.character(unique(data$fup_age_at_date_of_assessment)), names(data)[3:(3+N_cols+N_covs-1)], unique(data$PatID)))    # set dimnames properly\n",
    "\n",
    "#swap index ordering to (PatID, timestep, column) (currently (timestep, column, PatID))\n",
    "data <- aperm(data, c(3,1,2))\n",
    "\n",
    "#make sure they have at least 1 NSAA score \n",
    "# might slightly bias, but we dont really have any proper information otherwise...\n",
    "which_enough = which(apply(!is.na(data[,,N_covs+1]), 1, sum)>0)\n",
    "data = data[which_enough, , ]\n",
    "\n",
    "#shuffle patient order (randomise)\n",
    "data = data[sample(dim(data)[1]),1:dim(data)[2], 1:dim(data)[3]]\n",
    "\n",
    "#subset data for speed reasons\n",
    "init_age = 3\n",
    "final_age = 20\n",
    "N_patients = dim(data)[1] #all of the patients\n",
    "\n",
    "data = data[1:dim(data)[1], (init_age*12/every_x_months):(final_age*12/every_x_months), ]\n",
    "#data = data[c(1,8), (init_age*12/every_x_months):(final_age*12/every_x_months), ]\n",
    "\n",
    "#save full data \n",
    "X_data = data[,,1:N_covs,drop = FALSE]\n",
    "y_data = data[,,(N_covs+1):(N_covs+N_cols),drop = FALSE]\n",
    "save(X_data, y_data,file='y_data.out.RData')\n",
    "#np$save(\"X_data.out.npy\",r_to_py(X_data))\n",
    "#np$save(\"y_data.out.npy\",r_to_py(y_data))\n",
    "\n",
    "#subset N patients as well\n",
    "data = data[1:N_patients, , ]\n",
    "\n",
    "N_timesteps = dim(data)[2]\n",
    "\n",
    "sum(!is.na(data[,,N_covs+1])) #how many data points do we have for NSAA (the first output, use +2 for the second, etc)\n",
    "\n",
    "#get input and output data\n",
    "X_data = data[,,1:N_covs,drop = FALSE]\n",
    "y_data = data[,,(N_covs+1):(N_covs+N_cols),drop = FALSE]\n",
    "\n",
    "#get maximum number of timesteps observed for each patient, for each output\n",
    "N_timesteps_t = matrix(1, nrow = N_patients, ncol = N_cols)\n",
    "for (output in 1:N_cols){\n",
    "  for (n in 1:N_patients){\n",
    "    N_timesteps_t[n, output] = max(which(!is.na(y_data[n,,output])))\n",
    "  }\n",
    "}\n",
    "\n",
    "#replace -Inf with 2 (minimum number of timestpes we'd need for model to actually run\n",
    "N_timesteps_t[N_timesteps_t==-Inf] = 2\n",
    "\n",
    "#Decide which patients/observations are the held-out validation points\n",
    "#We need to hold back certain observations from them, and make the model predict for the whole timeseries for them\n",
    "\n",
    "N_valid = round(0.2*N_patients) #20% of patients become the validaiton patients\n",
    "#delete the second X% of observations for the first set of patients, where X% is random (between 20% and 80%)\n",
    "y_gutted_data = y_data\n",
    "y_valid = y_data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#transform the data\n",
    "NSAA_transformer <- function(y){\n",
    "  ytrans = y\n",
    "  ytrans = logit( (ytrans + 0.5)/35) #convert -0.5 to 34.5 range to real range \n",
    "  return(ytrans)\n",
    "}\n",
    "\n",
    "positive_transformer <- function(y){\n",
    "  ytrans = y\n",
    "  ytrans = log(exp(ytrans)-1) #convert positive range to real range\n",
    "    \n",
    "  #make any values that are now inf what they were from y (its just a numerical issue caused by exp(big value)):\n",
    "  ytrans[which(ytrans == Inf)] = y[which(ytrans == Inf)]\n",
    "  return(ytrans)\n",
    "}\n",
    "\n",
    "NSAA_itransformer <- function(y){\n",
    "  ytrans = y\n",
    "  ytrans = ilogit(ytrans)*35 - 0.5  #convert real range to -0.5 to 34.5 range \n",
    "  return(ytrans)\n",
    "}\n",
    "\n",
    "positive_itransformer <- function(y){\n",
    "  ytrans = y\n",
    "  ytrans = log(1+exp(ytrans)) #convert real range to positive range\n",
    "    \n",
    "  #make any values that are now inf what they were from y (its just a numerical issue caused by exp(big value)):\n",
    "  ytrans[which(ytrans == Inf)] = y[which(ytrans == Inf)]\n",
    "  return(ytrans)\n",
    "}\n",
    "\n",
    "#y_gutted_data[,,1] = NSAA_transformer(y_gutted_data[,,1] )\n",
    "#y_gutted_data[,,2] = positive_transformer(y_gutted_data[,,2] )\n",
    "#y_gutted_data[,,3] = positive_transformer(y_gutted_data[,,3] )\n",
    "\n",
    "X_max = apply(X_data, 3, max, na.rm = TRUE)\n",
    "X_min = apply(X_data, 3, min, na.rm = TRUE)\n",
    "\n",
    "\n",
    "X_scale = (X_max-X_min)\n",
    "X_scale[X_scale == 0] = 1 #prevent NAs if only one value\n",
    "X = sweep(sweep(X_data, 3, X_min, \"-\"), 3, X_scale, \"/\")\n",
    "y_gutted = y_gutted_data\n",
    "\n",
    "\n",
    "time_step_multi <- 12/every_x_months\n",
    "\n",
    "#save standardisation values\n",
    "#save(X_min, X_max, y_mean, y_sd,file='stand_vals.out.RData')\n",
    "#np$save(\"X_min.out.npy\",r_to_py(X_min))\n",
    "#np$save(\"X_max.out.npy\",r_to_py(X_max))\n",
    "#np$save(\"y_mean.out.npy\",r_to_py(y_mean))\n",
    "#np$save(\"y_sd.out.npy\",r_to_py(y_sd))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exceptional-debate",
   "metadata": {},
   "outputs": [],
   "source": [
    "solveLeastSquares <- nimbleFunction(\n",
    "    run = function(X = double(2), y = double(1)) { # type declarations\n",
    "        ans <- inverse(t(X) %*% X) %*% (t(X) %*% y)\n",
    "        return(ans)\n",
    "        returnType(double(2))  # return type declaration\n",
    "    } )## Create Nimble Model (Code for the Bayesian Hierarchical Model)\n",
    "#get Nimble Model\n",
    "state_model_code <- nimbleCode({\n",
    "  \n",
    "    #init gradient\n",
    "    #init_grad_mean ~ T(dnorm(0,sd=20),0,)\n",
    "    #init_grad_sd ~ T(dnorm(0,sd=10),0,)\n",
    "    #for (n in 1:N_patients){\n",
    "    #    init_grad[n] ~ T(dnorm(init_grad_mean,sd=init_grad_sd),0,)\n",
    "    #    grad[1,n] <- init_grad[n]\n",
    "    #}\n",
    "    \n",
    "    #init nsaa\n",
    "    #init gradient\n",
    "    init_nsaa_mean ~ T(dnorm(0,sd=20),0,)\n",
    "    init_nsaa_sd ~ T(dnorm(0,sd=10),0,)\n",
    "    for (n in 1:N_patients){\n",
    "        init_nsaa[n] ~ T(dnorm(init_nsaa_mean,sd=init_nsaa_sd),0,)\n",
    "        nsaa[1,n] <- init_nsaa[n]\n",
    "    }\n",
    "  \n",
    "    #theta_k_in\n",
    "    theta_k_in_mean ~ T(dnorm(0,sd=20),0,)\n",
    "    theta_k_in_sd ~ T(dnorm(0,sd=10),0,)\n",
    "    for (n in 1:N_patients){\n",
    "        theta_k_in[n] ~ T(dnorm(theta_k_in_mean,sd=theta_k_in_sd),0,)\n",
    "    }\n",
    "    \n",
    "    #theta_k_out\n",
    "    theta_k_out_mean ~ T(dnorm(0,sd=20),0,)\n",
    "    theta_k_out_sd ~ T(dnorm(0,sd=10),0,)\n",
    "    for (n in 1:N_patients){\n",
    "        theta_k_out[n] ~ T(dnorm(theta_k_out_mean,sd=theta_k_out_sd),0,)\n",
    "    }\n",
    "    \n",
    "    #chain\n",
    "    for (time in 2:69){\n",
    "        for (individual in 1:N_patients){\n",
    "            #grad[time,individual] <- grad[time-1,individual] + theta_k_in[individual] - (theta_k_out[individual] * time) * nsaa[time-1,individual]\n",
    "            #grad[time,individual] <- theta_k_in[individual] - (theta_k_out[individual] * time) * nsaa[time-1,individual]\n",
    "            nsaa[time,individual] <- nsaa[time-1,individual] + theta_k_in[individual] - (theta_k_out[individual] * time) * nsaa[time-1,individual]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "  \n",
    "    #innovation  \n",
    "    #for (output in 1:N_cols) {\n",
    "      innov_mean ~ T(dnorm(0, sd = 5),0,)\n",
    "      innov_sd ~ T(dnorm(0, sd = 5),0,)\n",
    "      for (n in 1:N_patients) {        \n",
    "        innov[n] ~ T(dnorm(innov_mean, sd = innov_sd),0,)\n",
    "      }\n",
    "    #}\n",
    "                             \n",
    "  #obs err\n",
    "    #for (output in 1:N_cols) {\n",
    "      obs_err_mean ~ T(dnorm(0, sd = 5),0,)\n",
    "      obs_err_sd ~ T(dnorm(0, sd = 5),0,)\n",
    "      for (n in 1:N_patients) {        \n",
    "        obs_err[n] ~ T(dnorm(obs_err_mean, sd = obs_err_sd),0,)\n",
    "      }\n",
    "    #}\n",
    "                             \n",
    "  #Random walks\n",
    "  #for (output in 1:N_cols) {\n",
    "    for (n in 1:N_patients) {\n",
    "      RW[n, 1] <- 0\n",
    "      for (t in 2:N_timesteps_t_max[n]) {\n",
    "        RW[n, t] ~ dnorm(RW[n,t-1], sd = innov[n])\n",
    "      }\n",
    "    }\n",
    "  #}\n",
    "\n",
    "  \n",
    "  #observations:\n",
    "  for (data in (1:N_data)) {\n",
    "    y_state[data] <- nsaa[t_reshape[data],n_reshape[data]] + RW[n_reshape[data], t_reshape[data]]\n",
    "    y[data] ~ dnorm( y_state[data], sd = obs_err[n_reshape[data]])\n",
    "  }\n",
    "    \n",
    "  \n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sticky-shareware",
   "metadata": {},
   "source": [
    "### Get data ready for nimble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "first-adams",
   "metadata": {},
   "outputs": [],
   "source": [
    "#don't want to be modelling the *observations* at each time point, which nimble mgitht ry to do even for all the NAs\n",
    "#so we flatten y into a 1d array only containing the actual observations\n",
    "#but then we need several arrays which allow us to relearn which patient/timestep/output each eentry is:\n",
    "\n",
    "y_gutted_reshape <- as.numeric(y_gutted)\n",
    "n_matrix <- y_gutted\n",
    "for (n in 1:dim(n_matrix)[1]){\n",
    "  n_matrix[n,,] = n\n",
    "}\n",
    "n_reshape <- as.numeric(n_matrix)\n",
    "\n",
    "t_matrix <- y_gutted\n",
    "for (t in 1:dim(t_matrix)[2]){\n",
    "  t_matrix[,t,] = t\n",
    "}\n",
    "t_reshape <- as.numeric(t_matrix)\n",
    "\n",
    "out_matrix <- y_gutted\n",
    "for (out in 1:dim(out_matrix)[3]){\n",
    "  out_matrix[,,out] = out\n",
    "}\n",
    "out_reshape <- as.numeric(out_matrix)\n",
    "\n",
    "y_gutted_reshape_isna = which(!is.na(y_gutted_reshape))\n",
    "y_gutted_reshape = y_gutted_reshape[y_gutted_reshape_isna]\n",
    "n_reshape = n_reshape[y_gutted_reshape_isna]\n",
    "t_reshape = t_reshape[y_gutted_reshape_isna]\n",
    "out_reshape = out_reshape[y_gutted_reshape_isna]\n",
    "\n",
    "#For hibma mode, we only fit nsaa model, so remove all with outcome != 1\n",
    "y_gutted_reshape_isna = which(!is.na(y_gutted_reshape))\n",
    "y_gutted_reshape = y_gutted_reshape[out_reshape == 1]\n",
    "n_reshape = n_reshape[out_reshape == 1]\n",
    "t_reshape = t_reshape[out_reshape == 1]\n",
    "out_reshape = out_reshape[out_reshape == 1]\n",
    "\n",
    "#Due to castastrophic difficulties with indexing in nimble I have resorted to using these ad-hoc, hacky indexers to get it to work\n",
    "#I've forgotten what most of them do to be honest but I managed to get it to work somehow\n",
    "#Good luck to anyone in the future tying to figure out what is going on\n",
    "#I've tried to annotate some of it to help out but idk\n",
    "#Feel free to contact me (Victor Applebaum) if you have any questions but I will probaly have forgotten most of it by the time you're looking at this\n",
    "\n",
    "n_data_ids <- rep(NA,N_patients)\n",
    "for (n in 1:N_patients){\n",
    "    n_data_ids[n] <- sum(n_reshape==n)\n",
    "}\n",
    "\n",
    "#Ok so some of the patients have had there results removed for some reason, and the whole thing crashes when this happened\n",
    "#So we create a new number, N_pat_with_points, which is like N_patients but only those that have points\n",
    "#We can then use i_n[n] for 1:N_pat_with_points to point to the nth patient that actually has points\n",
    "n_pat_with_points <- c()\n",
    "for (n in 1:N_patients){\n",
    "    if (length(n_reshape[n_reshape==n])>0){\n",
    "        n_pat_with_points <- append(n_pat_with_points,n)\n",
    "    }\n",
    "}\n",
    "i_n <- rep(NA,length(n_pat_with_points))\n",
    "for (i in 1:length(n_pat_with_points)){\n",
    "    i_n[i] <- (1:N_patients)[n_pat_with_points[i]]\n",
    "}\n",
    "N_pat_with_points <- length(n_pat_with_points)\n",
    "\n",
    "i <- nimMatrix(NA,N_patients,max(n_data_ids))#indexing matrix for patients i[n,i_ind]= position of i_ind'th point for nth patient\n",
    "for (n in 1:N_patients){\n",
    "    if (length((1:length(n_reshape))[n_reshape==n])>0){\n",
    "        data_n <- c()\n",
    "        for (data in 1:length(n_reshape)){\n",
    "            if (n_reshape[data] == n){\n",
    "                data_n <- append(data_n,data)\n",
    "            }\n",
    "        }\n",
    "        for (i_ind in 1:length(data_n)){\n",
    "            i[n,i_ind] <- data_n[i_ind]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "j <- nimArray(NA,dim = c(N_patients,N_cols,max(n_data_ids)))#indexes both patient and outcome j[n,m,i_ind] position of i_ind'th point for nth patient's mth outcome\n",
    "for (n in 1:N_patients){\n",
    "    for (m in 1:N_cols){\n",
    "        if (length((1:length(n_reshape))[n_reshape==n & out_reshape==m])>0){\n",
    "            data_n <- c()\n",
    "            for (data in 1:length(n_reshape)){\n",
    "                if (n_reshape[data] == n & out_reshape[data] == m){\n",
    "                    data_n <- append(data_n,data)\n",
    "                }\n",
    "            }\n",
    "            for (i_ind in 1:length(data_n)){\n",
    "                j[n,m,i_ind] <- data_n[i_ind]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "i_j <- nimMatrix(NA,N_patients,N_cols)#number of points avaliable for the patient n's mth outcome\n",
    "for (n in 1:N_patients){\n",
    "    for (m in 1:N_cols){\n",
    "        i_j[n,m] <- sum(is.na(j[n,m,])==FALSE)\n",
    "    }\n",
    "}\n",
    "y_real_reindexed=nimArray(NA,dim=c(N_patients,N_cols,length(y_gutted_reshape)))#rearranges y which i need for some reason\n",
    "for (n in 1:N_pat_with_points){\n",
    "    for (output in 1:N_cols){\n",
    "      for (data in 1:i_j[i_n[n],output]){\n",
    "          y_real_reindexed[i_n[n],output,data] <- y_gutted_reshape[j[i_n[n],output,data]]\n",
    "\n",
    "      }\n",
    "    }\n",
    "}\n",
    "\n",
    "i_out <- nimMatrix(NA,N_patients,N_cols)\n",
    "i_out_num <- nimArray(NA,dim=c(N_patients))\n",
    "for (n in 1:N_patients){\n",
    "    counter <- 0\n",
    "    for (output in 1:N_cols){\n",
    "        if (i_j[n,output] > 1){\n",
    "            counter <- counter + 1\n",
    "            i_out[n,counter] <- output\n",
    "        }\n",
    "    }\n",
    "    i_out_num[n] <- sum(!is.na(i_out[n,]))\n",
    "}\n",
    "i_out_1 <- nimMatrix(NA,N_patients,N_cols)\n",
    "i_out_num_1 <- nimArray(NA,dim=c(N_patients))\n",
    "for (n in 1:N_patients){\n",
    "    counter <- 0\n",
    "    for (output in 1:N_cols){\n",
    "        if (i_j[n,output] == 1){\n",
    "            counter <- counter + 1\n",
    "            i_out_1[n,counter] <- output\n",
    "        }\n",
    "    }\n",
    "    i_out_num_1[n] <- sum(!is.na(i_out_1[n,]))\n",
    "}\n",
    "\n",
    "\n",
    "starts_mat <- nimArray(NA,c(N_pat_with_points,N_cols))#At some point things have to go in a big matrix, we need these two to tell us the positions we should be working in\n",
    "ends_mat <- nimArray(NA,c(N_pat_with_points,N_cols))\n",
    "for (n in 1:N_pat_with_points){\n",
    "    for (m in 1:N_cols){\n",
    "        if (m == 1 & n == 1){\n",
    "            starts <- c(1)\n",
    "            ends <- c(i_j[i_n[n],m])\n",
    "        }\n",
    "        starts <- append(starts,ends[length(ends)]+1)\n",
    "        ends <- append(ends,i_j[i_n[n],m]+starts[length(starts)]-1)\n",
    "        ends_mat[n,m] <- ends[length(ends)-1]\n",
    "        starts_mat[n,m] <- ends_mat[n,m]-i_j[i_n[n]]+1\n",
    "    }\n",
    "}\n",
    "\n",
    "starts_mat <- nimArray(NA,c(N_pat_with_points,N_cols))#At some point things have to go in a big matrix, we need these two to tell us the positions we should be working in\n",
    "ends_mat <- nimArray(NA,c(N_pat_with_points,N_cols))\n",
    "rolling_sum <- 0\n",
    "for (n in 1:N_pat_with_points){\n",
    "    for (m in 1:N_cols){\n",
    "        starts_mat[n,m] <- rolling_sum + 1\n",
    "        ends_mat[n,m] <- starts_mat[n,m] + i_j[i_n[n],m]-1\n",
    "        rolling_sum <- rolling_sum + i_j[i_n[n],m]\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778a2ca0-f19a-4496-8fff-95e9f96631cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Before fitting MCMC, also find some properties about the data set for synthetic section\n",
    "\n",
    "col_i = 1 #we are interested in NSAA - first outcome\n",
    "\n",
    "    #We find the distribution of start points\n",
    "    start_points <- c()\n",
    "    for (id in unique(n_reshape[out_reshape==1])){\n",
    "        start_points <- append(start_points,min(t_reshape[out_reshape==1 & n_reshape==id]))\n",
    "    }\n",
    "\n",
    "\n",
    "    #We find the distribution of rates of appointment attendance in the real data\n",
    "    rates <- c()\n",
    "    for (id in unique(n_reshape[out_reshape==1 & n_reshape > N_valid])){\n",
    "        if (length(n_reshape[out_reshape==1 & n_reshape==id]) > 0){\n",
    "            rates <- append(rates,(max(t_reshape[out_reshape==1 & n_reshape==id])-min(t_reshape[out_reshape==1 & n_reshape==id]))/length(n_reshape[out_reshape==1 & n_reshape==id]-1))\n",
    "        }\n",
    "    }\n",
    "\n",
    "    ##Finding the probabilities of a line stopping\n",
    "    #First we find the locations of the stops for each individual\n",
    "    end_location <- array(NA,dim=c(length(unique(n_reshape[n_reshape>N_valid])),2))\n",
    "    for (individual in 1:length(unique(n_reshape[n_reshape>N_valid]))){\n",
    "        end_location[individual,1] = max(t_reshape[n_reshape==unique(n_reshape[n_reshape>N_valid])[individual] & out_reshape==col_i])\n",
    "        end_location[individual,2] = y_gutted_reshape[n_reshape==unique(n_reshape[n_reshape>N_valid])[individual] & out_reshape==col_i & t_reshape==end_location[individual,1]] \n",
    "    }\n",
    "    #Create grid\n",
    "    grid_height <- 6\n",
    "    grid_width <- 6\n",
    "    n_stops <- array(NA,dim=c(grid_height,grid_width))#Number of stops within a box\n",
    "    stopping_grid <- array(NA,dim=c(grid_height,grid_width))#Fraction of point in each box which is a stop\n",
    "    for (i in 1:grid_height){\n",
    "        for (j in 1:grid_width){\n",
    "            #Find box locations\n",
    "            age_min <- (j-1)*70/grid_width\n",
    "            age_max <- j*70/grid_width\n",
    "            nsaa_min <- (i-1)*35/grid_height\n",
    "            nsaa_max <- i*35/grid_height\n",
    "            n_stops[i,j] <- length((1:length(unique(n_reshape)))[end_location[,1]>=age_min & end_location[,1]<age_max & end_location[,2]>=nsaa_min & end_location[,2]<nsaa_max])\n",
    "            stopping_grid[i,j] <- n_stops[i,j] / length(n_reshape[out_reshape==col_i & t_reshape>=age_min & t_reshape<age_max & y_gutted_reshape>=nsaa_min & y_gutted_reshape<nsaa_max])\n",
    "            if (is.na(stopping_grid[i,j])){stopping_grid[i,j]<-0}\n",
    "        }\n",
    "    }\n",
    "\n",
    "#save treatments for later\n",
    "X_train = X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atmospheric-london",
   "metadata": {},
   "source": [
    "### Prepare MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollywood-bacteria",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_timesteps_t_max <- apply(N_timesteps_t,1, max)\n",
    "\n",
    "state_model_consts <- list(N_covs = N_covs, #Number of covariances (something to do with treatments)?\n",
    "                           N_cols = N_cols, #Number of outputs (3)\n",
    "                           N_timesteps = N_timesteps, #Number of timesteps\n",
    "                           N_timesteps_t = N_timesteps_t, \n",
    "                           N_timesteps_t_max = N_timesteps_t_max,\n",
    "                           N_patients = N_patients, #Number of patients\n",
    "                           X = X,#Something to do with treatments\n",
    "                           N_data = length(y_gutted_reshape), #Number of data points\n",
    "                           n_reshape = n_reshape,#Patient identifiers for each point\n",
    "                           t_reshape = t_reshape,#Time for each point\n",
    "                           out_reshape = out_reshape,#Identifier for output\n",
    "                           timesteps_per_year = 12/every_x_months,\n",
    "                           mature_age_steps = (20-init_age)*12/every_x_months,\n",
    "                           milestone_age_steps = (15-init_age)*12/every_x_months,\n",
    "                           n_data_ids = n_data_ids,#number of points for each patient\n",
    "                           i = i, #indexing matrix for patients i[n,i_ind]= position of i_ind'th point for nth patient\n",
    "                           n_pat_with_points = n_pat_with_points,\n",
    "                           i_n = i_n,\n",
    "                           N_pat_with_points =N_pat_with_points,\n",
    "                           j = j, #indexes both patient and outcome j[n,m,i_ind] position of i_ind'th point for nth patient's mth outcome\n",
    "                           i_j = i_j,\n",
    "                           starts_mat = starts_mat,\n",
    "                           ends_mat = ends_mat,\n",
    "                           i_out = i_out,\n",
    "                           i_out_num = i_out_num,\n",
    "                           i_out_1 = i_out_1,\n",
    "                           i_out_num_1 = i_out_num_1\n",
    "                          )\n",
    "state_model_data <-  list(y = y_gutted_reshape)#When Using RW\n",
    "#state_model_data <-  list(y = y_real_reindexed)#When Using GP\n",
    "seed = 12345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b233d8-183b-4304-8c1a-c9d5d110d0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load init values from previous run\n",
    "load('state_samples.out.RData')\n",
    "#state_model_inits <- state_samples$chain1[1000,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf43a35-b45c-4d2e-bc39-ed3749c867a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_model_inits <- list(init_nsaa = array(NA,N_patients),\n",
    "                            theta_k_in = array(NA,N_patients),\n",
    "                            theta_k_out = array(NA,N_patients),\n",
    "                            obs_err = array(NA,N_patients),\n",
    "                            innov = array(NA,N_patients),\n",
    "                            RW = array(NA,c(N_patients,69))\n",
    "                          )\n",
    "                          \n",
    "\n",
    "\n",
    "\n",
    "state_model_inits[['init_nsaa_mean']] = state_samples$chain1[1000,'init_nsaa_mean']\n",
    "state_model_inits[['init_nsaa_sd']] = state_samples$chain1[1000,'init_nsaa_sd']\n",
    "state_model_inits[['theta_k_in_mean']] = state_samples$chain1[1000,'theta_k_in_mean']\n",
    "state_model_inits[['theta_k_in_sd']] = state_samples$chain1[1000,'theta_k_in_sd']\n",
    "state_model_inits[['theta_k_out_mean']] = state_samples$chain1[1000,'theta_k_out_mean']\n",
    "state_model_inits[['theta_k_out_sd']] = state_samples$chain1[1000,'theta_k_out_sd']\n",
    "state_model_inits[['obs_err_mean']] = state_samples$chain1[1000,'obs_err_mean']\n",
    "state_model_inits[['obs_err_sd']] = state_samples$chain1[1000,'obs_err_sd']\n",
    "state_model_inits[['innov_mean']] = state_samples$chain1[1000,'innov_mean']\n",
    "state_model_inits[['innov_sd']] = state_samples$chain1[1000,'innov_sd']\n",
    "for (individual in 1:state_model_consts$N_patients){\n",
    "    state_model_inits[['init_nsaa']][individual] <- state_samples$chain1[1000,'init_nsaa_mean']\n",
    "    state_model_inits[['theta_k_in']][individual] <- state_samples$chain1[1000,'theta_k_in_mean']\n",
    "    state_model_inits[['theta_k_out']][individual] <- state_samples$chain1[1000,'theta_k_out_mean']\n",
    "    state_model_inits[['obs_err']][individual] <- state_samples$chain1[1000,'obs_err_mean']\n",
    "    state_model_inits[['innov']][individual] <- state_samples$chain1[1000,'innov_mean']\n",
    "    for (time in 1:69){\n",
    "        state_model_inits[['RW']][individual,time] <- 0\n",
    "    }\n",
    "}\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460cabc5-bd3f-438b-8e2b-80af64cd6758",
   "metadata": {},
   "source": [
    "## Run MCMC, this is the cell which takes forever, and could be skipped and the results loaded in instead"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ce3152-c6e4-49b4-8561-aaaaa93f146f",
   "metadata": {},
   "source": [
    "It will be skipped if Fit_from_scratch is not TRUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9362f2c5-8835-4c1e-8d70-0d53b53ca5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if (Fit_from_scratch == TRUE){\n",
    "      #nimble function for calculating the softmax probs for a vector of scores\n",
    "      softplus_nimble <- nimbleFunction(\n",
    "        run = function(x = double(0)){\n",
    "          return(log(1+exp(x)))\n",
    "          returnType(double(0))\n",
    "        })\n",
    "      csoftplus_nimble <- compileNimble(softplus_nimble)\n",
    "    \n",
    "\n",
    "      #nimble function required for getting LKJ correlation matrix\n",
    "      uppertri_mult_diag <- nimbleFunction(\n",
    "        run = function(mat = double(2), vec = double(1)) {\n",
    "          returnType(double(2))\n",
    "          p <- length(vec)\n",
    "          out <- matrix(nrow = p, ncol = p, init = FALSE)\n",
    "          for(i in 1:p)\n",
    "            out[ , i] <- mat[ , i] * vec[i]\n",
    "          return(out)\n",
    "        })\n",
    "      cuppertri_mult_diag <- compileNimble(uppertri_mult_diag)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "monitors=c(\"nsaa\",\"y_state\",\n",
    "                                                          \"RW\",\"innov\",\"innov_mean\",\"innov_sd\",\n",
    "                                                          \"obs_err\",\"obs_err_mean\",\"obs_err_sd\",\n",
    "                                                          \"theta_k_in\",\"theta_k_in_mean\",\"theta_k_in_sd\",\n",
    "                                                          \"theta_k_out\",\"theta_k_out_mean\",\"theta_k_out_sd\",\n",
    "                                                          \"init_nsaa\",\"init_nsaa_mean\",\"init_nsaa_sd\"\n",
    "                                               )\n",
    "\n",
    "\n",
    "\n",
    "      state_samples <- nimbleMCMC(code = state_model_code,\n",
    "                                  constants = state_model_consts,\n",
    "                                  data = state_model_data,\n",
    "                                  inits = state_model_inits,\n",
    "                                  monitors=monitors,\n",
    "                                  nburnin=1000000,\n",
    "                                  niter = 2000000,\n",
    "                                  thin = 1000,\n",
    "                                  #setSeed=1,\n",
    "                                  samplesAsCodaMCMC = TRUE,\n",
    "                                  nchains = 2)\n",
    "\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c477b25-c62f-45ae-9c1a-c4a67d14d0b9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Save or load the data (decide depending on if we ran the previous cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a675d2-e080-46fa-b915-421fe4c30ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save (or load) results\n",
    "\n",
    "if (Fit_from_scratch == TRUE){\n",
    "    save(state_samples,file='state_samples.out_RERUN.RData')\n",
    "}else{\n",
    "    load('state_samples.out_RERUN.RData')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0e2c6d-0715-494d-8219-3e99f4a6cd8b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Traceplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conservative-victorian",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(state_samples[,\"init_nsaa_mean\"])\n",
    "plot(state_samples[,\"init_nsaa_sd\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02dec49b-a3cf-4bd0-b3c8-84dbb22eeba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(state_samples[,\"theta_k_in_mean\"])\n",
    "plot(state_samples[,\"theta_k_in_sd\"])\n",
    "plot(state_samples[,\"theta_k_in[2]\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sticky-weapon",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(state_samples[,\"theta_k_out_mean\"])\n",
    "plot(state_samples[,\"theta_k_out_sd\"])\n",
    "plot(state_samples[,\"theta_k_out[5]\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a69aee3-ec56-4cfe-a7b6-c15459626f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(state_samples[,\"obs_err_mean\"])\n",
    "plot(state_samples[,\"obs_err_sd\"])\n",
    "plot(state_samples[,\"obs_err[1]\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434812fd-5c75-401a-873c-29ee940e0510",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(state_samples[,\"y_state[10]\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c501ec85-9f0c-4aa8-a1e3-050caa03bcbc",
   "metadata": {},
   "source": [
    "## Get results from model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc43e16-c72f-41a2-bc14-b1e4ac99c6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_samples_merged <- data.frame(do.call('rbind',state_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e070aabc-5b78-417f-ae09-08e558272fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract population parameters from fit\n",
    "#and take logs of positive only parameters\n",
    "\n",
    "transformed_state_samples_merged <- list()\n",
    "\n",
    "transformed_state_samples_merged$init_nsaa_mean <- c(log(state_samples_merged$init_nsaa_mean))\n",
    "transformed_state_samples_merged$init_nsaa_sd <- c(log(state_samples_merged$init_nsaa_sd))\n",
    "transformed_state_samples_merged$theta_k_in_mean <- c(log(state_samples_merged$theta_k_in_mean))\n",
    "transformed_state_samples_merged$theta_k_in_sd <- c(log(state_samples_merged$theta_k_in_sd))\n",
    "transformed_state_samples_merged$theta_k_out_mean <- c(log(state_samples_merged$theta_k_out_mean))\n",
    "transformed_state_samples_merged$theta_k_out_sd <- c(log(state_samples_merged$theta_k_out_sd))\n",
    "transformed_state_samples_merged$innov_mean <- c(log(state_samples_merged$innov_mean))\n",
    "transformed_state_samples_merged$innov_sd <- c(log(state_samples_merged$innov_sd))\n",
    "transformed_state_samples_merged$obs_err_mean <- c(log(state_samples_merged$obs_err_mean))\n",
    "transformed_state_samples_merged$obs_err_sd <- c(log(state_samples_merged$obs_err_sd))\n",
    "\n",
    "order = c('init_nsaa_mean','init_nsaa_sd',\n",
    "          'theta_k_in_mean','theta_k_in_sd',\n",
    "          'theta_k_out_mean','theta_k_out_sd',\n",
    "          'innov_mean','innov_sd',\n",
    "          'obs_err_mean','obs_err_sd'\n",
    "         )\n",
    "transformed_state_samples_merged =  transformed_state_samples_merged[order]\n",
    "\n",
    "#now approaximate using multivariate normal\n",
    "pop_par_mean = colMeans(t(matrix(unlist(transformed_state_samples_merged), ncol = 2000, byrow = TRUE)))\n",
    "pop_par_cov  = cov(t(matrix(unlist(transformed_state_samples_merged), ncol = 2000, byrow = TRUE)))\n",
    "\n",
    "save(pop_par_mean,file='RERUN_pop_par_mean.RData')\n",
    "save(pop_par_cov,file='RERUN_pop_par_cov.RData')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2979d83e-29de-4d08-a424-72782506c09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#New Nimble model for fitting individuals given the known population parmeters\n",
    "solveLeastSquares <- nimbleFunction(\n",
    "    run = function(X = double(2), y = double(1)) { # type declarations\n",
    "        ans <- inverse(t(X) %*% X) %*% (t(X) %*% y)\n",
    "        return(ans)\n",
    "        returnType(double(2))  # return type declaration\n",
    "    } )## Create Nimble Model (Code for the Bayesian Hierarchical Model)\n",
    "#get Nimble Model\n",
    "\n",
    "state_model_code_individual <- nimbleCode({\n",
    "  \n",
    "    for (n in 1:N_patients){\n",
    "        parameters[n,1:10] ~ dmnorm(pop_par_mean[1:10],cov = pop_par_cov[1:10,1:10])\n",
    "        init_nsaa_mean[n] <- exp(parameters[n,1])\n",
    "        init_nsaa_sd[n] <- exp(parameters[n,2])\n",
    "        theta_k_in_mean[n] <- exp(parameters[n,3])\n",
    "        theta_k_in_sd[n] <- exp(parameters[n,4])\n",
    "        theta_k_out_mean[n] <- exp(parameters[n,5])\n",
    "        theta_k_out_sd[n] <- exp(parameters[n,6])\n",
    "        innov_mean[n] <- exp(parameters[n,7])\n",
    "        innov_sd[n] <- exp(parameters[n,8])\n",
    "        obs_err_mean[n] <- exp(parameters[n,9])\n",
    "        obs_err_sd[n] <- exp(parameters[n,10])\n",
    "    }\n",
    "        \n",
    "    #init nsaa\n",
    "    #init gradient\n",
    "    for (n in 1:N_patients){\n",
    "        init_nsaa[n] ~ T(dnorm(init_nsaa_mean[n],sd=init_nsaa_sd[n]),0,)\n",
    "        nsaa[1,n] <- init_nsaa[n]\n",
    "    }\n",
    "  \n",
    "    #theta_k_in\n",
    "    for (n in 1:N_patients){\n",
    "        theta_k_in[n] ~ T(dnorm(theta_k_in_mean[n],sd=theta_k_in_sd[n]),0,)\n",
    "    }\n",
    "    \n",
    "    #theta_k_out\n",
    "    for (n in 1:N_patients){\n",
    "        theta_k_out[n] ~ T(dnorm(theta_k_out_mean[n],sd=theta_k_out_sd[n]),0,)\n",
    "    }\n",
    "    \n",
    "    #chain\n",
    "    for (time in 2:69){\n",
    "        for (individual in 1:N_patients){\n",
    "            #grad[time,individual] <- grad[time-1,individual] + theta_k_in[individual] - (theta_k_out[individual] * time) * nsaa[time-1,individual]\n",
    "            #grad[time,individual] <- theta_k_in[individual] - (theta_k_out[individual] * time) * nsaa[time-1,individual]\n",
    "            nsaa[time,individual] <- nsaa[time-1,individual] + theta_k_in[individual] - (theta_k_out[individual] * time) * nsaa[time-1,individual]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "  \n",
    "    #innovation  \n",
    "    #for (output in 1:N_cols) {\n",
    "      for (n in 1:N_patients) {        \n",
    "        innov[n] ~ T(dnorm(innov_mean[n], sd = innov_sd[n]),0,)\n",
    "      }\n",
    "    #}\n",
    "                             \n",
    "  #obs err\n",
    "    #for (output in 1:N_cols) {\n",
    "      for (n in 1:N_patients) {        \n",
    "        obs_err[n] ~ T(dnorm(obs_err_mean[n], sd = obs_err_sd[n]),0,)\n",
    "      }\n",
    "    #}\n",
    "                             \n",
    "  #Random walks\n",
    "  #for (output in 1:N_cols) {\n",
    "    for (n in 1:N_patients) {\n",
    "      RW[n, 1] <- 0\n",
    "      for (t in 2:69) {\n",
    "        RW[n, t] ~ dnorm(RW[n,t-1], sd = innov[n])\n",
    "      }\n",
    "    }\n",
    "  #}\n",
    "\n",
    "  \n",
    "  #observations:\n",
    "  for (data in (1:N_data)) {\n",
    "    y_state[data] <- nsaa[t_reshape[data],n_reshape[data]] + RW[n_reshape[data], t_reshape[data]]\n",
    "    y[data] ~ dnorm( y_state[data], sd = obs_err[n_reshape[data]])\n",
    "  }\n",
    "\n",
    "  \n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dbdc66-79b1-48bb-866e-e12af7188d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Now we repeat data processing with the validation dataset instead\n",
    "data = data_validation\n",
    "\n",
    "set.seed(12345)\n",
    "\n",
    "\n",
    "#which columns do we want in the model?\n",
    "inputs =  c(\"steroids_regime\")\n",
    "outputs = c(\"Calculated_nsaa_score\", \"nsaa_walk_time\", \"nsaa_rise_from_floor_time\")\n",
    "\n",
    "#make data in terms of 3 month intervals\n",
    "every_x_months = 3\n",
    "data$fup_age_at_date_of_assessment = round(data$fup_age_at_date_of_assessment/every_x_months)\n",
    "\n",
    "#Delete rows where the patients age aren't known (alternatively, we could re-infer it from the time?)\n",
    "data = data[!is.na(data$fup_age_at_date_of_assessment), ]\n",
    "\n",
    "#fill in missing timesteps (monthly)\n",
    "data = complete(data, fup_age_at_date_of_assessment = 0:(25*12/every_x_months), nesting(PatID))\n",
    "\n",
    "#also make sure we only have one data row per patID per appointment time:\n",
    "data = data %>%\n",
    "  group_by(PatID, fup_age_at_date_of_assessment) %>%\n",
    "  filter(row_number()==1) %>%\n",
    "  ungroup()\n",
    "\n",
    "#inputs (i.e. treatments / X in the model) cannot have any missing values at any time step.\n",
    "#This shouldn't be a problem as they dont need to be specially observed (clinicians should be dictating them)\n",
    "#but they may not have been written down for each timestep\n",
    "\n",
    "#sometimes data steroids is input as \"\" rather than NA\n",
    "data$steroids_used[which(data$steroids_used == \"\")] = NA\n",
    "data$steroids_regime[which(data$steroids_regime == \"\")] = NA\n",
    "\n",
    "#for the treatments, which we don't expect to change regularly, use the previous value if there is one\n",
    "data <- data %>% group_by(PatID) %>%\n",
    "  fill(age_at_km_steroids_start, .direction = \"downup\") %>%\n",
    "  fill(names(select(data, all_of(c(inputs, \"steroids_dose\")))), .direction = \"down\") %>%\n",
    "  dplyr::ungroup()\n",
    "\n",
    "#if the patient's age is after the age they started steroids, we can also use later values to interpolate\n",
    "#Note that this will only do so if the date they started steroids is recorded (at any point, and is why its interpolated up and down earlier)\n",
    "data <- data %>% group_by(PatID) %>%\n",
    "  mutate(steroids_dose = ifelse(is.na(steroids_dose) & fup_age_at_date_of_assessment> age_at_km_steroids_start, na.locf(steroids_dose, fromLast = TRUE), steroids_dose)) %>%\n",
    "  mutate(steroids_used = ifelse(is.na(steroids_used) & fup_age_at_date_of_assessment> age_at_km_steroids_start, na.locf(steroids_used, fromLast = TRUE, coredata = TRUE), steroids_used)) %>%\n",
    "  mutate(steroids_regime = ifelse(is.na(steroids_regime) & fup_age_at_date_of_assessment> age_at_km_steroids_start, na.locf(steroids_regime, fromLast = TRUE, coredata = TRUE), steroids_regime)) %>%\n",
    "  dplyr::ungroup()\n",
    "\n",
    "#and if any steroids dose are still NA, make them 0\n",
    "data <- data %>% mutate(steroids_dose = replace_na(steroids_dose, 0))\n",
    "#and then, if any steroids dose are 0, force the other steroid information to be NA\n",
    "data$steroids_used[data$steroids_dose == 0] = NA\n",
    "data$steroids_regime[data$steroids_dose == 0] = NA\n",
    "\n",
    "#for the other steroid information, replace NA with \"Unknown\" if steroids dose > 0, and \"None\" if steroids_dose = 0\n",
    "which_missing_used = is.na(data$steroids_used) & (data$steroids_dose > 0)\n",
    "which_none_used = is.na(data$steroids_used) & (data$steroids_dose == 0)\n",
    "which_missing_regime = is.na(data$steroids_regime) & (data$steroids_dose > 0)\n",
    "which_none_regime = is.na(data$steroids_regime) & (data$steroids_dose == 0)\n",
    "\n",
    "data$steroids_used <- as.character(data$steroids_used)\n",
    "data$steroids_used[which_none_used] = \"None\"\n",
    "if(sum(which_missing_used) > 0){\n",
    "  data$steroids_used[which_missing_used] = \"Unknown\"\n",
    "}\n",
    "\n",
    "data$steroids_regime <- as.character(data$steroids_regime)\n",
    "data$steroids_regime[which_none_regime] = \"None\"\n",
    "if(sum(which_missing_regime) > 0){\n",
    "  data$steroids_regime[which_missing_regime] = \"Unknown\"\n",
    "}\n",
    "\n",
    "\n",
    "#convert other information to factors, and force \"no steroids\" to be the baseline intercept\n",
    "data$steroids_used <- as.factor(data$steroids_used)\n",
    "data$steroids_used <- relevel(data$steroids_used, \"None\") #make \"None\" first\n",
    "data$steroids_regime <- as.factor(data$steroids_regime)\n",
    "data$steroids_regime <- relevel(data$steroids_regime, \"None\") #make \"None\" first\n",
    "\n",
    "\n",
    "#sometimes a walk time or rise time of 0 is recorded. This is impossible, so replace with NA\n",
    "\n",
    "data$nsaa_walk_time[which(data$nsaa_walk_time == 0)] = NA\n",
    "data$nsaa_rise_from_floor_time[which(data$nsaa_rise_from_floor_time == 0)] = NA\n",
    "\n",
    "#convert dataframe into 3d arrays (time, patient, column)\n",
    "N_patients = n_distinct(data$PatID)\n",
    "N_timesteps = n_distinct(data$fup_age_at_date_of_assessment)\n",
    "\n",
    "#which columns do we want (first set should be PatID and fup_age, second should be inputs, third should be outputs)\n",
    "data <-select(data, all_of(c(c(\"PatID\", \"fup_age_at_date_of_assessment\"), inputs, outputs)))\n",
    "\n",
    "#change format of data to allow conversion\n",
    "data = arrange(data, PatID, fup_age_at_date_of_assessment)\n",
    "data$PatID <- as.integer(as.numeric(factor(data$PatID)))\n",
    "data = data.frame(data)\n",
    "\n",
    "#convert categorical variables to one hot variables (\"None\" is the base example)\n",
    "dmy <- dummyVars(\" ~ .\", data = data, fullRank = TRUE)\n",
    "data <- data.frame(predict(dmy, newdata = data))\n",
    "\n",
    "N_cols = dim(select(data,contains(outputs)))[2] #number of outputs\n",
    "N_covs = dim(select(data,contains(inputs)))[2] #number of inputs\n",
    "Xnames = colnames(data)[2+(1:N_covs)] #names of covariates (for posterity)\n",
    "\n",
    "#convert to 3d array\n",
    "data <- data %>%\n",
    "  nest(-PatID) %>%    # collapse other columns to list column of data frames\n",
    "  mutate(data = map(data, ~as.matrix(.x[-1]))) %>%    # drop dates from nested data frames and coerce each to matrix\n",
    "  pull(data) %>%    # extract matrix list\n",
    "  invoke(abind::abind, ., along = 3) %>%    # abind in 3rd dimension\n",
    "  `dimnames<-`(list(as.character(unique(data$fup_age_at_date_of_assessment)), names(data)[3:(3+N_cols+N_covs-1)], unique(data$PatID)))    # set dimnames properly\n",
    "\n",
    "#swap index ordering to (PatID, timestep, column) (currently (timestep, column, PatID))\n",
    "data <- aperm(data, c(3,1,2))\n",
    "\n",
    "#make sure they have at least 1 NSAA score \n",
    "# might slightly bias, but we dont really have any proper information otherwise...\n",
    "which_enough = which(apply(!is.na(data[,,N_covs+1]), 1, sum)>0)\n",
    "data = data[which_enough, , ]\n",
    "\n",
    "#shuffle patient order (randomise)\n",
    "data = data[sample(dim(data)[1]),1:dim(data)[2], 1:dim(data)[3]]\n",
    "\n",
    "#subset data for speed reasons\n",
    "init_age = 3\n",
    "final_age = 20\n",
    "N_patients = dim(data)[1] #all of the patients\n",
    "\n",
    "data = data[1:dim(data)[1], (init_age*12/every_x_months):(final_age*12/every_x_months), ]\n",
    "#data = data[c(1,8), (init_age*12/every_x_months):(final_age*12/every_x_months), ]\n",
    "\n",
    "#save full data \n",
    "X_data = data[,,1:N_covs,drop = FALSE]\n",
    "y_data = data[,,(N_covs+1):(N_covs+N_cols),drop = FALSE]\n",
    "save(X_data, y_data,file='y_data.out.RData')\n",
    "#np$save(\"X_data.out.npy\",r_to_py(X_data))\n",
    "#np$save(\"y_data.out.npy\",r_to_py(y_data))\n",
    "\n",
    "#subset N patients as well\n",
    "data = data[1:N_patients, , ]\n",
    "\n",
    "N_timesteps = dim(data)[2]\n",
    "\n",
    "sum(!is.na(data[,,N_covs+1])) #how many data points do we have for NSAA (the first output, use +2 for the second, etc)\n",
    "\n",
    "#get input and output data\n",
    "X_data = data[,,1:N_covs,drop = FALSE]\n",
    "y_data = data[,,(N_covs+1):(N_covs+N_cols),drop = FALSE]\n",
    "\n",
    "#get maximum number of timesteps observed for each patient, for each output\n",
    "N_timesteps_t = matrix(1, nrow = N_patients, ncol = N_cols)\n",
    "for (output in 1:N_cols){\n",
    "  for (n in 1:N_patients){\n",
    "    N_timesteps_t[n, output] = max(which(!is.na(y_data[n,,output])))\n",
    "  }\n",
    "}\n",
    "\n",
    "#replace -Inf with 2 (minimum number of timestpes we'd need for model to actually run\n",
    "N_timesteps_t[N_timesteps_t==-Inf] = 2\n",
    "\n",
    "#Decide which patients/observations are the held-out validation points\n",
    "#We need to hold back certain observations from them, and make the model predict for the whole timeseries for them\n",
    "\n",
    "N_valid = N_patients\n",
    "#delete the second X% of observations for the first set of patients, where X% is random (between 20% and 80%)\n",
    "y_gutted_data = y_data\n",
    "y_valid = y_data\n",
    "for (n in 1:N_valid){\n",
    "  which_notna = which(!is.na(y_data[n,,1]))\n",
    "  how_many_obs = length(which_notna)\n",
    "  Xperc = runif(1, 0.2, 0.8)\n",
    "  keep_up_to = which_notna[floor(how_many_obs*Xperc)]\n",
    "  if (length(keep_up_to)==0){\n",
    "    keep_up_to = 0\n",
    "  }\n",
    "  y_gutted_data[n, (keep_up_to+1):N_timesteps, 1:N_cols] = NA\n",
    "  y_valid[n, 1:(keep_up_to), 1:N_cols] = NA\n",
    "  N_timesteps_t[n, 1:N_cols] = N_timesteps\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "#y_gutted_data[,,1] = NSAA_transformer(y_gutted_data[,,1] )\n",
    "#y_gutted_data[,,2] = positive_transformer(y_gutted_data[,,2] )\n",
    "#y_gutted_data[,,3] = positive_transformer(y_gutted_data[,,3] )\n",
    "\n",
    "#standardise data\n",
    "\n",
    "#don't recalculate this - keeping same sd and means as were in training data\n",
    "X_max = apply(X_data, 3, max, na.rm = TRUE)\n",
    "X_min = apply(X_data, 3, min, na.rm = TRUE)\n",
    "\n",
    "\n",
    "X_scale = (X_max-X_min)\n",
    "X_scale[X_scale == 0] = 1 #prevent NAs if only one value\n",
    "X = sweep(sweep(X_data, 3, X_min, \"-\"), 3, X_scale, \"/\")\n",
    "y_gutted = y_gutted_data\n",
    "\n",
    "\n",
    "time_step_multi <- 12/every_x_months\n",
    "\n",
    "\n",
    "#don't want to be modelling the *observations* at each time point, which nimble mgitht ry to do even for all the NAs\n",
    "#so we flatten y into a 1d array only containing the actual observations\n",
    "#but then we need several arrays which allow us to relearn which patient/timestep/output each eentry is:\n",
    "\n",
    "y_gutted_reshape <- as.numeric(y_gutted)\n",
    "n_matrix <- y_gutted\n",
    "for (n in 1:dim(n_matrix)[1]){\n",
    "  n_matrix[n,,] = n\n",
    "}\n",
    "n_reshape <- as.numeric(n_matrix)\n",
    "\n",
    "t_matrix <- y_gutted\n",
    "for (t in 1:dim(t_matrix)[2]){\n",
    "  t_matrix[,t,] = t\n",
    "}\n",
    "t_reshape <- as.numeric(t_matrix)\n",
    "\n",
    "out_matrix <- y_gutted\n",
    "for (out in 1:dim(out_matrix)[3]){\n",
    "  out_matrix[,,out] = out\n",
    "}\n",
    "out_reshape <- as.numeric(out_matrix)\n",
    "\n",
    "y_gutted_reshape_isna = which(!is.na(y_gutted_reshape))\n",
    "y_gutted_reshape = y_gutted_reshape[y_gutted_reshape_isna]\n",
    "n_reshape = n_reshape[y_gutted_reshape_isna]\n",
    "t_reshape = t_reshape[y_gutted_reshape_isna]\n",
    "out_reshape = out_reshape[y_gutted_reshape_isna]\n",
    "\n",
    "#For hibma mode, we only fit nsaa model, so remove all with outcome != 1\n",
    "y_gutted_reshape_isna = which(!is.na(y_gutted_reshape))\n",
    "y_gutted_reshape = y_gutted_reshape[out_reshape == 1]\n",
    "n_reshape = n_reshape[out_reshape == 1]\n",
    "t_reshape = t_reshape[out_reshape == 1]\n",
    "out_reshape = out_reshape[out_reshape == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a98b546-b0cb-4b1d-b68a-f5058fd770f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit all validation individuals\n",
    "\n",
    "    softplus_nimble <- nimbleFunction(\n",
    "      run = function(x = double(0)){\n",
    "        return(log(1+exp(x)))\n",
    "        returnType(double(0))\n",
    "      })\n",
    "\n",
    "    state_model_consts <- list(N_covs = N_covs, #Number of covariances (something to do with treatments)?\n",
    "                           N_cols = N_cols, #Number of outputs (3)\n",
    "                           N_patients = N_patients, #Number of patients\n",
    "                           X = X,#Something to do with treatments\n",
    "                           N_data = length(y_gutted_reshape), #Number of data points\n",
    "                           n_reshape = n_reshape,#Patient identifiers for each point\n",
    "                           t_reshape = t_reshape,#Time for each point\n",
    "                           out_reshape = out_reshape,#Identifier for output\n",
    "                           timesteps_per_year = 12/every_x_months,\n",
    "                           mature_age_steps = (20-init_age)*12/every_x_months,\n",
    "                           milestone_age_steps = (15-init_age)*12/every_x_months,\n",
    "                               pop_par_mean = pop_par_mean,\n",
    "                               pop_par_cov = pop_par_cov\n",
    "                              )\n",
    "    state_model_data <-  list(y = c(y_gutted_reshape))\n",
    "    Inits = list(parameters = array(pop_par_mean,c(N_patients,10)),\n",
    "                 init_nsaa = array(exp(pop_par_mean[1]),N_patients),\n",
    "                 theta_k_in = array(exp(pop_par_mean[3]),N_patients),\n",
    "                 theta_k_out = array(exp(pop_par_mean[5]),N_patients),\n",
    "                 innov = array(exp(pop_par_mean[7]),N_patients),\n",
    "                 obs_err = array(exp(pop_par_mean[9]),N_patients)\n",
    "                 )\n",
    "                 \n",
    "\n",
    "    Monitors = c('nsaa','y_state','theta_k_out','parameters','theta_k_in','innov','obs_err','RW','init_nsaa')\n",
    "\n",
    "        samples <- nimbleMCMC(code = state_model_code_individual,\n",
    "                   constants = state_model_consts,\n",
    "                   data = state_model_data,\n",
    "                   init = Inits,\n",
    "                   monitors = Monitors,\n",
    "                   niter = 2000000,\n",
    "                   nburnin = 1000000,\n",
    "                   thin = 1000,\n",
    "                   nchains = 2,\n",
    "                   samplesAsCodaMCMC = TRUE)\n",
    "\n",
    "    save(samples,file = paste0('Samples','.RData'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fe4bc7-b072-47c7-8614-decd7f8f1773",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(samples[,'theta_k_out[1]'])\n",
    "plot(samples[,'theta_k_out[2]'])\n",
    "plot(samples[,'innov[3]'])\n",
    "plot(samples[,'obs_err[4]'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79180c9d-cf87-4089-ab70-2eb52f59216a",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_merged <- data.frame(do.call('rbind',samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1460b8c7-01d3-44f0-b737-512f3d9684e0",
   "metadata": {},
   "source": [
    "#### Northstar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620db222-ee4b-4cc3-a68f-afd4f6259a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (load_results == FALSE){\n",
    "\n",
    "softplus_nimble <- nimbleFunction(\n",
    "  run = function(x = double(0)){\n",
    "    return(log(1+exp(x)))\n",
    "    returnType(double(0))\n",
    "  })\n",
    "\n",
    "\n",
    "#plot nsaa trajectory for a patient\n",
    "col_i = 1\n",
    "\n",
    "#counters for checking test points in the intervals\n",
    "test_points_in <- rep(0,99)\n",
    "test_points_tot <- rep(0,99)\n",
    "\n",
    "#observations for sharpnesses at sharpness_interval by number of points\n",
    "sharpness_interval <- 0.95\n",
    "sharpness_interval2 <- 0.7\n",
    "num_points <- array(NA,N_valid)\n",
    "for (individual in 1:N_valid){num_points[individual] = length((1:69)[!is.na(y_gutted_data[individual, , col_i])])}\n",
    "sharpnesses <- array(NA,dim=c(N_valid,max(num_points)+1))\n",
    "sharpnesses2 <- array(NA,dim=c(N_valid,max(num_points)+1))\n",
    "sharpness_count <- array(0,dim=c(max(num_points))+1)\n",
    "\n",
    "\n",
    "for (n in 1:N_valid){\n",
    "   \n",
    "    #extract needed parts from model\n",
    "    N_timesteps_t_max = 69\n",
    "    nsaa = as.matrix(select(select(samples_merged,contains(paste0(\"nsaa.\"))),ends_with(paste0(\"..\",n, \".\"))))\n",
    "    RW = as.matrix(select(samples_merged,contains(paste0(\"RW.\",n, \".\"))))\n",
    "    obs_err = as.matrix(select(samples_merged,contains(paste0(\"obs_err.\",n, \".\"))))\n",
    "\n",
    "    \n",
    "    y_n = nsaa + RW\n",
    "    y_n = y_n + rnorm(length(y_n), 0, obs_err) #add noise\n",
    "    for (iter in 1:2000){\n",
    "        for (time in 1:69){\n",
    "            y_n[iter,time] = min(max(y_n[iter,time],0),34.0000001)\n",
    "        }\n",
    "    }\n",
    "\n",
    "    q_025_n = apply(y_n[,1:69], 2, quantile, 0.025, na.rm = T)\n",
    "    q_15_n = apply(y_n[,1:69], 2, quantile, 0.15, na.rm = T)\n",
    "    q_5_n = apply(y_n[,1:69], 2, quantile, 0.5, na.rm = T)\n",
    "    q_85_n = apply(y_n[,1:69], 2, quantile, 0.85, na.rm = T)\n",
    "    q_975_n = apply(y_n[,1:69], 2, quantile, 0.975, na.rm = T)\n",
    "\n",
    "    time <- init_age+(1:69)*(every_x_months/12)\n",
    "     N_timesteps_t_max = apply(N_timesteps_t,1, max)\n",
    "    \n",
    "    \n",
    "      #Plot\n",
    "    if (plot_preds == TRUE){\n",
    "  print(\n",
    "    #With GP\n",
    "    ggplot() +\n",
    "      geom_ribbon(aes(x=init_age+(1:69)*(every_x_months/12),\n",
    "                      ymin= q_15_n,\n",
    "                      ymax= q_85_n),\n",
    "                  alpha = 0.5,\n",
    "                  xmin=0,\n",
    "                  xmax=270,\n",
    "                  fill = 'lightseagreen')+\n",
    "      geom_ribbon(aes(x=init_age+(1:69)*(every_x_months/12),\n",
    "                      ymin= q_85_n,\n",
    "                      ymax= q_975_n),\n",
    "                  alpha = 0.5,\n",
    "                  xmin=0,\n",
    "                  xmax=270,\n",
    "                  fill = 'lightskyblue')+\n",
    "      geom_ribbon(aes(x=init_age+(1:69)*(every_x_months/12),\n",
    "                      ymin= q_025_n,\n",
    "                      ymax= q_15_n),\n",
    "                  alpha = 0.5,\n",
    "                  xmin=0,\n",
    "                  xmax=270,\n",
    "                  fill = 'lightskyblue')+\n",
    "      geom_line(aes(x=init_age+(1:N_timesteps_t_max[n])*(every_x_months/12), y = q_5_n), col='black',size=3) +#GP posterior mean\n",
    "      geom_point(aes(x=init_age+(1:N_timesteps)*(every_x_months/12), y = y_data[n, , col_i]), size=4, col='red') +#Test points\n",
    "      geom_point(aes(x=init_age+(1:N_timesteps)*(every_x_months/12), y = y_gutted_data[n, , col_i]), size=4, col='blue') +#Design points\n",
    "      #ggtitle(paste(\"Patient\", n ,\"NSAA prediction\"))+\n",
    "      coord_cartesian(ylim = c(0,35), xlim = c(min(time),max(time)))+\n",
    "      labs(x='Years since birth', y='NSAA score')+\n",
    "      theme(text = element_text(size = 25,colour='#003D3C'))\n",
    "  )\n",
    "    ggsave(paste0(\"RERUN_NSAA/NSAA_pred\", n, \".pdf\"))\n",
    "\n",
    "    }\n",
    "          #Check number of test points inside each interval\n",
    "      for (interval in 1:99){#for each interval\n",
    "          upper <- apply(y_n[,1:N_timesteps_t_max[n]], 2, quantile, 1-(1-interval/100)/2, na.rm = T)\n",
    "          lower <-  apply(y_n[,1:N_timesteps_t_max[n]], 2, quantile, (1-interval/100)/2, na.rm = T)\n",
    "          for (point in (1:69)[!is.na(y_data[n, , col_i])]){\n",
    "              \n",
    "              if (y_data[n, point, col_i] < upper[point] & y_data[n, point, col_i] > lower[point] & !(point %in% (1:69)[!is.na(y_gutted_data[n, , col_i])])){\n",
    "                  test_points_in[interval] <- test_points_in[interval] +1\n",
    "              }\n",
    "              \n",
    "              if (!is.na(y_data[n, point, col_i]) & !(point %in% (1:69)[!is.na(y_gutted_data[n, , col_i])])){\n",
    "                  test_points_tot[interval] <- test_points_tot[interval] +1\n",
    "              }\n",
    "          }\n",
    "          #also evaluate sharpness\n",
    "          if (interval/100 == sharpness_interval){\n",
    "              sharpnesses[n,length((1:69)[!is.na(y_gutted_data[n, , col_i])])+1] <- mean(upper-lower)\n",
    "              sharpness_count[length((1:69)[!is.na(y_gutted_data[n, , col_i])])+1] <- sharpness_count[length((1:69)[!is.na(y_gutted_data[n, , col_i])])+1] + 1\n",
    "          }\n",
    "          if (interval/100 == sharpness_interval2){\n",
    "              sharpnesses2[n,length((1:69)[!is.na(y_gutted_data[n, , col_i])])+1] <- mean(upper-lower)\n",
    "          }\n",
    "      }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3949b07a-3690-4c08-9f43-8581c606893d",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results <- TRUE\n",
    "\n",
    "if (load_results == TRUE){\n",
    "    load('NSAA_sharpnesses.RData')\n",
    "    load('sharpness_count.RData')\n",
    "    load('test_points_in.RData')\n",
    "    load('test_points_tot.RData')\n",
    "}\n",
    "\n",
    "\n",
    "#plot quantile coverage\n",
    "ggplot()+\n",
    "    geom_line(aes(x=(1:99)/100, y = (1:99)/100), col='black',size=3)+\n",
    "    geom_line(aes(x=(1:99)/100, y = test_points_in/test_points_tot), col='lightseagreen',size=3)+\n",
    "    labs(x='Prediction Interval', y='Proportion Validation Points Contained')+\n",
    "    theme(text = element_text(size = 25,colour='#003D3C'),legend.position=\"top\")+\n",
    "    scale_color_manual(breaks=c('Model', 'Target'),\n",
    "                     values=c('Model'='lightseagreen', 'Target'='black'))#\n",
    "    ggsave(paste0(\"AnalysisPlots/NSAAQuantileCoverage\", \".pdf\"))\n",
    "\n",
    "#Determine sharpness\n",
    "\n",
    "sharpness_means <- array(NA,dim(sharpnesses)[2])\n",
    "for (no_points_s in 1:dim(sharpnesses)[2]){\n",
    "    sharpness_means[no_points_s] <- mean(sharpnesses[,no_points_s],na.rm = TRUE)\n",
    "}\n",
    "sharpness_means2 <- array(NA,dim(sharpnesses2)[2])\n",
    "for (no_points_s in 1:dim(sharpnesses2)[2]){\n",
    "    sharpness_means2[no_points_s] <- mean(sharpnesses2[,no_points_s],na.rm = TRUE)\n",
    "}\n",
    "\n",
    "print(paste('The sum abs differences from desired quantile coverage is',sum(abs(test_points_in/test_points_tot - (1:99)/100))))\n",
    "\n",
    "sharpness_grouped <- array(NA,4)\n",
    "sharpness_grouped[1] <- sharpness_means[1] * sharpness_count[1] / sum(sharpness_count[1])\n",
    "sharpness_grouped[2] <- sum(sharpness_means[2:4] * sharpness_count[2:4]) / sum(sharpness_count[2:4])\n",
    "sharpness_grouped[3] <- sum(sharpness_means[5:8] * sharpness_count[5:8]) / sum(sharpness_count[5:8])\n",
    "sharpness_grouped[4] <- sum(sharpness_means[9:length(sharpness_means)] * sharpness_count[9:length(sharpness_means)],na.rm=TRUE) / sum(sharpness_count[9:length(sharpness_means)],na.rm=TRUE)\n",
    "print('Grouped together, the 95% mean prediction intervals are:')\n",
    "sharpness_grouped\n",
    "print('MCIDs:')\n",
    "sharpness_grouped/3.5\n",
    "\n",
    "sharpness2_grouped <- array(NA,4)\n",
    "sharpness2_grouped[1] <- sharpness_means2[1] * sharpness_count[1] / sum(sharpness_count[1])\n",
    "sharpness2_grouped[2] <- sum(sharpness_means2[2:4] * sharpness_count[2:4]) / sum(sharpness_count[2:4])\n",
    "sharpness2_grouped[3] <- sum(sharpness_means2[5:8] * sharpness_count[5:8]) / sum(sharpness_count[5:8])\n",
    "sharpness2_grouped[4] <- sum(sharpness_means2[9:length(sharpness_means2)] * sharpness_count[9:length(sharpness_means2)],na.rm=TRUE) / sum(sharpness_count[9:length(sharpness_means2)],na.rm=TRUE)\n",
    "print('Grouped together, the 70% mean prediction intervals are:')\n",
    "sharpness2_grouped\n",
    "print('MCIDs:')\n",
    "sharpness2_grouped/3.5\n",
    "\n",
    "if (save_results == TRUE){\n",
    "    save(sharpnesses,file='NSAA_sharpnesses.RData')\n",
    "    save(sharpness_count,file='sharpness_count.RData')\n",
    "    save(test_points_in,file='test_points_in.RData')\n",
    "    save(test_points_tot,file='test_points_tot.RData')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1d6e61-03e8-411f-94eb-4e41d3011184",
   "metadata": {},
   "source": [
    "## Could also use this model for synthetic data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56f0771-03a9-470b-95ce-c8f1f45f0329",
   "metadata": {},
   "outputs": [],
   "source": [
    "Generate_Trajectory <- function(){\n",
    "    N_covs = N_covs #Number of covariances (something to do with treatments)?\n",
    "                               N_cols = N_cols #Number of outputs (3)\n",
    "                               N_timesteps = 69 #Number of timesteps\n",
    "                               N_timesteps_t = 69 \n",
    "                               N_timesteps_t_max = 69\n",
    "                               N_patients = 1 #Number of patients\n",
    "                               X = X_train[sample(dim(X_train)[1],1),,]#Something to do with treatments\n",
    "                               N_data = length(y_gutted_reshape[n_reshape == individual]) #Number of data points\n",
    "                               n_reshape = rep(1,length(n_reshape[n_reshape == individual]))#Patient identifiers for each point\n",
    "                               t_reshape = as.array(t_reshape[n_reshape == individual])#Time for each point\n",
    "                               out_reshape = as.array(out_reshape[n_reshape == individual])#Identifier for output\n",
    "                               timesteps_per_year = 12/every_x_months\n",
    "                               mature_age_steps = (20-init_age)*12/every_x_months\n",
    "                               milestone_age_steps = (15-init_age)*12/every_x_months\n",
    "    \n",
    "    parameters <- array(NA,10)\n",
    "    parameters[1:10] <- rmvnorm(1,pop_par_mean[1:10],pop_par_cov[1:10,1:10])\n",
    "    \n",
    "        init_nsaa_mean <- exp(parameters[1])\n",
    "        init_nsaa_sd <- exp(parameters[2])\n",
    "        theta_k_in_mean <- exp(parameters[3])\n",
    "        theta_k_in_sd <- exp(parameters[4])\n",
    "        theta_k_out_mean <- exp(parameters[5])\n",
    "        theta_k_out_sd <- exp(parameters[6])\n",
    "        innov_mean <- exp(parameters[7])\n",
    "        innov_sd <- exp(parameters[8])\n",
    "        obs_err_mean <- exp(parameters[9])\n",
    "        obs_err_sd <- exp(parameters[10])\n",
    "\n",
    "        \n",
    "    #init nsaa\n",
    "    #init gradient\n",
    "    nsaa <- array(NA,69)\n",
    "        init_nsaa <- max(rnorm(1,init_nsaa_mean,sd=init_nsaa_sd),0)\n",
    "        nsaa[1] <- init_nsaa\n",
    "\n",
    "  \n",
    "    #theta_k_in\n",
    "        theta_k_in <- max(rnorm(1,theta_k_in_mean,sd=theta_k_in_sd),0)\n",
    " \n",
    "    \n",
    "    #theta_k_out\n",
    "\n",
    "        theta_k_out <- max(rnorm(1,theta_k_out_mean,sd=theta_k_out_sd),0)\n",
    " \n",
    "    \n",
    "    #chain\n",
    "\n",
    "    for (time in 2:69){\n",
    "            #grad[time,individual] <- grad[time-1,individual] + theta_k_in[individual] - (theta_k_out[individual] * time) * nsaa[time-1,individual]\n",
    "            #grad[time,individual] <- theta_k_in[individual] - (theta_k_out[individual] * time) * nsaa[time-1,individual]\n",
    "            nsaa[time] <- nsaa[time-1] + theta_k_in - (theta_k_out * time) * nsaa[time-1]\n",
    "\n",
    "    }\n",
    "    \n",
    "  \n",
    "    #innovation  \n",
    "    #for (output in 1:N_cols) {    \n",
    "        innov <- max(rnorm(1,innov_mean, sd = innov_sd),0)\n",
    "\n",
    "    #}\n",
    "                             \n",
    "  #obs err\n",
    "    #for (output in 1:N_cols) {       \n",
    "        obs_err <- max(rnorm(1,obs_err_mean, sd = obs_err_sd),0)\n",
    "    #}\n",
    "                             \n",
    "  #Random walks\n",
    "  #for (output in 1:N_cols) {\n",
    "    RW <- array(NA,69)\n",
    "      RW[1] <- 0\n",
    "      for (t in 2:69) {\n",
    "        RW[t] <- rnorm(1,RW[t-1], sd = innov)\n",
    "      }\n",
    "  #}\n",
    "\n",
    "  \n",
    "  y_state <- array(NA,c(69))\n",
    "  for (t in 1:69){\n",
    "      y_state[t] <- nsaa[t] + RW[t] + rnorm(1,0,sd=obs_err)\n",
    "  }\n",
    "  for (t in 1:69){\n",
    "      y_state[t] <- max(0,min(34,y_state[t]))\n",
    "  }\n",
    "\n",
    "  return(y_state)\n",
    "\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ac1489-3ef5-49aa-a47b-f27fcc8004d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(MASS)\n",
    "\n",
    "#extracting trajectories\n",
    "\n",
    "    set.seed(10)\n",
    "KL_score <- array(NA,100)\n",
    "LC_score <- array(NA,100)\n",
    "for (synth_run in 1:100){    while(TRUE){ df <- try({\n",
    "        N_synth_trajs <- N_valid\n",
    "        N_show <- 50 #number of trajectories shown in the plots\n",
    "\n",
    "        Synth_trajs <- array(NA,c(N_synth_trajs,69))\n",
    "        for (synth_traj in 1:N_synth_trajs){\n",
    "            Synth_trajs[synth_traj,] <- Generate_Trajectory()\n",
    "        }\n",
    "\n",
    "\n",
    "        #sample initial points\n",
    "        synth_start_time <- array(NA,N_synth_trajs)\n",
    "        for (i in 1:N_synth_trajs){\n",
    "            synth_start_time[i] <- sample(start_points,1)\n",
    "        }\n",
    "        #sampling rates\n",
    "        synth_rate <- array(NA,N_synth_trajs)\n",
    "        for (i in 1:N_synth_trajs){\n",
    "            synth_rate[i] <- round(sample(rates,1))\n",
    "        }\n",
    "        #if it is already at zero, trajectory doesn't exist, so resample\n",
    "        for (i in 1:N_synth_trajs){\n",
    "            no_zeroes <- FALSE\n",
    "            while (no_zeroes == FALSE){\n",
    "                if (Synth_trajs[i,synth_start_time[i]] == 0 | Synth_trajs[i,synth_start_time[i] + synth_rate[i]] == 0){\n",
    "                    Synth_trajs[i,] <- round(Generate_Trajectory())\n",
    "                } else {\n",
    "                    no_zeroes <- TRUE\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        Synth_trajs_reshape <- reshape2::melt(Synth_trajs,varnames=c('individual','time'))\n",
    "        Synth_trajs_reshape_limited <- Synth_trajs_reshape[Synth_trajs_reshape[,1] %in% 1:N_show,]\n",
    "        if (synth_run == 1){\n",
    "            synth_plot <- ggplot(Synth_trajs_reshape_limited) +\n",
    "                geom_line(aes(x=(init_age+(1:N_timesteps)*(every_x_months/12))[time],y=value,group=individual,colour=factor(individual))) +\n",
    "                #theme_bw() +\n",
    "                labs(x='Years since birth', y='NSAA score')+\n",
    "                theme(text = element_text(size = 25,colour='#003D3C'),legend.position=\"none\") +\n",
    "                xlim(3.25,20.25) +\n",
    "                ylim(0,35)\n",
    "            synth_plot\n",
    "                ggsave(\"SynthTrajectoriesExampleStep1.pdf\")\n",
    "            }\n",
    "\n",
    "        #now set initial points\n",
    "        for (i in 1:N_synth_trajs){\n",
    "            Synth_trajs_reshape <- Synth_trajs_reshape[!(Synth_trajs_reshape$individual == i & Synth_trajs_reshape$time < synth_start_time[i]),]\n",
    "        }\n",
    "        Synth_trajs_reshape_limited <- Synth_trajs_reshape[Synth_trajs_reshape[,1] %in% 1:N_show,]\n",
    "        if (synth_run == 1){\n",
    "            synth_plot <- ggplot(Synth_trajs_reshape_limited) +\n",
    "                geom_line(aes(x=(init_age+(1:N_timesteps)*(every_x_months/12))[time],y=value,group=individual,colour=factor(individual))) +\n",
    "                #theme_bw() +\n",
    "                labs(x='Years since birth', y='NSAA score')+\n",
    "                theme(text = element_text(size = 25,colour='#003D3C'),legend.position=\"none\") +\n",
    "                xlim(3.25,20.25) +\n",
    "                ylim(0,35)\n",
    "            synth_plot\n",
    "                ggsave(\"SynthTrajectoriesExampleStep2.pdf\")\n",
    "        }\n",
    "\n",
    "        #now do regularities\n",
    "        for (i in 1:N_synth_trajs){\n",
    "            Synth_trajs_reshape <- Synth_trajs_reshape[!(Synth_trajs_reshape$individual == i & Synth_trajs_reshape$time %in% (synth_start_time[i]+synth_rate[i]*(1:69))),]\n",
    "        }\n",
    "        Synth_trajs_reshape_limited <- Synth_trajs_reshape[Synth_trajs_reshape[,1] %in% 1:N_show,]\n",
    "        if (synth_run == 1){\n",
    "            synth_plot <- ggplot(Synth_trajs_reshape_limited) +\n",
    "                geom_line(aes(x=(init_age+(1:N_timesteps)*(every_x_months/12))[time],y=value,group=individual,colour=factor(individual))) +\n",
    "                #theme_bw() +\n",
    "                labs(x='Years since birth', y='NSAA score')+\n",
    "                theme(text = element_text(size = 25,colour='#003D3C'),legend.position=\"none\") +\n",
    "                xlim(3.25,20.25) +\n",
    "                ylim(0,35)\n",
    "            synth_plot\n",
    "                ggsave(\"SynthTrajectoriesExampleStep3.pdf\")\n",
    "            }\n",
    "    \n",
    "\n",
    "\n",
    "        #stopping points\n",
    "        last_point <- array(FALSE,dim(Synth_trajs_reshape)[1])\n",
    "            for (i in 1:grid_height){\n",
    "                for (j in 1:grid_width){\n",
    "                    #Find box locations\n",
    "                    age_min <- (j-1)*70/grid_width\n",
    "                    age_max <- j*70/grid_width\n",
    "                    nsaa_min <- (i-1)*35/grid_height\n",
    "                    nsaa_max <- i*35/grid_height\n",
    "                    for (point in 1:dim(Synth_trajs_reshape)[1]){\n",
    "                        if (Synth_trajs_reshape$time[point] <= age_max & Synth_trajs_reshape$time[point] > age_min & Synth_trajs_reshape$value[point] <= nsaa_max & Synth_trajs_reshape$value[point] > nsaa_min){\n",
    "                            last_point[point] <- sample(c(TRUE,FALSE),1,prob=c(stopping_grid[i,j],1-stopping_grid[i,j]))\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        #remove points after these points\n",
    "        remove_points <- c()\n",
    "        for (point in 1:dim(Synth_trajs_reshape)[1]){\n",
    "            if (last_point[point] == TRUE){\n",
    "                for (point2 in 1:dim(Synth_trajs_reshape)[1]){\n",
    "                    if (Synth_trajs_reshape$individual[point2] == Synth_trajs_reshape$individual[point] & Synth_trajs_reshape$time[point2] > Synth_trajs_reshape$time[point]){\n",
    "                        remove_points <- append(remove_points,point2)\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "            if (Synth_trajs_reshape$value[point] == 0){\n",
    "                for (point2 in 1:dim(Synth_trajs_reshape)[1]){\n",
    "                    if (Synth_trajs_reshape$individual[point2] == Synth_trajs_reshape$individual[point] & Synth_trajs_reshape$time[point2] >= Synth_trajs_reshape$time[point]){\n",
    "                        remove_points <- append(remove_points,point2)\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        Synth_trajs_reshape <- Synth_trajs_reshape[! (1:dim(Synth_trajs_reshape)[1] %in% remove_points),]\n",
    "        Synth_trajs_reshape_limited <- Synth_trajs_reshape[Synth_trajs_reshape[,1] %in% 1:N_show,]\n",
    "            if (synth_run == 1){\n",
    "        synth_plot <- ggplot(Synth_trajs_reshape_limited) +\n",
    "            geom_line(aes(x=(init_age+(1:N_timesteps)*(every_x_months/12))[time],y=value,group=individual,colour=factor(individual))) +\n",
    "            #theme_bw() +\n",
    "            labs(x='Years since birth', y='NSAA score')+\n",
    "            theme(text = element_text(size = 25,colour='#003D3C'),legend.position=\"none\") +\n",
    "            xlim(3.25,20.25) +\n",
    "            ylim(0,35)\n",
    "        synth_plot\n",
    "            ggsave(\"SynthTrajectoriesExampleStep4.pdf\")\n",
    "                }\n",
    "\n",
    "        #combine fake and real trajectories\n",
    "        y_data_reshape <- reshape2::melt(unname(y_data[,,1]),varnames=c('id','age'))[!is.na(reshape2::melt(unname(y_data[,,1]),varnames=c('id','age'))$value),]\n",
    "        y_data_reshape$real <- TRUE\n",
    "        y_test_real_reshape <- reshape2::melt(unname(y_gutted_data[, , 1]),varnames=c('id','age'))[!is.na(reshape2::melt(unname(y_gutted_data[, , 1]),varnames=c('id','age'))$value),]\n",
    "        y_test_real_reshape$real <- TRUE\n",
    "        Synth_trajs_reshape$real <- FALSE\n",
    "        names(Synth_trajs_reshape) = c('id','age','value','real')\n",
    "        Synth_trajs_reshape$id <- Synth_trajs_reshape$id + max(y_test_real_reshape$id,y_data_reshape$id)\n",
    "\n",
    "        Trajs_together <- rbind(y_data_reshape,y_test_real_reshape,Synth_trajs_reshape)\n",
    "\n",
    "        ng = 4\n",
    "\n",
    "        # Run latent class model (takes time)\n",
    "        LatC8 <- lcmm(value ~ age + I(age^2), mixture=~age, maxiter = 1000, idiag = TRUE, subject='id', ng=ng, data=Trajs_together)\n",
    "\n",
    "       pred_ages = seq(1, max(Trajs_together$age,na.rm = TRUE),length=max(Trajs_together$age,na.rm = TRUE))\n",
    "        dn <- data.frame(age=pred_ages)\n",
    "        lcT8 <- predictY(LatC8, newdata = dn, var.time = \"age\", draws = TRUE)\n",
    "        lcT8$age <- dn$age\n",
    "\n",
    "        classes <- LatC8$pprob$class\n",
    "        patNum <- LatC8$pprob$id\n",
    "\n",
    "        tmp <- do.call(rbind, Map(data.frame, A=classes, B=patNum))\n",
    "\n",
    "        lcT <- lcT8\n",
    "        times = lcT$times[,1]\n",
    "        pred = lcT$pred\n",
    "        pred = data.frame(pred)\n",
    "\n",
    "        group.colors <- c(\"Class 1\" = \"red\", \"Class 2\" = \"yellow\", \"Class 3\" =\"blue\", \"Class 4\" = \"darkgreen\")\n",
    "\n",
    "        i = 1\n",
    "        for (x in tmp[[\"B\"]]){\n",
    "            Trajs_together[Trajs_together$id == x, \"labels\"] = tmp[[\"A\"]][i]\n",
    "            i = i +1\n",
    "        }\n",
    "\n",
    "        #need to remove patIDNum to maintain consistency with kmeans output\n",
    "        #Trajs_together = select(Trajs_together, -id)\n",
    "\n",
    "        #and make classes 0-3 rather than 1-4, again for kmeans consistency\n",
    "        Trajs_together[\"labels\"] = Trajs_together[\"labels\"] -1 \n",
    "\n",
    "        data <- Trajs_together[which(!is.na(Trajs_together$labels)),] #remove na classes (why do these exist?)\n",
    "\n",
    "        data$labels <- as.factor(data$labels)\n",
    "        levels(data$labels) <- c(\"Class 4\", \"Class 3\", \"Class 2\", \"Class 1\")\n",
    "\n",
    "\n",
    "        data.real <- data[data[,4] == TRUE,]\n",
    "        data.synth <- data[data[,4] == FALSE,]\n",
    "\n",
    "        #For first run only, we plot synthetic and real data\n",
    "            if (synth_run == 1){\n",
    "        print(\n",
    "        ggplot(data)+\n",
    "            geom_line(aes(x=init_age+age*(every_x_months/12), y= value, group = id, color = labels))+\n",
    "            xlab(\"age\")+\n",
    "            scale_color_manual(values=group.colors)+\n",
    "            theme(legend.position = \"none\",\n",
    "            axis.text=element_text(size=16),\n",
    "            axis.title=element_text(size=16))+\n",
    "            ylab(\"NSAA\")+\n",
    "            xlab(\"Age (Years)\")+\n",
    "            coord_cartesian(xlim=c(3,20.25),ylim=c(0,35)))\n",
    "            #ggtitle('Groupings of both real and synthetic data together'))\n",
    "            #coord_cartesian(xlim=c(0, 69),ylim=c(-3,3))+\n",
    "            #scale_y_continuous(breaks=seq(0,35,5), limits = c(0, 35))\n",
    "        ggsave(\"NSAA_prediction_plots/data_all_clustered.out.png\",width = 16, height = 14, units = \"cm\")\n",
    "\n",
    "        print(\n",
    "        ggplot(data.real)+\n",
    "            geom_line(aes(x=init_age+age*(every_x_months/12), y= value, group = id, color = labels))+\n",
    "            xlab(\"age\")+\n",
    "            scale_color_manual(values=group.colors)+\n",
    "            theme(legend.position = \"none\",\n",
    "            axis.text=element_text(size=16),\n",
    "            axis.title=element_text(size=16))+\n",
    "            ylab(\"NSAA\")+\n",
    "            xlab(\"Age (Years)\")+\n",
    "            coord_cartesian(xlim=c(3,20.25),ylim=c(0,35)))\n",
    "            #ggtitle('Groupings of real data'))\n",
    "            #coord_cartesian(xlim=c(0, 69),ylim=c(-3,3))+\n",
    "            #scale_y_continuous(breaks=seq(0,35,5), limits = c(0, 35))\n",
    "        ggsave(\"NSAA_prediction_plots/data_real_clustered.out.png\",width = 16, height = 14, units = \"cm\")\n",
    "\n",
    "        print(\n",
    "        ggplot(data.synth)+\n",
    "            geom_line(aes(x=init_age+age*(every_x_months/12), y= value, group = id, color = labels))+\n",
    "            xlab(\"age\")+\n",
    "            scale_color_manual(values=group.colors)+\n",
    "            theme(legend.position = \"none\",\n",
    "            axis.text=element_text(size=16),\n",
    "            axis.title=element_text(size=16))+\n",
    "            ylab(\"NSAA\")+\n",
    "            xlab(\"Age (Years)\")+\n",
    "            coord_cartesian(xlim=c(3,20.25),ylim=c(0,35)))\n",
    "            #ggtitle('Groupings of synthetic data')\n",
    "            #coord_cartesian(xlim=c(0, 69),ylim=c(-3,3))+\n",
    "            #scale_y_continuous(breaks=seq(0,35,5), limits = c(0, 35))\n",
    "               ggsave(\"NSAA_prediction_plots/data_synth_clustered.out.png\",width = 16, height = 14, units = \"cm\")\n",
    "    }\n",
    "\n",
    "        classifications <- data.frame(patNum,classes)\n",
    "        classifications.real <- classifications[patNum <= max(n_reshape[out_reshape==1]),]\n",
    "        classifications.synth <- classifications[patNum > max(n_reshape[out_reshape==1]),]\n",
    "\n",
    "        g.real <- array(NA,4)\n",
    "        g.synth <- array(NA,4)\n",
    "        for (group in 1:ng){\n",
    "            g.real[group] <- length(rep(1:dim(classifications.real)[1])[classifications.real$classes==group])\n",
    "            g.synth[group] <- length(rep(1:dim(classifications.synth)[1])[classifications.synth$classes==group])\n",
    "        }\n",
    "\n",
    "        LC_score[synth_run] <- log((1/ng) * sum((g.real/(g.real+g.synth) - sum(g.real)/(sum(g.real)+sum(g.synth)))^2))\n",
    "\n",
    "\n",
    "\n",
    "        esti1 <- kde2d(data.real$age,data.real$value,lims=c(0,69,0,35))\n",
    "        esti1df <- expand.grid(X=esti1$x, Y=esti1$y)\n",
    "        esti1df$Z <- c(esti1$z)\n",
    "\n",
    "        esti2 <- kde2d(data.synth$age,data.synth$value,lims=c(0,69,0,35))\n",
    "        esti2df <- expand.grid(X=esti2$x, Y=esti2$y)\n",
    "        esti2df$Z <- c(esti2$z)\n",
    "\n",
    "\n",
    "        KL_score[synth_run] <- KL(rbind(c(esti1$z)/sum(c(esti1$z)),c(esti2$z)/sum(c(esti2$z))))\n",
    "\n",
    "    })\n",
    "    if(!is(df, 'try-error')) break }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5c2059-db6f-44c3-9f97-64ac1bfdcb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(KL_score)\n",
    "mean(LC_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
