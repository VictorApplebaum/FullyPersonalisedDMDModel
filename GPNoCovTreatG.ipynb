{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "above-scout",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Build a basic version of our model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1976b6df-23df-4cc5-95fc-cdcfe31c5328",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amber-effort",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(caret)\n",
    "library(dplyr) #install.packages(\"tidyverse\")\n",
    "library(tidyr) \n",
    "library(ggplot2)\n",
    "library(purrr)  \n",
    "library(zoo) #install.packages(\"zoo\")\n",
    "library(parallel)\n",
    "library(nimble) #install.packages(\"nimble\")\n",
    "library(abind) #install.packages(\"abind\")\n",
    "library(coda)\n",
    "#library(caret) #install.packages(\"caret\")\n",
    "library(reticulate) #install.packages(\"reticulate\")\n",
    "library(data.table) #install.packages(\"data.table)\n",
    "use_python(\"/usr/bin/python3\")\n",
    "#np = import(\"numpy\") #py_install(\"numpy\")\n",
    "#pd = import(\"pandas\") #py_install(\"pandas\")\n",
    "\n",
    "library(lcmm)\n",
    "\n",
    ".libPaths('~/R_packages')\n",
    "\n",
    "library(philentropy)\n",
    "library(plgp)\n",
    "\n",
    "\n",
    "\n",
    "setwd('~/northstar-trajectories/HierarchicalGaussianProcess/091023Run/GPNoCovTreat')\n",
    "\n",
    "set.seed(12345)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dress-marijuana",
   "metadata": {},
   "source": [
    "## Load in Data (and tidy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "burning-excitement",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read.csv(file = 'in.csv')\n",
    "#N_data_used = 1000\n",
    "#data = data[0:N_data_used,]\n",
    "\n",
    "N_patients_pre_split = length(unique(data$PatID))\n",
    "N_valid = round(0.3*N_patients_pre_split) #30% of patients become the validaiton patients (data is pre-randomised)\n",
    "validation_pats = unique(data$PatID)[1:N_valid]\n",
    "training_pats = unique(data$PatID)[(N_valid+1):N_patients_pre_split]\n",
    "\n",
    "data_validation = data[data$PatID %in% validation_pats,]\n",
    "data = data[data$PatID %in% training_pats,]\n",
    "\n",
    "#FIt model from scratch, or load in previously obtained model fits? \n",
    "#(The latter requires the data and inputs to not have been changed, but does allow new plots and predictions to be done)\n",
    "Fit_from_scratch = FALSE\n",
    "load_results <- FALSE\n",
    "plot_preds <- TRUE\n",
    "save_results <- TRUE\n",
    "\n",
    "#which columns do we want in the model?\n",
    "inputs =  c(\"steroids_regime\")\n",
    "outputs = c(\"Calculated_nsaa_score\", \"nsaa_walk_time\", \"nsaa_rise_from_floor_time\")\n",
    "\n",
    "#make data in terms of 3 month intervals\n",
    "every_x_months = 3\n",
    "data$fup_age_at_date_of_assessment = round(data$fup_age_at_date_of_assessment/every_x_months)\n",
    "\n",
    "#Delete rows where the patients age aren't known (alternatively, we could re-infer it from the time?)\n",
    "data = data[!is.na(data$fup_age_at_date_of_assessment), ]\n",
    "\n",
    "#fill in missing timesteps (monthly)\n",
    "data = complete(data, fup_age_at_date_of_assessment = 0:(25*12/every_x_months), nesting(PatID))\n",
    "\n",
    "#also make sure we only have one data row per patID per appointment time:\n",
    "data = data %>%\n",
    "  group_by(PatID, fup_age_at_date_of_assessment) %>%\n",
    "  filter(row_number()==1) %>%\n",
    "  ungroup()\n",
    "\n",
    "#inputs (i.e. treatments / X in the model) cannot have any missing values at any time step.\n",
    "#This shouldn't be a problem as they dont need to be specially observed (clinicians should be dictating them)\n",
    "#but they may not have been written down for each timestep\n",
    "\n",
    "#sometimes data steroids is input as \"\" rather than NA\n",
    "data$steroids_used[which(data$steroids_used == \"\")] = NA\n",
    "data$steroids_regime[which(data$steroids_regime == \"\")] = NA\n",
    "\n",
    "#for the treatments, which we don't expect to change regularly, use the previous value if there is one\n",
    "data <- data %>% group_by(PatID) %>%\n",
    "  fill(age_at_km_steroids_start, .direction = \"downup\") %>%\n",
    "  fill(names(select(data, all_of(c(inputs, \"steroids_dose\")))), .direction = \"down\") %>%\n",
    "  dplyr::ungroup()\n",
    "\n",
    "#if the patient's age is after the age they started steroids, we can also use later values to interpolate\n",
    "#Note that this will only do so if the date they started steroids is recorded (at any point, and is why its interpolated up and down earlier)\n",
    "data <- data %>% group_by(PatID) %>%\n",
    "  mutate(steroids_dose = ifelse(is.na(steroids_dose) & fup_age_at_date_of_assessment> age_at_km_steroids_start, na.locf(steroids_dose, fromLast = TRUE), steroids_dose)) %>%\n",
    "  mutate(steroids_used = ifelse(is.na(steroids_used) & fup_age_at_date_of_assessment> age_at_km_steroids_start, na.locf(steroids_used, fromLast = TRUE, coredata = TRUE), steroids_used)) %>%\n",
    "  mutate(steroids_regime = ifelse(is.na(steroids_regime) & fup_age_at_date_of_assessment> age_at_km_steroids_start, na.locf(steroids_regime, fromLast = TRUE, coredata = TRUE), steroids_regime)) %>%\n",
    "  dplyr::ungroup()\n",
    "\n",
    "#and if any steroids dose are still NA, make them 0\n",
    "data <- data %>% mutate(steroids_dose = replace_na(steroids_dose, 0))\n",
    "#and then, if any steroids dose are 0, force the other steroid information to be NA\n",
    "data$steroids_used[data$steroids_dose == 0] = NA\n",
    "data$steroids_regime[data$steroids_dose == 0] = NA\n",
    "\n",
    "#for the other steroid information, replace NA with \"Unknown\" if steroids dose > 0, and \"None\" if steroids_dose = 0\n",
    "which_missing_used = is.na(data$steroids_used) & (data$steroids_dose > 0)\n",
    "which_none_used = is.na(data$steroids_used) & (data$steroids_dose == 0)\n",
    "which_missing_regime = is.na(data$steroids_regime) & (data$steroids_dose > 0)\n",
    "which_none_regime = is.na(data$steroids_regime) & (data$steroids_dose == 0)\n",
    "\n",
    "data$steroids_used <- as.character(data$steroids_used)\n",
    "data$steroids_used[which_none_used] = \"None\"\n",
    "if(sum(which_missing_used) > 0){\n",
    "  data$steroids_used[which_missing_used] = \"Unknown\"\n",
    "}\n",
    "\n",
    "data$steroids_regime <- as.character(data$steroids_regime)\n",
    "data$steroids_regime[which_none_regime] = \"None\"\n",
    "if(sum(which_missing_regime) > 0){\n",
    "  data$steroids_regime[which_missing_regime] = \"Unknown\"\n",
    "}\n",
    "\n",
    "\n",
    "#convert other information to factors, and force \"no steroids\" to be the baseline intercept\n",
    "data$steroids_used <- as.factor(data$steroids_used)\n",
    "data$steroids_used <- relevel(data$steroids_used, \"None\") #make \"None\" first\n",
    "data$steroids_regime <- as.factor(data$steroids_regime)\n",
    "data$steroids_regime <- relevel(data$steroids_regime, \"None\") #make \"None\" first\n",
    "\n",
    "\n",
    "#sometimes a walk time or rise time of 0 is recorded. This is impossible, so replace with NA\n",
    "\n",
    "data$nsaa_walk_time[which(data$nsaa_walk_time == 0)] = NA\n",
    "data$nsaa_rise_from_floor_time[which(data$nsaa_rise_from_floor_time == 0)] = NA\n",
    "\n",
    "#convert dataframe into 3d arrays (time, patient, column)\n",
    "N_patients = n_distinct(data$PatID)\n",
    "N_timesteps = n_distinct(data$fup_age_at_date_of_assessment)\n",
    "\n",
    "#which columns do we want (first set should be PatID and fup_age, second should be inputs, third should be outputs)\n",
    "data <-select(data, all_of(c(c(\"PatID\", \"fup_age_at_date_of_assessment\"), inputs, outputs)))\n",
    "\n",
    "#change format of data to allow conversion\n",
    "data = arrange(data, PatID, fup_age_at_date_of_assessment)\n",
    "data$PatID <- as.integer(as.numeric(factor(data$PatID)))\n",
    "data = data.frame(data)\n",
    "\n",
    "#convert categorical variables to one hot variables (\"None\" is the base example)\n",
    "dmy <- dummyVars(\" ~ .\", data = data, fullRank = TRUE)\n",
    "data <- data.frame(predict(dmy, newdata = data))\n",
    "\n",
    "N_cols = dim(select(data,contains(outputs)))[2] #number of outputs\n",
    "N_covs = dim(select(data,contains(inputs)))[2] #number of inputs\n",
    "Xnames = colnames(data)[2+(1:N_covs)] #names of covariates (for posterity)\n",
    "\n",
    "#convert to 3d array\n",
    "data <- data %>%\n",
    "  nest(-PatID) %>%    # collapse other columns to list column of data frames\n",
    "  mutate(data = map(data, ~as.matrix(.x[-1]))) %>%    # drop dates from nested data frames and coerce each to matrix\n",
    "  pull(data) %>%    # extract matrix list\n",
    "  invoke(abind::abind, ., along = 3) %>%    # abind in 3rd dimension\n",
    "  `dimnames<-`(list(as.character(unique(data$fup_age_at_date_of_assessment)), names(data)[3:(3+N_cols+N_covs-1)], unique(data$PatID)))    # set dimnames properly\n",
    "\n",
    "#swap index ordering to (PatID, timestep, column) (currently (timestep, column, PatID))\n",
    "data <- aperm(data, c(3,1,2))\n",
    "\n",
    "#make sure they have at least 1 NSAA score \n",
    "# might slightly bias, but we dont really have any proper information otherwise...\n",
    "which_enough = which(apply(!is.na(data[,,N_covs+1]), 1, sum)>0)\n",
    "data = data[which_enough, , ]\n",
    "\n",
    "#shuffle patient order (randomise)\n",
    "data = data[sample(dim(data)[1]),1:dim(data)[2], 1:dim(data)[3]]\n",
    "\n",
    "#subset data for speed reasons\n",
    "init_age = 3\n",
    "final_age = 20\n",
    "N_patients = dim(data)[1] #all of the patients\n",
    "\n",
    "data = data[1:dim(data)[1], (init_age*12/every_x_months):(final_age*12/every_x_months), ]\n",
    "#data = data[c(1,8), (init_age*12/every_x_months):(final_age*12/every_x_months), ]\n",
    "\n",
    "#save full data \n",
    "X_data = data[,,1:N_covs,drop = FALSE]\n",
    "y_data = data[,,(N_covs+1):(N_covs+N_cols),drop = FALSE]\n",
    "save(X_data, y_data,file='y_data.out.RData')\n",
    "#np$save(\"X_data.out.npy\",r_to_py(X_data))\n",
    "#np$save(\"y_data.out.npy\",r_to_py(y_data))\n",
    "\n",
    "#subset N patients as well\n",
    "data = data[1:N_patients, , ]\n",
    "\n",
    "N_timesteps = dim(data)[2]\n",
    "\n",
    "sum(!is.na(data[,,N_covs+1])) #how many data points do we have for NSAA (the first output, use +2 for the second, etc)\n",
    "\n",
    "#get input and output data\n",
    "X_data = data[,,1:N_covs,drop = FALSE]\n",
    "y_data = data[,,(N_covs+1):(N_covs+N_cols),drop = FALSE]\n",
    "\n",
    "#get maximum number of timesteps observed for each patient, for each output\n",
    "N_timesteps_t = matrix(1, nrow = N_patients, ncol = N_cols)\n",
    "for (output in 1:N_cols){\n",
    "  for (n in 1:N_patients){\n",
    "    N_timesteps_t[n, output] = max(which(!is.na(y_data[n,,output])))\n",
    "  }\n",
    "}\n",
    "\n",
    "#replace -Inf with 2 (minimum number of timestpes we'd need for model to actually run\n",
    "N_timesteps_t[N_timesteps_t==-Inf] = 2\n",
    "\n",
    "#Decide which patients/observations are the held-out validation points\n",
    "#We need to hold back certain observations from them, and make the model predict for the whole timeseries for them\n",
    "\n",
    "N_valid = round(0.2*N_patients) #20% of patients become the validaiton patients\n",
    "#delete the second X% of observations for the first set of patients, where X% is random (between 20% and 80%)\n",
    "y_gutted_data = y_data\n",
    "y_valid = y_data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#transform the data\n",
    "NSAA_transformer <- function(y){\n",
    "  ytrans = y\n",
    "  ytrans = logit( (ytrans + 0.5)/35) #convert -0.5 to 34.5 range to real range \n",
    "  return(ytrans)\n",
    "}\n",
    "\n",
    "positive_transformer <- function(y){\n",
    "  ytrans = y\n",
    "  ytrans = log(exp(ytrans)-1) #convert positive range to real range\n",
    "    \n",
    "  #make any values that are now inf what they were from y (its just a numerical issue caused by exp(big value)):\n",
    "  ytrans[which(ytrans == Inf)] = y[which(ytrans == Inf)]\n",
    "  return(ytrans)\n",
    "}\n",
    "\n",
    "NSAA_itransformer <- function(y){\n",
    "  ytrans = y\n",
    "  ytrans = ilogit(ytrans)*35 - 0.5  #convert real range to -0.5 to 34.5 range \n",
    "  return(ytrans)\n",
    "}\n",
    "\n",
    "positive_itransformer <- function(y){\n",
    "  ytrans = y\n",
    "  ytrans = log(1+exp(ytrans)) #convert real range to positive range\n",
    "    \n",
    "  #make any values that are now inf what they were from y (its just a numerical issue caused by exp(big value)):\n",
    "  ytrans[which(ytrans == Inf)] = y[which(ytrans == Inf)]\n",
    "  return(ytrans)\n",
    "}\n",
    "\n",
    "y_gutted_data[,,1] = NSAA_transformer(y_gutted_data[,,1] )\n",
    "y_gutted_data[,,2] = positive_transformer(y_gutted_data[,,2] )\n",
    "y_gutted_data[,,3] = positive_transformer(y_gutted_data[,,3] )\n",
    "\n",
    "#standardise data\n",
    "X_max = apply(X_data, 3, max, na.rm = TRUE)\n",
    "X_min = apply(X_data, 3, min, na.rm = TRUE)\n",
    "y_mean = apply(y_gutted_data, 3, mean, na.rm = TRUE)\n",
    "y_sd = apply(y_gutted_data, 3, sd, na.rm = TRUE)\n",
    "\n",
    "X_scale = (X_max-X_min)\n",
    "X_scale[X_scale == 0] = 1 #prevent NAs if only one value\n",
    "X = sweep(sweep(X_data, 3, X_min, \"-\"), 3, X_scale, \"/\")\n",
    "y_gutted = sweep(sweep(y_gutted_data, 3, y_mean, \"-\"), 3, y_sd, \"/\")\n",
    "\n",
    "\n",
    "time_step_multi <- 12/every_x_months\n",
    "\n",
    "#save standardisation values\n",
    "save(X_min, X_max, y_mean, y_sd,file='stand_vals.out.RData')\n",
    "#np$save(\"X_min.out.npy\",r_to_py(X_min))\n",
    "#np$save(\"X_max.out.npy\",r_to_py(X_max))\n",
    "#np$save(\"y_mean.out.npy\",r_to_py(y_mean))\n",
    "#np$save(\"y_sd.out.npy\",r_to_py(y_sd))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277017ff-35e5-4929-94f7-53ac4c5bc9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "solveLeastSquares <- nimbleFunction(\n",
    "    run = function(X = double(2), y = double(1)) { # type declarations\n",
    "        ans <- inverse(t(X) %*% X) %*% (t(X) %*% y)\n",
    "        return(ans)\n",
    "        returnType(double(2))  # return type declaration\n",
    "    } )## Create Nimble Model (Code for the Bayesian Hierarchical Model)\n",
    "#get Nimble Model\n",
    "state_model_code <- nimbleCode({\n",
    "    \n",
    "  #the effect of treatments (gamma)\n",
    "  for (cov in 1:(N_covs)) {\n",
    "    cov_unscaled_mean[cov] ~ dnorm(-8, sd = 2)\n",
    "    cov_unscaled_sd[cov] ~ T(dnorm(0, sd = 1),0,)\n",
    "    for (n in 1:N_patients) {\n",
    "      cov_effect_unscaled[n, cov] ~ dnorm(cov_unscaled_mean[cov], sd = cov_unscaled_sd[cov])\n",
    "      cov_effect[n,cov] <- softplus_nimble(cov_effect_unscaled[n,cov])\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  #total up these effects (not essential code, just clearer\n",
    "  for (n in 1:N_patients) {\n",
    "    Treat[n, 1] <-  0\n",
    "    for (t in 2:N_timesteps_t_max[n]) {\n",
    "      Treat[n, t] <-  inprod( (cov_effect[n,1:(N_covs)]), X[n, t - 1, 1:(N_covs)])  \n",
    "    }\n",
    "  }\n",
    "  \n",
    "  #disease rate of decay\n",
    "  Delta_unscaled_mean ~ dnorm(0, sd = 1)\n",
    "  Delta_unscaled_sd ~ T(dnorm(0, sd = 1), 0, )\n",
    "  for (n in 1:N_patients){\n",
    "    Delta_unscaled[n] ~ dnorm(Delta_unscaled_mean, sd = Delta_unscaled_sd)\n",
    "    Delta[n] <- softplus_nimble(Delta_unscaled[n])\n",
    "  }\n",
    "  \n",
    "  #initial disease state (phi)\n",
    "  #When disease = 0?\n",
    "   \n",
    "  init_disease_when_mean ~ dnorm(20, sd = 5)\n",
    "  init_disease_when_sd ~ T(dnorm(0, sd = 5), 0, )\n",
    "  for (n in 1:N_patients) {        \n",
    "    init_disease_when_unscaled[n] ~dnorm(init_disease_when_mean, sd = init_disease_when_sd)\n",
    "    init_disease_when[n] <- init_disease_when_unscaled[n]\n",
    "  }\n",
    "  \n",
    "  #calculate what the initial disease is for each patient\n",
    "  for (n in 1:N_patients) {        \n",
    "    disease[n,1] <- -init_disease_when[n]*Delta[n]\n",
    "  }  \n",
    "  #disease states (phi:)\n",
    "  for (n in 1:N_patients) {        \n",
    "    for (t in 2:N_timesteps_t_max[n]) {\n",
    "      disease[n, t] <- disease[n, t - 1]  + Delta[n] - Treat[n, t] \n",
    "    }\n",
    "  }\n",
    "  \n",
    "  \n",
    "  #how disease affects the different outputs\n",
    "  for (output in 1:N_cols) {\n",
    "    beta_1_unscaled_mean[output] ~ dnorm(0, sd = 1)\n",
    "    beta_1_unscaled_sd[output] ~ T(dnorm(0, sd = 1), 0, )\n",
    "  }\n",
    "  for (n in 1:N_patients) {\n",
    "      for (output in 1:N_cols){\n",
    "        beta_1_unscaled[n, output] ~ dnorm(beta_1_unscaled_mean[output], beta_1_unscaled_sd[output])\n",
    "      }\n",
    "  }\n",
    "  \n",
    "  #the first beta_1 can be set to 1 (note that this means, technically, the beta_params could have been 1 fewer above\n",
    "  #but nimble doesnt like 1D correlation matrices, even tho its possible)\n",
    "  for (n in 1:N_patients) {\n",
    "    beta_1[n, 1] <- 1\n",
    "  } \n",
    "  for (output in 2:N_cols) {\n",
    "    for (n in 1:N_patients) {\n",
    "      beta_1[n, output] <- beta_1_unscaled[n, output]\n",
    "    } \n",
    "  }\n",
    "  \n",
    "  \n",
    "  #shape parameter for how healthy state changes over time\n",
    "  for (output in 1:N_cols) {\n",
    "    alpha_1_unscaled_mean[output] ~ dnorm(0, sd = 3) \n",
    "    alpha_1_unscaled_sd[output] ~ T(dnorm(0, sd = 1), 0, )\n",
    "  }\n",
    "  for (n in 1:N_patients) {\n",
    "      for (output in 1:N_cols){\n",
    "        alpha_1_unscaled[n, output] ~ dnorm(alpha_1_unscaled_mean[output], alpha_1_unscaled_sd[output])\n",
    "      }\n",
    "  }\n",
    "  for (output in 1:N_cols){\n",
    "    for (n in 1:N_patients){\n",
    "      alpha_1[n, output] <- ilogit(alpha_1_unscaled[n, output])\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  #healthy state at mature age\n",
    "  for (output in 1:N_cols) {\n",
    "    mature_state_mean[output] ~ dnorm(mature_prior_mean[output], sd = mature_prior_mean_conf[output])\n",
    "    mature_state_sd[output] ~ T(dnorm(mature_prior_spread[output], sd = mature_prior_spread_conf[output]), 0, )\n",
    "  }\n",
    "  for (n in 1:N_patients) {\n",
    "      for (output in 1:N_cols){\n",
    "        mature_state[n, output] ~ dnorm(mature_state_mean[output], mature_state_sd[output])\n",
    "      }\n",
    "  }\n",
    "  \n",
    "  \n",
    "  \n",
    "  #initial healthy state (theta)\n",
    "  for (output in 1:N_cols) {\n",
    "    init_state_mean[output] ~ dnorm(init_prior_mean[output], sd = init_prior_mean_conf[output])\n",
    "    init_state_sd[output] ~ T(dnorm(init_prior_spread[output], sd = init_prior_spread_conf[output]), 0, )\n",
    "  }\n",
    "  for (n in 1:N_patients) {\n",
    "      for (output in 1:N_cols){\n",
    "        state[n, 1, output] ~ dnorm(init_state_mean[output], sd = init_state_sd[output])\n",
    "      }\n",
    "  }\n",
    "  #for (n in 1:N_patients) {\n",
    "  #  state[n, 1, 1:N_cols] ~ dmnorm(init_state_mean[1:N_cols], cholesky = init_state_cov[1:N_cols, 1:N_cols], prec_param = 0)\n",
    "  #}\n",
    "  \n",
    "  \n",
    "  #healthy states (theta):\n",
    "  for (output in 1:N_cols) {\n",
    "    for (n in 1:N_patients) {\n",
    "      #from state_0, alpha_1 and the \"final\" state, we can infer what delta should be\n",
    "      #mature_state = delta + alpha*delta + alpha^2*delta + .... + alpha^(steps-1)*delta + alpha^(steps)*state_0\n",
    "      #which is a geometric series (+ alpha^(steps)*state_0)\n",
    "      \n",
    "      delta[n, output] <- (mature_state[n, output] - (alpha_1[n, output]^mature_age_steps)*state[n, 1, output])/ ( (1- (alpha_1[n,output]^mature_age_steps)) / (1 - alpha_1[n, output]) )\n",
    "      for (t in 2:N_timesteps_t_max[n]) {\n",
    "        state[n, t, output] <- alpha_1[n, output]*state[n,t-1, output] + delta[n, output]\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  \n",
    "    #innovation  \n",
    "   # for (output in 1:N_cols) {\n",
    "   #   innov_mean[output] ~ T(dnorm(0, sd = 0.1),0,)\n",
    "   #   innov_sd[output] ~ T(dnorm(0, sd = 0.1),0,)\n",
    "   #   for (n in 1:N_patients) {        \n",
    "   #     innov[n, output] ~ T(dnorm(innov_mean[output], sd = innov_sd[output]),0,)\n",
    "   #   }\n",
    "   # }\n",
    "                             \n",
    "  #obs err\n",
    "  #  for (output in 1:N_cols) {\n",
    "  #    obs_err_mean[output] ~ T(dnorm(0, sd = 0.1),0,)\n",
    "  #    obs_err_sd[output] ~ T(dnorm(0, sd = 0.1),0,)\n",
    "  #    for (n in 1:N_patients) {        \n",
    "  #      obs_err[n, output] ~ T(dnorm(obs_err_mean[output], sd = obs_err_sd[output]),0,)\n",
    "  #    }\n",
    "  #  }\n",
    "                             \n",
    "  #Random walks\n",
    "  #for (output in 1:N_cols) {\n",
    "  #  for (n in 1:N_patients) {\n",
    "  #    RW[n, 1, output] <- 0\n",
    "  #    for (t in 2:N_timesteps_t_max[n]) {\n",
    "  #      RW[n, t, output] ~ dnorm(RW[n,t-1, output], sd = innov[n,output])\n",
    "  #    }\n",
    "  #  }\n",
    "  #}\n",
    "  \n",
    "    #observations:\n",
    "  #for (data in 1:N_data) {\n",
    "  #  y_state[data] <- state[n_reshape[data], t_reshape[data], out_reshape[data]] + beta_1[n_reshape[data], out_reshape[data]]*(-softplus_nimble(disease[n_reshape[data],t_reshape[data]]))# + RW[n_reshape[data], t_reshape[data], out_reshape[data]]\n",
    "  #  \n",
    "  #}\n",
    "  for (n in 1:N_pat_with_points){\n",
    "      for (output in 1:i_out_num[i_n[n]]){\n",
    "        for (i_ind in 1:i_j[i_n[n],i_out[i_n[n],output]]){\n",
    "              y_state_reindexed[i_n[n],i_out[i_n[n],output],i_ind] <- state[n_reshape[j[i_n[n],i_out[i_n[n],output],i_ind]], t_reshape[j[i_n[n],i_out[i_n[n],output],i_ind]], out_reshape[j[i_n[n],i_out[i_n[n],output],i_ind]]] + beta_1[n_reshape[j[i_n[n],i_out[i_n[n],output],i_ind]], out_reshape[j[i_n[n],i_out[i_n[n],output],i_ind]]]*(-softplus_nimble(disease[n_reshape[j[i_n[n],i_out[i_n[n],output],i_ind]],t_reshape[j[i_n[n],i_out[i_n[n],output],i_ind]]]))# + RW[n_reshape[j[i_n[n],i_out[i_n[n],output],i_ind]], t_reshape[j[i_n[n],i_out[i_n[n],output],i_ind]], out_reshape[j[i_n[n],i_out[i_n[n],output],i_ind]]]\n",
    "        }\n",
    "      }\n",
    "  }\n",
    "\n",
    "    \n",
    "    \n",
    "#Gaussian Process fitting\n",
    "  for (output in 1:N_cols){\n",
    "      gp_rho_mean[output] ~ T(dnorm(0,sd=20),0,)\n",
    "      gp_rho_sd[output] ~  T(dnorm(0,sd=10),0,)\n",
    "      gp_alpha_mean[output] ~  T(dnorm(0,sd=20),0,)\n",
    "      gp_alpha_sd[output] ~  T(dnorm(0,sd=10),0,)\n",
    "      gp_sigma_mean[output] ~ T(dnorm(0, sd = 0.1),0,)\n",
    "      gp_sigma_sd[output] ~ T(dnorm(0, sd = 0.1),0,)\n",
    "  }\n",
    "    \n",
    "  for (n in 1:N_patients){\n",
    "      for (output in 1:N_cols){\n",
    "        gp_rho[n,output] ~ T(dnorm(gp_rho_mean[output], sd = gp_rho_sd[output]), 0, )\n",
    "        gp_alpha[n,output] ~ T(dnorm(gp_alpha_mean[output],  sd = gp_alpha_sd[output]), 0, )\n",
    "        gp_sigma[n,output] ~ T(dnorm(gp_sigma_mean[output], sd = gp_sigma_sd[output]), 0, )\n",
    "      }\n",
    "  }\n",
    "    \n",
    "  for (n in 1:N_pat_with_points){\n",
    "      for (output in 1:i_out_num[i_n[n]]){\n",
    "        for (i_ind in 1:i_j[i_n[n],i_out[i_n[n],output]]){\n",
    "          for (j_ind in 1:i_j[i_n[n],i_out[i_n[n],output]]){\n",
    "              K[n,i_out[i_n[n],output],i_ind,j_ind] <- (gp_alpha[i_n[n],i_out[i_n[n],output]]^2) *exp(-((t_reshape[j[i_n[n],i_out[i_n[n],output],i_ind]]-t_reshape[j[i_n[n],i_out[i_n[n],output],j_ind]])^2)/(gp_rho[i_n[n],i_out[i_n[n],output]]^2)) + exp(-10000*(i_ind-j_ind)^2) * gp_sigma[i_n[n],i_out[i_n[n],output]]^2\n",
    "              #indicator of diagonal is kinda hacky - fix later if possible\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "  }\n",
    "\n",
    "    \n",
    "  for (n in 1:N_pat_with_points){\n",
    "      for (output in 1:i_out_num[i_n[n]]){#For those individual/outcome combos with more than one point\n",
    "              L[starts_mat[n,i_out[i_n[n],output]] : ends_mat[n,i_out[i_n[n],output]],starts_mat[n,i_out[i_n[n],output]] : ends_mat[n,i_out[i_n[n],output]]] <- chol(K[n, i_out[i_n[n],output], 1:i_j[i_n[n],i_out[i_n[n],output]], 1:i_j[i_n[n],i_out[i_n[n],output]]])\n",
    "              y[i_n[n],i_out[i_n[n],output],1:i_j[i_n[n],i_out[i_n[n],output]]] ~ dmnorm(mean= y_state_reindexed[i_n[n],i_out[i_n[n],output],1:i_j[i_n[n],i_out[i_n[n],output]]], chol=L[starts_mat[n,i_out[i_n[n],output]] : ends_mat[n,i_out[i_n[n],output]],starts_mat[n,i_out[i_n[n],output]] : ends_mat[n,i_out[i_n[n],output]] ],prec_param = 0)\n",
    "      }\n",
    "      for (output in 1:i_out_num_1[i_n[n]]){#For those individual/outcome combos with exactly one point\n",
    "              y[i_n[n],i_out_1[i_n[n],output],1] ~ dnorm(y_state_reindexed[i_n[n],i_out_1[i_n[n],output],1],K[n, i_out_1[i_n[n],output], 1, 1])\n",
    "      }\n",
    "  }\n",
    "    \n",
    "})\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sticky-shareware",
   "metadata": {},
   "source": [
    "### Get data ready for nimble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "first-adams",
   "metadata": {},
   "outputs": [],
   "source": [
    "#don't want to be modelling the *observations* at each time point, which nimble mgitht ry to do even for all the NAs\n",
    "#so we flatten y into a 1d array only containing the actual observations\n",
    "#but then we need several arrays which allow us to relearn which patient/timestep/output each eentry is:\n",
    "\n",
    "y_gutted_reshape <- as.numeric(y_gutted)\n",
    "n_matrix <- y_gutted\n",
    "for (n in 1:dim(n_matrix)[1]){\n",
    "  n_matrix[n,,] = n\n",
    "}\n",
    "n_reshape <- as.numeric(n_matrix)\n",
    "\n",
    "t_matrix <- y_gutted\n",
    "for (t in 1:dim(t_matrix)[2]){\n",
    "  t_matrix[,t,] = t\n",
    "}\n",
    "t_reshape <- as.numeric(t_matrix)\n",
    "\n",
    "out_matrix <- y_gutted\n",
    "for (out in 1:dim(out_matrix)[3]){\n",
    "  out_matrix[,,out] = out\n",
    "}\n",
    "out_reshape <- as.numeric(out_matrix)\n",
    "\n",
    "y_gutted_reshape_isna = which(!is.na(y_gutted_reshape))\n",
    "y_gutted_reshape = y_gutted_reshape[y_gutted_reshape_isna]\n",
    "n_reshape = n_reshape[y_gutted_reshape_isna]\n",
    "t_reshape = t_reshape[y_gutted_reshape_isna]\n",
    "out_reshape = out_reshape[y_gutted_reshape_isna]\n",
    "\n",
    "\n",
    "#Due to castastrophic difficulties with indexing in nimble I have resorted to using these ad-hoc, hacky indexers to get it to work\n",
    "#I've forgotten what most of them do to be honest but I managed to get it to work somehow\n",
    "#Good luck to anyone in the future tying to figure out what is going on\n",
    "#I've tried to annotate some of it to help out but idk\n",
    "#Feel free to contact me (Victor Applebaum) if you have any questions but I will probaly have forgotten most of it by the time you're looking at this\n",
    "\n",
    "n_data_ids <- rep(NA,N_patients)\n",
    "for (n in 1:N_patients){\n",
    "    n_data_ids[n] <- sum(n_reshape==n)\n",
    "}\n",
    "\n",
    "#Ok so some of the patients have had there results removed for some reason, and the whole thing crashes when this happened\n",
    "#So we create a new number, N_pat_with_points, which is like N_patients but only those that have points\n",
    "#We can then use i_n[n] for 1:N_pat_with_points to point to the nth patient that actually has points\n",
    "n_pat_with_points <- c()\n",
    "for (n in 1:N_patients){\n",
    "    if (length(n_reshape[n_reshape==n])>0){\n",
    "        n_pat_with_points <- append(n_pat_with_points,n)\n",
    "    }\n",
    "}\n",
    "i_n <- rep(NA,length(n_pat_with_points))\n",
    "for (i in 1:length(n_pat_with_points)){\n",
    "    i_n[i] <- (1:N_patients)[n_pat_with_points[i]]\n",
    "}\n",
    "N_pat_with_points <- length(n_pat_with_points)\n",
    "\n",
    "i <- nimMatrix(NA,N_patients,max(n_data_ids))#indexing matrix for patients i[n,i_ind]= position of i_ind'th point for nth patient\n",
    "for (n in 1:N_patients){\n",
    "    if (length((1:length(n_reshape))[n_reshape==n])>0){\n",
    "        data_n <- c()\n",
    "        for (data in 1:length(n_reshape)){\n",
    "            if (n_reshape[data] == n){\n",
    "                data_n <- append(data_n,data)\n",
    "            }\n",
    "        }\n",
    "        for (i_ind in 1:length(data_n)){\n",
    "            i[n,i_ind] <- data_n[i_ind]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "j <- nimArray(NA,dim = c(N_patients,N_cols,max(n_data_ids)))#indexes both patient and outcome j[n,m,i_ind] position of i_ind'th point for nth patient's mth outcome\n",
    "for (n in 1:N_patients){\n",
    "    for (m in 1:N_cols){\n",
    "        if (length((1:length(n_reshape))[n_reshape==n & out_reshape==m])>0){\n",
    "            data_n <- c()\n",
    "            for (data in 1:length(n_reshape)){\n",
    "                if (n_reshape[data] == n & out_reshape[data] == m){\n",
    "                    data_n <- append(data_n,data)\n",
    "                }\n",
    "            }\n",
    "            for (i_ind in 1:length(data_n)){\n",
    "                j[n,m,i_ind] <- data_n[i_ind]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "i_j <- nimMatrix(NA,N_patients,N_cols)#number of points avaliable for the patient n's mth outcome\n",
    "for (n in 1:N_patients){\n",
    "    for (m in 1:N_cols){\n",
    "        i_j[n,m] <- sum(is.na(j[n,m,])==FALSE)\n",
    "    }\n",
    "}\n",
    "y_real_reindexed=nimArray(NA,dim=c(N_patients,N_cols,length(y_gutted_reshape)))#rearranges y which i need for some reason\n",
    "for (n in 1:N_pat_with_points){\n",
    "    for (output in 1:N_cols){\n",
    "      for (data in 1:i_j[i_n[n],output]){\n",
    "          y_real_reindexed[i_n[n],output,data] <- y_gutted_reshape[j[i_n[n],output,data]]\n",
    "\n",
    "      }\n",
    "    }\n",
    "}\n",
    "\n",
    "i_out <- nimMatrix(NA,N_patients,N_cols)\n",
    "i_out_num <- nimArray(NA,dim=c(N_patients))\n",
    "for (n in 1:N_patients){\n",
    "    counter <- 0\n",
    "    for (output in 1:N_cols){\n",
    "        if (i_j[n,output] > 1){\n",
    "            counter <- counter + 1\n",
    "            i_out[n,counter] <- output\n",
    "        }\n",
    "    }\n",
    "    i_out_num[n] <- sum(!is.na(i_out[n,]))\n",
    "}\n",
    "i_out_1 <- nimMatrix(NA,N_patients,N_cols)\n",
    "i_out_num_1 <- nimArray(NA,dim=c(N_patients))\n",
    "for (n in 1:N_patients){\n",
    "    counter <- 0\n",
    "    for (output in 1:N_cols){\n",
    "        if (i_j[n,output] == 1){\n",
    "            counter <- counter + 1\n",
    "            i_out_1[n,counter] <- output\n",
    "        }\n",
    "    }\n",
    "    i_out_num_1[n] <- sum(!is.na(i_out_1[n,]))\n",
    "}\n",
    "\n",
    "\n",
    "starts_mat <- nimArray(NA,c(N_pat_with_points,N_cols))#At some point things have to go in a big matrix, we need these two to tell us the positions we should be working in\n",
    "ends_mat <- nimArray(NA,c(N_pat_with_points,N_cols))\n",
    "for (n in 1:N_pat_with_points){\n",
    "    for (m in 1:N_cols){\n",
    "        if (m == 1 & n == 1){\n",
    "            starts <- c(1)\n",
    "            ends <- c(i_j[i_n[n],m])\n",
    "        }\n",
    "        starts <- append(starts,ends[length(ends)]+1)\n",
    "        ends <- append(ends,i_j[i_n[n],m]+starts[length(starts)]-1)\n",
    "        ends_mat[n,m] <- ends[length(ends)-1]\n",
    "        starts_mat[n,m] <- ends_mat[n,m]-i_j[i_n[n]]+1\n",
    "    }\n",
    "}\n",
    "\n",
    "starts_mat <- nimArray(NA,c(N_pat_with_points,N_cols))#At some point things have to go in a big matrix, we need these two to tell us the positions we should be working in\n",
    "ends_mat <- nimArray(NA,c(N_pat_with_points,N_cols))\n",
    "rolling_sum <- 0\n",
    "for (n in 1:N_pat_with_points){\n",
    "    for (m in 1:N_cols){\n",
    "        starts_mat[n,m] <- rolling_sum + 1\n",
    "        ends_mat[n,m] <- starts_mat[n,m] + i_j[i_n[n],m]-1\n",
    "        rolling_sum <- rolling_sum + i_j[i_n[n],m]\n",
    "    }\n",
    "}\n",
    "\n",
    "#get prior values for certain quantities\n",
    "mature_prior_mean = c(NSAA_transformer(34), positive_transformer(2), positive_transformer(2)) #what value for outputs does a healthy adult have?\n",
    "mature_prior_mean_conf = c(0.5, 1,1) #how confident are we in this estimate?\n",
    "mature_prior_spread = c(0, 0,0) #how much spread can healthy adults have?\n",
    "mature_prior_spread_conf = c(0.5, 1,1) #how confident are we in this estimate?\n",
    "\n",
    "init_prior_mean = c(NSAA_transformer(15), positive_transformer(7),positive_transformer(7)) #what value for outputs does a healthy initial patient have?\n",
    "init_prior_mean_conf = c(1, 1,1) #how confident are we in this estimate?\n",
    "init_prior_spread = c(0, 0,0) #how much spread can healthy initial adults have?\n",
    "init_prior_spread_conf = c(1, 1,1) #how confident are we in this estimate?\n",
    "\n",
    "#scale priors to be on standardised scales\n",
    "mature_prior_mean = (mature_prior_mean-y_mean)/y_sd\n",
    "mature_prior_mean_conf = mature_prior_mean_conf/y_sd\n",
    "mature_prior_spread = mature_prior_spread/y_sd\n",
    "mature_prior_spread_conf = mature_prior_spread_conf/y_sd\n",
    "\n",
    "init_prior_mean = (init_prior_mean-y_mean)/y_sd\n",
    "init_prior_mean_conf = init_prior_mean_conf/y_sd\n",
    "init_prior_spread = init_prior_spread/y_sd\n",
    "init_prior_spread_conf = init_prior_spread_conf/y_sd\n",
    "\n",
    "#doesnt like the dimensionality somtimes, so force it to be a vector\n",
    "mature_prior_mean = c(mature_prior_mean,0)\n",
    "mature_prior_mean_conf = c(mature_prior_mean_conf,0)\n",
    "mature_prior_spread = c(mature_prior_spread,0)\n",
    "mature_prior_spread_conf = c(mature_prior_spread_conf,0)\n",
    "\n",
    "init_prior_mean = c(init_prior_mean,0)\n",
    "init_prior_mean_conf = c(init_prior_mean_conf,0)\n",
    "init_prior_spread = c(init_prior_spread,0)\n",
    "init_prior_spread_conf = c(init_prior_spread_conf,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b823444-2c80-46d1-9e37-c4e129d82c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Before fitting MCMC, also find some properties about the data set for synthetic section\n",
    "\n",
    "col_i = 1 #we are interested in NSAA - first outcome\n",
    "\n",
    "    #We find the distribution of start points\n",
    "    start_points <- c()\n",
    "    for (id in unique(n_reshape[out_reshape==1])){\n",
    "        start_points <- append(start_points,min(t_reshape[out_reshape==1 & n_reshape==id]))\n",
    "    }\n",
    "\n",
    "\n",
    "    #We find the distribution of rates of appointment attendance in the real data\n",
    "    rates <- c()\n",
    "    for (id in unique(n_reshape[out_reshape==1 & n_reshape > N_valid])){\n",
    "        if (length(n_reshape[out_reshape==1 & n_reshape==id]) > 0){\n",
    "            rates <- append(rates,(max(t_reshape[out_reshape==1 & n_reshape==id])-min(t_reshape[out_reshape==1 & n_reshape==id]))/length(n_reshape[out_reshape==1 & n_reshape==id]-1))\n",
    "        }\n",
    "    }\n",
    "\n",
    "    ##Finding the probabilities of a line stopping\n",
    "    #First we find the locations of the stops for each individual\n",
    "    end_location <- array(NA,dim=c(length(unique(n_reshape[n_reshape>N_valid])),2))\n",
    "    for (individual in 1:length(unique(n_reshape[n_reshape>N_valid]))){\n",
    "        end_location[individual,1] = max(t_reshape[n_reshape==unique(n_reshape[n_reshape>N_valid])[individual] & out_reshape==col_i])\n",
    "        end_location[individual,2] = NSAA_itransformer(y_gutted_reshape[n_reshape==unique(n_reshape[n_reshape>N_valid])[individual] & out_reshape==col_i & t_reshape==end_location[individual,1]] * y_sd[col_i] + y_mean[col_i])\n",
    "    }\n",
    "    #Create grid\n",
    "    grid_height <- 6\n",
    "    grid_width <- 6\n",
    "    n_stops <- array(NA,dim=c(grid_height,grid_width))#Number of stops within a box\n",
    "    stopping_grid <- array(NA,dim=c(grid_height,grid_width))#Fraction of point in each box which is a stop\n",
    "    for (i in 1:grid_height){\n",
    "        for (j in 1:grid_width){\n",
    "            #Find box locations\n",
    "            age_min <- (j-1)*70/grid_width\n",
    "            age_max <- j*70/grid_width\n",
    "            nsaa_min <- (i-1)*35/grid_height\n",
    "            nsaa_max <- i*35/grid_height\n",
    "            n_stops[i,j] <- length((1:length(unique(n_reshape)))[end_location[,1]>=age_min & end_location[,1]<age_max & end_location[,2]>=nsaa_min & end_location[,2]<nsaa_max])\n",
    "            stopping_grid[i,j] <- n_stops[i,j] / length(n_reshape[out_reshape==col_i & t_reshape>=age_min & t_reshape<age_max & NSAA_itransformer(y_gutted_reshape * y_sd[col_i] + y_mean[col_i])>=nsaa_min & NSAA_itransformer(y_gutted_reshape * y_sd[col_i] + y_mean[col_i])<nsaa_max])\n",
    "            if (is.na(stopping_grid[i,j])){stopping_grid[i,j]<-0}\n",
    "        }\n",
    "    }\n",
    "\n",
    "#save treatments for later\n",
    "X_train = X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atmospheric-london",
   "metadata": {},
   "source": [
    "### Prepare MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollywood-bacteria",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_timesteps_t_max <- apply(N_timesteps_t,1, max)\n",
    "\n",
    "state_model_consts <- list(N_covs = N_covs, #Number of covariances (something to do with treatments)?\n",
    "                           N_cols = N_cols, #Number of outputs (3)\n",
    "                           N_timesteps = N_timesteps, #Number of timesteps\n",
    "                           N_timesteps_t = N_timesteps_t, \n",
    "                           N_timesteps_t_max = N_timesteps_t_max,\n",
    "                           N_patients = N_patients, #Number of patients\n",
    "                           X = X,#Something to do with treatments\n",
    "                           N_data = length(y_gutted_reshape), #Number of data points\n",
    "                           n_reshape = n_reshape,#Patient identifiers for each point\n",
    "                           t_reshape = t_reshape,#Time for each point\n",
    "                           out_reshape = out_reshape,#Identifier for output\n",
    "                           timesteps_per_year = 12/every_x_months,\n",
    "                           mature_age_steps = (20-init_age)*12/every_x_months,\n",
    "                           milestone_age_steps = (15-init_age)*12/every_x_months,\n",
    "                           mature_prior_mean= mature_prior_mean,\n",
    "                           mature_prior_mean_conf = mature_prior_mean_conf,\n",
    "                           mature_prior_spread = mature_prior_spread,\n",
    "                           mature_prior_spread_conf = mature_prior_spread_conf,\n",
    "                           init_prior_mean= init_prior_mean,\n",
    "                           init_prior_mean_conf = init_prior_mean_conf,\n",
    "                           init_prior_spread = init_prior_spread,\n",
    "                           init_prior_spread_conf = init_prior_spread_conf,\n",
    "                           n_data_ids = n_data_ids,#number of points for each patient\n",
    "                           i = i, #indexing matrix for patients i[n,i_ind]= position of i_ind'th point for nth patient\n",
    "                           n_pat_with_points = n_pat_with_points,\n",
    "                           i_n = i_n,\n",
    "                           N_pat_with_points =N_pat_with_points,\n",
    "                           j = j, #indexes both patient and outcome j[n,m,i_ind] position of i_ind'th point for nth patient's mth outcome\n",
    "                           i_j = i_j,\n",
    "                           starts_mat = starts_mat,\n",
    "                           ends_mat = ends_mat,\n",
    "                           i_out = i_out,\n",
    "                           i_out_num = i_out_num,\n",
    "                           i_out_1 = i_out_1,\n",
    "                           i_out_num_1 = i_out_num_1\n",
    "                          )\n",
    "#state_model_data <-  list(y = y_gutted_reshape)#When Using RW\n",
    "state_model_data <-  list(y = y_real_reindexed)#When Using GP\n",
    "seed = 12345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0baf1349-58a5-4ae2-85b2-57380fbc54e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load init values from previous run\n",
    "load('state_samples.out.RData')\n",
    "#state_model_inits <- state_samples$chain1[1000,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c510e248-4fa0-4ddd-8cd8-eff5a29cfb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_model_inits <- list(cov_unscaled_mean = runif(state_model_consts$N_covs, -10, -4),\n",
    "                          cov_unscaled_sd = runif(state_model_consts$N_covs, 0.01, 1),\n",
    "                          beta_1_unscaled_mean = array(NA,state_model_consts$N_cols),\n",
    "                          alpha_1_unscaled_mean = array(NA,state_model_consts$N_cols),\n",
    "                          alpha_1_unscaled_sd = array(NA,state_model_consts$N_cols),\n",
    "                          gp_rho_mean = array(NA,state_model_consts$N_cols),\n",
    "                          gp_rho_sd = array(NA,state_model_consts$N_cols),\n",
    "                          gp_sigma_mean = array(NA,state_model_consts$N_cols),\n",
    "                          gp_sigma_sd = array(NA,state_model_consts$N_cols),\n",
    "                          gp_alpha_mean = array(NA,state_model_consts$N_cols),\n",
    "                          gp_alpha_sd = array(NA,state_model_consts$N_cols),\n",
    "                          init_state_mean = array(NA,state_model_consts$N_cols),\n",
    "                          init_state_sd = array(NA,state_model_consts$N_cols),\n",
    "                          beta_1_unscaled = array(NA,c(state_model_consts$N_patients,state_model_consts$N_cols)),\n",
    "                          alpha_1_unscaled = array(NA,c(state_model_consts$N_patients,state_model_consts$N_cols)),\n",
    "                          gp_rho = array(NA,c(state_model_consts$N_patients,state_model_consts$N_cols)),\n",
    "                          gp_sigma = array(NA,c(state_model_consts$N_patients,state_model_consts$N_cols)),\n",
    "                          gp_alpha = array(NA,c(state_model_consts$N_patients,state_model_consts$N_cols))\n",
    "                          )\n",
    "                          \n",
    "\n",
    "\n",
    "\n",
    "state_model_inits[['Delta_unscaled_mean']] = state_samples$chain1[1000,'Delta_unscaled_mean']\n",
    "state_model_inits[['Delta_unscaled_sd']] = state_samples$chain1[1000,'Delta_unscaled_sd']\n",
    "\n",
    "for (individual in 1:state_model_consts$N_patients){\n",
    "    state_model_inits[['Delta_unscaled']][individual] <- state_samples$chain1[1000,'Delta_unscaled_mean']\n",
    "}\n",
    "\n",
    "for (col in 1:state_model_consts$N_cols){\n",
    "    state_model_inits[['beta_1_unscaled_mean']][col] = state_samples$chain1[1000,paste0('beta_1_unscaled_mean[',col,']')]\n",
    "    state_model_inits[['beta_1_unscaled_sd']][col] = state_samples$chain1[1000,paste0('beta_1_unscaled_sd[',col,']')]\n",
    "    state_model_inits[['alpha_1_unscaled_mean']][col] = state_samples$chain1[1000,paste0('alpha_1_unscaled_mean[',col,']')]\n",
    "    state_model_inits[['alpha_1_unscaled_sd']][col] = state_samples$chain1[1000,paste0('alpha_1_unscaled_sd[',col,']')]\n",
    "    state_model_inits[['gp_rho_mean']][col] = state_samples$chain1[1000,paste0('gp_rho_mean[',col,']')]\n",
    "    state_model_inits[['gp_rho_sd']][col] = state_samples$chain1[1000,paste0('gp_rho_sd[',col,']')]\n",
    "    state_model_inits[['gp_sigma_mean']][col] = state_samples$chain1[1000,paste0('gp_sigma_mean[',col,']')]\n",
    "    state_model_inits[['gp_sigma_sd']][col] = state_samples$chain1[1000,paste0('gp_sigma_sd[',col,']')]\n",
    "    state_model_inits[['gp_alpha_mean']][col] = state_samples$chain1[1000,paste0('gp_alpha_mean[',col,']')]\n",
    "    state_model_inits[['gp_alpha_sd']][col] = state_samples$chain1[1000,paste0('gp_alpha_sd[',col,']')]\n",
    "    state_model_inits[['init_state_mean']][col] = state_samples$chain1[1000,paste0('init_state_mean[',col,']')]\n",
    "    state_model_inits[['init_state_sd']][col] = state_samples$chain1[1000,paste0('init_state_sd[',col,']')]\n",
    "    for (individual in 1:state_model_consts$N_patients){\n",
    "        state_model_inits[['beta_1_unscaled']][individual,col]  = state_samples$chain1[1000,paste0('beta_1_unscaled_mean[',col,']')]\n",
    "        state_model_inits[['alpha_1_unscaled']][individual,col] = state_samples$chain1[1000,paste0('alpha_1_unscaled_mean[',col,']')]\n",
    "        state_model_inits[['gp_rho']][individual,col] = state_samples$chain1[1000,paste0('gp_rho[',1,', ',col,']')]\n",
    "        state_model_inits[['gp_sigma']][individual,col] = state_samples$chain1[1000,paste0('gp_sigma[',1,', ',col,']')]\n",
    "        state_model_inits[['gp_alpha']][individual,col] = state_samples$chain1[1000,paste0('gp_alpha[',1,', ',col,']')]\n",
    "        #state_model_inits[['state']][individual, 1, 1:col] = state_samples$chain1[1000,paste0('state[',individual,', 1, ',col,']')]\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "                              "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460cabc5-bd3f-438b-8e2b-80af64cd6758",
   "metadata": {},
   "source": [
    "## Run MCMC, this is the cell which takes forever, and could be skipped and the results loaded in instead"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ce3152-c6e4-49b4-8561-aaaaa93f146f",
   "metadata": {},
   "source": [
    "It will be skipped if Fit_from_scratch is not TRUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb166db-4a28-4293-82a5-53d91b16430e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (Fit_from_scratch == TRUE){\n",
    "      #nimble function for calculating the softmax probs for a vector of scores\n",
    "      softplus_nimble <- nimbleFunction(\n",
    "        run = function(x = double(0)){\n",
    "          return(log(1+exp(x)))\n",
    "          returnType(double(0))\n",
    "        })\n",
    "      csoftplus_nimble <- compileNimble(softplus_nimble)\n",
    "    \n",
    "\n",
    "      #nimble function required for getting LKJ correlation matrix\n",
    "      uppertri_mult_diag <- nimbleFunction(\n",
    "        run = function(mat = double(2), vec = double(1)) {\n",
    "          returnType(double(2))\n",
    "          p <- length(vec)\n",
    "          out <- matrix(nrow = p, ncol = p, init = FALSE)\n",
    "          for(i in 1:p)\n",
    "            out[ , i] <- mat[ , i] * vec[i]\n",
    "          return(out)\n",
    "        })\n",
    "      cuppertri_mult_diag <- compileNimble(uppertri_mult_diag)\n",
    "\n",
    "\n",
    "      #state_model_inits <- list(cov_unscaled_mean = runif(state_model_consts$N_covs, -10, -4), cov_unscaled_sd = runif(state_model_consts$N_covs, 0.01, 1))\n",
    "\n",
    "\n",
    "    monitors <- c(\"delta\",\n",
    "                  \"Delta\",\"Delta_unscaled_mean\",\"Delta_unscaled_sd\",\n",
    "                  \"beta_1\",\"beta_1_unscaled_mean\",\"beta_1_unscaled_sd\",#'beta_1_cov',\"beta_1_star\",\n",
    "                  \"alpha_1\",\"alpha_1_unscaled_mean\",\"alpha_1_unscaled_sd\",#'alpha_1_cov',\"alpha_1_star\",\n",
    "                  \"disease\",\n",
    "                  \"state\",\n",
    "                  \"gp_rho\", \"gp_rho_mean\" , \"gp_rho_sd\",\n",
    "                  \"gp_alpha\", \"gp_alpha_mean\", \"gp_alpha_sd\",\n",
    "                  \"gp_sigma\", \"gp_sigma_mean\", \"gp_sigma_sd\",\n",
    "                  \"init_state_mean\",\"init_state_sd\",#'init_state_cov','init_state_star',\n",
    "                  \"mature_state_mean\",\"mature_state_sd\",#'mature_state_cov','mature_state_star',\n",
    "                  \"Treat\",\"cov_unscaled_mean\",\"cov_unscaled_sd\",\"cov_effect\",\n",
    "                  'init_disease_when_mean','init_disease_when_sd'\n",
    "                 )\n",
    "\n",
    "\n",
    "\n",
    "      state_samples <- nimbleMCMC(code = state_model_code,\n",
    "                                  constants = state_model_consts,\n",
    "                                  data = state_model_data,\n",
    "                                  inits = list(),\n",
    "                                  monitors=monitors,\n",
    "                                  nburnin=200000,\n",
    "                                  niter = 800000,\n",
    "                                  thin = 400,\n",
    "                                  setSeed=5,\n",
    "                                  samplesAsCodaMCMC = TRUE,\n",
    "                                  nchains = 2)\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c477b25-c62f-45ae-9c1a-c4a67d14d0b9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Save or load the data (decide depending on if we ran the previous cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a675d2-e080-46fa-b915-421fe4c30ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save (or load) results\n",
    "\n",
    "if (Fit_from_scratch == TRUE){\n",
    "    save(state_samples,file='state_samples.out_RERUN.RData')\n",
    "}else{\n",
    "    load('state_samples.out_RERUN.RData')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0e2c6d-0715-494d-8219-3e99f4a6cd8b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Traceplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622af0ae-bc25-469a-b74c-0db7324a9a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(state_samples[,\"gp_rho[9, 1]\"])\n",
    "plot(state_samples[,\"gp_alpha[6, 1]\"])\n",
    "plot(state_samples[,\"gp_sigma[6, 1]\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attempted-manor",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(state_samples[,\"gp_rho_mean[1]\"],type='l')\n",
    "plot(state_samples[,\"gp_rho_sd[1]\"],type='l')\n",
    "plot(state_samples[,\"gp_alpha_mean[1]\"],type='l')\n",
    "plot(state_samples[,\"gp_alpha_sd[1]\"],type='l')\n",
    "plot(state_samples[,\"gp_sigma_mean[1]\"],type='l')\n",
    "plot(state_samples[,\"gp_sigma_sd[1]\"],type='l')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5ba4b0-c37a-4678-9d90-8e6e2034e8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(state_samples[,\"gp_rho_mean[2]\"],type='l')\n",
    "plot(state_samples[,\"gp_rho_sd[2]\"],type='l')\n",
    "plot(state_samples[,\"gp_alpha_mean[2]\"],type='l')\n",
    "plot(state_samples[,\"gp_alpha_sd[2]\"],type='l')\n",
    "plot(state_samples[,\"gp_sigma_mean[2]\"],type='l')\n",
    "plot(state_samples[,\"gp_sigma_sd[2]\"],type='l')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be09566b-6b11-40f6-8b75-7cc8ac1aa83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(state_samples[,\"init_state_mean[1]\"])\n",
    "plot(state_samples[,\"init_state_sd[3]\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4273b1eb-fafb-48ab-85de-193d1f9fb946",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(state_samples[,\"Treat[1, 20]\"])\n",
    "plot(state_samples[,\"cov_unscaled_mean[1]\"])\n",
    "plot(state_samples[,\"cov_unscaled_sd[1]\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conservative-victorian",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(state_samples[,\"alpha_1_unscaled_mean[2]\"])\n",
    "plot(state_samples[,\"alpha_1_unscaled_sd[3]\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a69aee3-ec56-4cfe-a7b6-c15459626f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(state_samples[,\"Delta_unscaled_mean\"])\n",
    "plot(state_samples[,\"Delta_unscaled_sd\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e88296-5677-48e7-a62a-01e42ed49ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(state_samples[,\"beta_1_unscaled_mean[2]\"])\n",
    "plot(state_samples[,\"beta_1_unscaled_sd[3]\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excited-porter",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot(state_samples[,\"beta_1[3, 3]\"])\n",
    "plot(state_samples[,\"alpha_1[5, 1]\"])\n",
    "plot(state_samples[,\"Delta[6]\"])\n",
    "plot(state_samples[,\"delta[10, 2]\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a78a67-831d-420b-b106-cbde945dff8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(state_samples[,\"state[5, 30, 2]\"])\n",
    "plot(state_samples[,\"disease[4, 30]\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb91eb5-1df6-40c4-b336-dc899ab8f5e9",
   "metadata": {},
   "source": [
    "## Get results from model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleased-return",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_samples_merged <- data.frame(do.call('rbind',state_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152e835f-733b-4525-918f-85216234cdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract population parameters from fit\n",
    "#and take logs of positive only parameters\n",
    "\n",
    "transformed_state_samples_merged <- list()\n",
    "\n",
    "transformed_state_samples_merged$Delta_unscaled_mean <- c(state_samples_merged$Delta_unscaled_mean)\n",
    "transformed_state_samples_merged$Delta_unscaled_sd <- c(log(state_samples_merged$Delta_unscaled_sd))\n",
    "transformed_state_samples_merged$init_disease_when_mean <- c(state_samples_merged$init_disease_when_mean)\n",
    "transformed_state_samples_merged$init_disease_when_sd <- c(log(state_samples_merged$init_disease_when_sd))\n",
    "for (col in 1:state_model_consts$N_cols){\n",
    "    transformed_state_samples_merged[[paste0('beta_1_unscaled_mean.',col,'.')]] = unlist(state_samples_merged[paste0('beta_1_unscaled_mean.',col,'.')])\n",
    "    transformed_state_samples_merged[[paste0('beta_1_unscaled_sd.',col,'.')]] = unlist(log(state_samples_merged[paste0('beta_1_unscaled_sd.',col,'.')]))\n",
    "    transformed_state_samples_merged[[paste0('alpha_1_unscaled_mean.',col,'.')]] = unlist(state_samples_merged[paste0('alpha_1_unscaled_mean.',col,'.')])\n",
    "    transformed_state_samples_merged[[paste0('alpha_1_unscaled_sd.',col,'.')]] = unlist(log(state_samples_merged[paste0('alpha_1_unscaled_sd.',col,'.')]))\n",
    "    transformed_state_samples_merged[[paste0('gp_alpha_mean.',col,'.')]] = unlist(log(state_samples_merged[paste0('gp_alpha_mean.',col,'.')]))\n",
    "    transformed_state_samples_merged[[paste0('gp_alpha_sd.',col,'.')]] = unlist(log(state_samples_merged[paste0('gp_alpha_sd.',col,'.')]))\n",
    "    transformed_state_samples_merged[[paste0('gp_rho_mean.',col,'.')]] = unlist(log(state_samples_merged[paste0('gp_rho_mean.',col,'.')]))\n",
    "    transformed_state_samples_merged[[paste0('gp_rho_sd.',col,'.')]] = unlist(log(state_samples_merged[paste0('gp_rho_sd.',col,'.')]))\n",
    "    transformed_state_samples_merged[[paste0('gp_sigma_mean.',col,'.')]] = unlist(log(state_samples_merged[paste0('gp_sigma_mean.',col,'.')]))\n",
    "    transformed_state_samples_merged[[paste0('gp_sigma_sd.',col,'.')]] = unlist(log(state_samples_merged[paste0('gp_sigma_sd.',col,'.')]))\n",
    "    transformed_state_samples_merged[[paste0('init_state_mean.',col,'.')]] = unlist(state_samples_merged[paste0('init_state_mean.',col,'.')])\n",
    "    transformed_state_samples_merged[[paste0('init_state_sd.',col,'.')]] = unlist(log(state_samples_merged[paste0('init_state_sd.',col,'.')]))\n",
    "    transformed_state_samples_merged[[paste0('mature_state_mean.',col,'.')]] = unlist(state_samples_merged[paste0('mature_state_mean.',col,'.')])\n",
    "    transformed_state_samples_merged[[paste0('mature_state_sd.',col,'.')]] = unlist(log(state_samples_merged[paste0('mature_state_sd.',col,'.')]))\n",
    "    #for (col2 in 1:state_model_consts$N_cols){\n",
    "    #    transformed_state_samples_merged[[paste0('beta_1_star.',col,'..',col2,'.')]] = unlist(state_samples_merged[paste0('beta_1_star.',col,'..',col2,'.')])\n",
    "    #    transformed_state_samples_merged[[paste0('alpha_1_star.',col,'..',col2,'.')]] = unlist(state_samples_merged[paste0('alpha_1_star.',col,'..',col2,'.')])\n",
    "    #    transformed_state_samples_merged[[paste0('mature_state_star.',col,'..',col2,'.')]] = unlist(state_samples_merged[paste0('mature_state_star.',col,'..',col2,'.')])\n",
    "    #    transformed_state_samples_merged[[paste0('init_state_star.',col,'..',col2,'.')]] = unlist(state_samples_merged[paste0('init_state_star.',col,'..',col2,'.')])#\n",
    "\n",
    "    #}\n",
    "}\n",
    "for (cov in 1:state_model_consts$N_covs){\n",
    "    transformed_state_samples_merged[[paste0('cov_unscaled_mean.',cov,'.')]] = unlist(state_samples_merged[paste0('cov_unscaled_mean.',cov,'.')])\n",
    "    transformed_state_samples_merged[[paste0('cov_unscaled_sd.',cov,'.')]] = unlist(log(state_samples_merged[paste0('cov_unscaled_sd.',cov,'.')]))\n",
    "}\n",
    "order = c('Delta_unscaled_mean','Delta_unscaled_sd',\n",
    "          'init_disease_when_mean','init_disease_when_sd',\n",
    "          'beta_1_unscaled_mean.1.','beta_1_unscaled_mean.2.','beta_1_unscaled_mean.3.',\n",
    "          'beta_1_unscaled_sd.1.','beta_1_unscaled_sd.2.','beta_1_unscaled_sd.3.',\n",
    "          'alpha_1_unscaled_mean.1.','alpha_1_unscaled_mean.2.','alpha_1_unscaled_mean.3.',\n",
    "          'alpha_1_unscaled_sd.1.','alpha_1_unscaled_sd.2.','alpha_1_unscaled_sd.3.',\n",
    "          'gp_alpha_mean.1.','gp_alpha_mean.2.','gp_alpha_mean.3.',\n",
    "          'gp_alpha_sd.1.','gp_alpha_sd.2.','gp_alpha_sd.3.',\n",
    "          'gp_rho_mean.1.','gp_rho_mean.2.','gp_rho_mean.3.',\n",
    "          'gp_rho_sd.1.','gp_rho_sd.2.','gp_rho_sd.3.',\n",
    "          'init_state_mean.1.','init_state_mean.2.','init_state_mean.3.',\n",
    "          'init_state_sd.1.','init_state_sd.2.','init_state_sd.3.',\n",
    "          'mature_state_mean.1.','mature_state_mean.2.','mature_state_mean.3.',\n",
    "          'mature_state_sd.1.','mature_state_sd.2.','mature_state_sd.3.',\n",
    "          #'beta_1_star.1..1.','beta_1_star.1..2.','beta_1_star.1..3.','beta_1_star.2..2.','beta_1_star.2..3.','beta_1_star.3..3.',\n",
    "          #'alpha_1_star.1..1.','alpha_1_star.1..2.','alpha_1_star.1..3.','alpha_1_star.2..2.','alpha_1_star.2..3.','alpha_1_star.3..3.',\n",
    "          #'mature_state_star.1..1.','mature_state_star.1..2.','mature_state_star.1..3.','mature_state_star.2..2.','mature_state_star.2..3.','mature_state_star.3..3.',\n",
    "          #'init_state_star.1..1.','init_state_star.1..2.','init_state_star.1..3.','init_state_star.2..2.','init_state_star.2..3.','init_state_star.3..3.',\n",
    "          'cov_unscaled_mean.1.','cov_unscaled_mean.2.','cov_unscaled_mean.3.','cov_unscaled_mean.4.',\n",
    "          'cov_unscaled_sd.1.','cov_unscaled_sd.2.','cov_unscaled_sd.3.','cov_unscaled_sd.4.',\n",
    "          'gp_sigma_mean.1.','gp_sigma_mean.2.','gp_sigma_mean.3.',\n",
    "          'gp_sigma_sd.1.','gp_sigma_sd.2.','gp_sigma_sd.3.'\n",
    "         )\n",
    "transformed_state_samples_merged =  transformed_state_samples_merged[order]\n",
    "\n",
    "#now approaximate using multivariate normal\n",
    "pop_par_mean = colMeans(t(matrix(unlist(transformed_state_samples_merged), ncol = 3000, byrow = TRUE)))\n",
    "pop_par_cov  = cov(t(matrix(unlist(transformed_state_samples_merged), ncol = 3000, byrow = TRUE)))\n",
    "\n",
    "save(pop_par_mean,file='RERUN_pop_par_mean.RData')\n",
    "save(pop_par_cov,file='RERUN_pop_par_cov.RData')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230409f2-6782-4844-b75b-51f62a3eeefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#New Nimble model for fitting individuals given the known population parmeters\n",
    "solveLeastSquares <- nimbleFunction(\n",
    "    run = function(X = double(2), y = double(1)) { # type declarations\n",
    "        ans <- inverse(t(X) %*% X) %*% (t(X) %*% y)\n",
    "        return(ans)\n",
    "        returnType(double(2))  # return type declaration\n",
    "    } )## Create Nimble Model (Code for the Bayesian Hierarchical Model)\n",
    "#get Nimble Model\n",
    "\n",
    "state_model_code <- nimbleCode({\n",
    "  \n",
    "    for (n in 1:N_patients){\n",
    "        parameters[n,1:54] ~ dmnorm(pop_par_mean[1:54],cov = pop_par_cov[1:54,1:54])\n",
    "\n",
    "        #first we have to extract parameters from normal distribution using the same order that we put the in with\n",
    "        #so im writing these out manually\n",
    "        #also have to take exp of sd parameters as we logged them earlier\n",
    "        Delta_unscaled_mean[n] <- parameters[n,1]\n",
    "        Delta_unscaled_sd[n] <- exp(parameters[n,2])\n",
    "        init_disease_when_mean[n] <- parameters[n,3]\n",
    "        init_disease_when_sd[n] <- exp(parameters[n,4])\n",
    "        beta_1_unscaled_mean[n,1:3] <- parameters[n,5:7]\n",
    "        beta_1_unscaled_sd[n,1:3] <- exp(parameters[n,8:10])\n",
    "        alpha_1_unscaled_mean[n,1:3] <- parameters[n,11:13]\n",
    "        alpha_1_unscaled_sd[n,1:3] <- exp(parameters[n,14:16])\n",
    "        gp_alpha_mean[n,1:3] <- exp(parameters[n,17:19])\n",
    "        gp_alpha_sd[n,1:3] <- exp(parameters[n,20:22])\n",
    "        gp_rho_mean[n,1:3] <- exp(parameters[n,23:25])\n",
    "        gp_rho_sd[n,1:3] <- exp(parameters[n,26:28])\n",
    "        init_state_mean[n,1:3] <- parameters[n,29:31]\n",
    "        init_state_sd[n,1:3] <- exp(parameters[n,32:34])\n",
    "        mature_state_mean[n,1:3] <- parameters[n,35:37]\n",
    "        mature_state_sd[n,1:3] <- exp(parameters[n,38:40])\n",
    "\n",
    "        cov_unscaled_mean[n,1:4] <- parameters[n,41:44]\n",
    "        cov_unscaled_sd[n,1:4] <- exp(parameters[n,45:48])\n",
    "\n",
    "        gp_sigma_mean[n,1:3] <- exp(parameters[n,49:51])\n",
    "        gp_sigma_sd[n,1:3] <- exp(parameters[n,52:54])\n",
    "    }\n",
    "\n",
    "  #the effect of treatments (gamma)\n",
    "  for (cov in 1:(N_covs)) {\n",
    "    for (n in 1:N_patients) {\n",
    "      cov_effect_unscaled[n, cov] ~ dnorm(cov_unscaled_mean[n,cov], sd = cov_unscaled_sd[n,cov])\n",
    "      cov_effect[n,cov] <- softplus_nimble(cov_effect_unscaled[n,cov])\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  #total up these effects (not essential code, just clearer\n",
    "  for (n in 1:N_patients) {\n",
    "    Treat[n, 1] <-  0\n",
    "    for (t in 2:69) {\n",
    "      Treat[n, t] <-  inprod( (cov_effect[n,1:(N_covs)]), X[n, t - 1, 1:(N_covs)])  \n",
    "    }\n",
    "  }\n",
    "  \n",
    "  #disease rate of decay\n",
    "  for (n in 1:N_patients){\n",
    "    Delta_unscaled[n] ~ dnorm(Delta_unscaled_mean[n], sd = Delta_unscaled_sd[n])\n",
    "    Delta[n] <- softplus_nimble(Delta_unscaled[n])\n",
    "  }\n",
    "  \n",
    "  #initial disease state (phi)\n",
    "  #When disease = 0?\n",
    "  for (n in 1:N_patients) {        \n",
    "    init_disease_when_unscaled[n] ~dnorm(init_disease_when_mean[n], sd = init_disease_when_sd[n])\n",
    "    init_disease_when[n] <- init_disease_when_unscaled[n]\n",
    "  }\n",
    "  \n",
    "  #calculate what the initial disease is for each patient\n",
    "  for (n in 1:N_patients) {        \n",
    "    disease[n,1] <- -init_disease_when[n]*Delta[n]\n",
    "  }  \n",
    "  #disease states (phi:)\n",
    "  for (n in 1:N_patients) {        \n",
    "    for (t in 2:69) {\n",
    "      disease[n, t] <- disease[n, t - 1]  + Delta[n] - Treat[n, t] \n",
    "    }\n",
    "  }\n",
    "  \n",
    "  \n",
    "  #how disease affects the different outputs\n",
    "  for (n in 1:N_patients) {\n",
    "      for (output in 1:N_cols){\n",
    "          beta_1_unscaled[n,output] ~ dnorm(beta_1_unscaled_mean[n,output], sd = beta_1_unscaled_sd[n,output])\n",
    "      }\n",
    "  }\n",
    "  \n",
    "  #the first beta_1 can be set to 1 (note that this means, technically, the beta_params could have been 1 fewer above\n",
    "  #but nimble doesnt like 1D correlation matrices, even tho its possible)\n",
    "  for (n in 1:N_patients) {\n",
    "    beta_1[n, 1] <- 1\n",
    "  } \n",
    "  for (output in 2:N_cols) {\n",
    "    for (n in 1:N_patients) {\n",
    "      beta_1[n, output] <- beta_1_unscaled[n, output]\n",
    "    } \n",
    "  }\n",
    "  \n",
    "  \n",
    "  #shape parameter for how healthy state changes over time\n",
    "  for (n in 1:N_patients) {\n",
    "      for (output in 1:N_cols){\n",
    "          alpha_1_unscaled[n,output] ~ dnorm(alpha_1_unscaled_mean[n,output], sd = alpha_1_unscaled_sd[n,output])\n",
    "      }\n",
    "  }\n",
    "  for (output in 1:N_cols){\n",
    "    for (n in 1:N_patients){\n",
    "      alpha_1[n, output] <- ilogit(alpha_1_unscaled[n, output])\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  #healthy state at mature age\n",
    "\n",
    "    for (n in 1:N_patients) {\n",
    "      for (output in 1:N_cols){\n",
    "          mature_state[n,output] ~ dnorm(mature_state_mean[n,output], sd = mature_state_sd[n,output])\n",
    "      }\n",
    "  }\n",
    "  \n",
    "  \n",
    "  \n",
    "  #initial healthy state (theta)\n",
    "  for (n in 1:N_patients) {\n",
    "      for (output in 1:N_cols){\n",
    "        state[n, 1, output] ~ dnorm(init_state_mean[n,output], sd = init_state_sd[n,output])\n",
    "      }\n",
    "  }\n",
    "  \n",
    "  \n",
    "  #healthy states (theta):\n",
    "  for (output in 1:N_cols) {\n",
    "    for (n in 1:N_patients) {\n",
    "      #from state_0, alpha_1 and the \"final\" state, we can infer what delta should be\n",
    "      #mature_state = delta + alpha*delta + alpha^2*delta + .... + alpha^(steps-1)*delta + alpha^(steps)*state_0\n",
    "      #which is a geometric series (+ alpha^(steps)*state_0)\n",
    "      \n",
    "      delta[n, output] <- (mature_state[n, output] - (alpha_1[n, output]^mature_age_steps)*state[n, 1, output])/ ( (1- (alpha_1[n,output]^mature_age_steps)) / (1 - alpha_1[n, output]) )\n",
    "      for (t in 2:69) {\n",
    "        state[n, t, output] <- alpha_1[n, output]*state[n,t-1, output] + delta[n, output]\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  \n",
    "\n",
    "  for (n in 1:N_pat_with_points){\n",
    "      for (output in 1:i_out_num[i_n[n]]){\n",
    "        for (i_ind in 1:i_j[i_n[n],i_out[i_n[n],output]]){\n",
    "              y_state_reindexed[i_n[n],i_out[i_n[n],output],i_ind] <- state[n_reshape[j[i_n[n],i_out[i_n[n],output],i_ind]], t_reshape[j[i_n[n],i_out[i_n[n],output],i_ind]], out_reshape[j[i_n[n],i_out[i_n[n],output],i_ind]]] + beta_1[n_reshape[j[i_n[n],i_out[i_n[n],output],i_ind]], out_reshape[j[i_n[n],i_out[i_n[n],output],i_ind]]]*(-softplus_nimble(disease[n_reshape[j[i_n[n],i_out[i_n[n],output],i_ind]],t_reshape[j[i_n[n],i_out[i_n[n],output],i_ind]]]))# + RW[n_reshape[j[i_n[n],i_out[i_n[n],output],i_ind]], t_reshape[j[i_n[n],i_out[i_n[n],output],i_ind]], out_reshape[j[i_n[n],i_out[i_n[n],output],i_ind]]]\n",
    "        }\n",
    "      }\n",
    "  }\n",
    "\n",
    "    \n",
    "    \n",
    "#Gaussian Process fitting\n",
    "   \n",
    "  for (n in 1:(N_patients)){\n",
    "      for (output in 1:N_cols){\n",
    "        gp_rho[n,output] ~ T(dnorm(gp_rho_mean[n,output], sd = gp_rho_sd[n,output]), 0, )\n",
    "        gp_alpha[n,output] ~ T(dnorm(gp_alpha_mean[n,output],  sd = gp_alpha_sd[n,output]), 0, )\n",
    "        gp_sigma[n,output] ~ T(dnorm(gp_sigma_mean[n,output], sd = gp_sigma_sd[n,output]), 0, )\n",
    "      }\n",
    "  }\n",
    "    \n",
    "       \n",
    "  for (n in 1:N_pat_with_points){\n",
    "      for (output in 1:i_out_num[i_n[n]]){\n",
    "        for (i_ind in 1:i_j[i_n[n],i_out[i_n[n],output]]){\n",
    "          for (j_ind in 1:i_j[i_n[n],i_out[i_n[n],output]]){\n",
    "              K[n,i_out[i_n[n],output],i_ind,j_ind] <- (gp_alpha[i_n[n],i_out[i_n[n],output]]^2) *exp(-((t_reshape[j[i_n[n],i_out[i_n[n],output],i_ind]]-t_reshape[j[i_n[n],i_out[i_n[n],output],j_ind]])^2)/(gp_rho[i_n[n],i_out[i_n[n],output]]^2)) + exp(-10000*(i_ind-j_ind)^2) * gp_sigma[i_n[n],i_out[i_n[n],output]]^2\n",
    "              #indicator of diagonal is kinda hacky - fix later if possible\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "  }\n",
    "\n",
    "    \n",
    "  for (n in 1:N_pat_with_points){\n",
    "      for (output in 1:i_out_num[i_n[n]]){#For those individual/outcome combos with more than one point\n",
    "              L[starts_mat[n,i_out[i_n[n],output]] : ends_mat[n,i_out[i_n[n],output]],starts_mat[n,i_out[i_n[n],output]] : ends_mat[n,i_out[i_n[n],output]]] <- chol(K[n, i_out[i_n[n],output], 1:i_j[i_n[n],i_out[i_n[n],output]], 1:i_j[i_n[n],i_out[i_n[n],output]]])\n",
    "              y[i_n[n],i_out[i_n[n],output],1:i_j[i_n[n],i_out[i_n[n],output]]] ~ dmnorm(mean= y_state_reindexed[i_n[n],i_out[i_n[n],output],1:i_j[i_n[n],i_out[i_n[n],output]]], chol=L[starts_mat[n,i_out[i_n[n],output]] : ends_mat[n,i_out[i_n[n],output]],starts_mat[n,i_out[i_n[n],output]] : ends_mat[n,i_out[i_n[n],output]] ],prec_param = 0)\n",
    "      }\n",
    "      for (output in 1:i_out_num_1[i_n[n]]){#For those individual/outcome combos with exactly one point\n",
    "              y[i_n[n],i_out_1[i_n[n],output],1] ~ dnorm(y_state_reindexed[i_n[n],i_out_1[i_n[n],output],1],K[n, i_out_1[i_n[n],output], 1, 1])\n",
    "      }\n",
    "  }\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866d1a11-3bee-4a9f-aff5-a3c9c1380420",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Now we repeat data processing with the validation dataset instead\n",
    "data = data_validation\n",
    "\n",
    "set.seed(12345)\n",
    "\n",
    "\n",
    "#which columns do we want in the model?\n",
    "inputs =  c(\"steroids_regime\")\n",
    "outputs = c(\"Calculated_nsaa_score\", \"nsaa_walk_time\", \"nsaa_rise_from_floor_time\")\n",
    "\n",
    "#make data in terms of 3 month intervals\n",
    "every_x_months = 3\n",
    "data$fup_age_at_date_of_assessment = round(data$fup_age_at_date_of_assessment/every_x_months)\n",
    "\n",
    "#Delete rows where the patients age aren't known (alternatively, we could re-infer it from the time?)\n",
    "data = data[!is.na(data$fup_age_at_date_of_assessment), ]\n",
    "\n",
    "#fill in missing timesteps (monthly)\n",
    "data = complete(data, fup_age_at_date_of_assessment = 0:(25*12/every_x_months), nesting(PatID))\n",
    "\n",
    "#also make sure we only have one data row per patID per appointment time:\n",
    "data = data %>%\n",
    "  group_by(PatID, fup_age_at_date_of_assessment) %>%\n",
    "  filter(row_number()==1) %>%\n",
    "  ungroup()\n",
    "\n",
    "#inputs (i.e. treatments / X in the model) cannot have any missing values at any time step.\n",
    "#This shouldn't be a problem as they dont need to be specially observed (clinicians should be dictating them)\n",
    "#but they may not have been written down for each timestep\n",
    "\n",
    "#sometimes data steroids is input as \"\" rather than NA\n",
    "data$steroids_used[which(data$steroids_used == \"\")] = NA\n",
    "data$steroids_regime[which(data$steroids_regime == \"\")] = NA\n",
    "\n",
    "#for the treatments, which we don't expect to change regularly, use the previous value if there is one\n",
    "data <- data %>% group_by(PatID) %>%\n",
    "  fill(age_at_km_steroids_start, .direction = \"downup\") %>%\n",
    "  fill(names(select(data, all_of(c(inputs, \"steroids_dose\")))), .direction = \"down\") %>%\n",
    "  dplyr::ungroup()\n",
    "\n",
    "#if the patient's age is after the age they started steroids, we can also use later values to interpolate\n",
    "#Note that this will only do so if the date they started steroids is recorded (at any point, and is why its interpolated up and down earlier)\n",
    "data <- data %>% group_by(PatID) %>%\n",
    "  mutate(steroids_dose = ifelse(is.na(steroids_dose) & fup_age_at_date_of_assessment> age_at_km_steroids_start, na.locf(steroids_dose, fromLast = TRUE), steroids_dose)) %>%\n",
    "  mutate(steroids_used = ifelse(is.na(steroids_used) & fup_age_at_date_of_assessment> age_at_km_steroids_start, na.locf(steroids_used, fromLast = TRUE, coredata = TRUE), steroids_used)) %>%\n",
    "  mutate(steroids_regime = ifelse(is.na(steroids_regime) & fup_age_at_date_of_assessment> age_at_km_steroids_start, na.locf(steroids_regime, fromLast = TRUE, coredata = TRUE), steroids_regime)) %>%\n",
    "  dplyr::ungroup()\n",
    "\n",
    "#and if any steroids dose are still NA, make them 0\n",
    "data <- data %>% mutate(steroids_dose = replace_na(steroids_dose, 0))\n",
    "#and then, if any steroids dose are 0, force the other steroid information to be NA\n",
    "data$steroids_used[data$steroids_dose == 0] = NA\n",
    "data$steroids_regime[data$steroids_dose == 0] = NA\n",
    "\n",
    "#for the other steroid information, replace NA with \"Unknown\" if steroids dose > 0, and \"None\" if steroids_dose = 0\n",
    "which_missing_used = is.na(data$steroids_used) & (data$steroids_dose > 0)\n",
    "which_none_used = is.na(data$steroids_used) & (data$steroids_dose == 0)\n",
    "which_missing_regime = is.na(data$steroids_regime) & (data$steroids_dose > 0)\n",
    "which_none_regime = is.na(data$steroids_regime) & (data$steroids_dose == 0)\n",
    "\n",
    "data$steroids_used <- as.character(data$steroids_used)\n",
    "data$steroids_used[which_none_used] = \"None\"\n",
    "if(sum(which_missing_used) > 0){\n",
    "  data$steroids_used[which_missing_used] = \"Unknown\"\n",
    "}\n",
    "\n",
    "data$steroids_regime <- as.character(data$steroids_regime)\n",
    "data$steroids_regime[which_none_regime] = \"None\"\n",
    "if(sum(which_missing_regime) > 0){\n",
    "  data$steroids_regime[which_missing_regime] = \"Unknown\"\n",
    "}\n",
    "\n",
    "\n",
    "#convert other information to factors, and force \"no steroids\" to be the baseline intercept\n",
    "data$steroids_used <- as.factor(data$steroids_used)\n",
    "data$steroids_used <- relevel(data$steroids_used, \"None\") #make \"None\" first\n",
    "data$steroids_regime <- as.factor(data$steroids_regime)\n",
    "data$steroids_regime <- relevel(data$steroids_regime, \"None\") #make \"None\" first\n",
    "\n",
    "\n",
    "#sometimes a walk time or rise time of 0 is recorded. This is impossible, so replace with NA\n",
    "\n",
    "data$nsaa_walk_time[which(data$nsaa_walk_time == 0)] = NA\n",
    "data$nsaa_rise_from_floor_time[which(data$nsaa_rise_from_floor_time == 0)] = NA\n",
    "\n",
    "#convert dataframe into 3d arrays (time, patient, column)\n",
    "N_patients = n_distinct(data$PatID)\n",
    "N_timesteps = n_distinct(data$fup_age_at_date_of_assessment)\n",
    "\n",
    "#which columns do we want (first set should be PatID and fup_age, second should be inputs, third should be outputs)\n",
    "data <-select(data, all_of(c(c(\"PatID\", \"fup_age_at_date_of_assessment\"), inputs, outputs)))\n",
    "\n",
    "#change format of data to allow conversion\n",
    "data = arrange(data, PatID, fup_age_at_date_of_assessment)\n",
    "data$PatID <- as.integer(as.numeric(factor(data$PatID)))\n",
    "data = data.frame(data)\n",
    "\n",
    "#convert categorical variables to one hot variables (\"None\" is the base example)\n",
    "dmy <- dummyVars(\" ~ .\", data = data, fullRank = TRUE)\n",
    "data <- data.frame(predict(dmy, newdata = data))\n",
    "\n",
    "N_cols = dim(select(data,contains(outputs)))[2] #number of outputs\n",
    "N_covs = dim(select(data,contains(inputs)))[2] #number of inputs\n",
    "Xnames = colnames(data)[2+(1:N_covs)] #names of covariates (for posterity)\n",
    "\n",
    "#convert to 3d array\n",
    "data <- data %>%\n",
    "  nest(-PatID) %>%    # collapse other columns to list column of data frames\n",
    "  mutate(data = map(data, ~as.matrix(.x[-1]))) %>%    # drop dates from nested data frames and coerce each to matrix\n",
    "  pull(data) %>%    # extract matrix list\n",
    "  invoke(abind::abind, ., along = 3) %>%    # abind in 3rd dimension\n",
    "  `dimnames<-`(list(as.character(unique(data$fup_age_at_date_of_assessment)), names(data)[3:(3+N_cols+N_covs-1)], unique(data$PatID)))    # set dimnames properly\n",
    "\n",
    "#swap index ordering to (PatID, timestep, column) (currently (timestep, column, PatID))\n",
    "data <- aperm(data, c(3,1,2))\n",
    "\n",
    "#make sure they have at least 1 NSAA score \n",
    "# might slightly bias, but we dont really have any proper information otherwise...\n",
    "which_enough = which(apply(!is.na(data[,,N_covs+1]), 1, sum)>0)\n",
    "data = data[which_enough, , ]\n",
    "\n",
    "#shuffle patient order (randomise)\n",
    "data = data[sample(dim(data)[1]),1:dim(data)[2], 1:dim(data)[3]]\n",
    "\n",
    "#subset data for speed reasons\n",
    "init_age = 3\n",
    "final_age = 20\n",
    "N_patients = dim(data)[1] #all of the patients\n",
    "\n",
    "data = data[1:dim(data)[1], (init_age*12/every_x_months):(final_age*12/every_x_months), ]\n",
    "#data = data[c(1,8), (init_age*12/every_x_months):(final_age*12/every_x_months), ]\n",
    "\n",
    "#save full data \n",
    "X_data = data[,,1:N_covs,drop = FALSE]\n",
    "y_data = data[,,(N_covs+1):(N_covs+N_cols),drop = FALSE]\n",
    "save(X_data, y_data,file='y_data.out.RData')\n",
    "#np$save(\"X_data.out.npy\",r_to_py(X_data))\n",
    "#np$save(\"y_data.out.npy\",r_to_py(y_data))\n",
    "\n",
    "#subset N patients as well\n",
    "data = data[1:N_patients, , ]\n",
    "\n",
    "N_timesteps = dim(data)[2]\n",
    "\n",
    "sum(!is.na(data[,,N_covs+1])) #how many data points do we have for NSAA (the first output, use +2 for the second, etc)\n",
    "\n",
    "#get input and output data\n",
    "X_data = data[,,1:N_covs,drop = FALSE]\n",
    "y_data = data[,,(N_covs+1):(N_covs+N_cols),drop = FALSE]\n",
    "\n",
    "#get maximum number of timesteps observed for each patient, for each output\n",
    "N_timesteps_t = matrix(1, nrow = N_patients, ncol = N_cols)\n",
    "for (output in 1:N_cols){\n",
    "  for (n in 1:N_patients){\n",
    "    N_timesteps_t[n, output] = max(which(!is.na(y_data[n,,output])))\n",
    "  }\n",
    "}\n",
    "\n",
    "#replace -Inf with 2 (minimum number of timestpes we'd need for model to actually run\n",
    "N_timesteps_t[N_timesteps_t==-Inf] = 2\n",
    "\n",
    "#Decide which patients/observations are the held-out validation points\n",
    "#We need to hold back certain observations from them, and make the model predict for the whole timeseries for them\n",
    "\n",
    "N_valid = N_patients\n",
    "#delete the second X% of observations for the first set of patients, where X% is random (between 20% and 80%)\n",
    "y_gutted_data = y_data\n",
    "y_valid = y_data\n",
    "for (n in 1:N_valid){\n",
    "  which_notna = which(!is.na(y_data[n,,1]))\n",
    "  how_many_obs = length(which_notna)\n",
    "  Xperc = runif(1, 0.2, 0.8)\n",
    "  keep_up_to = which_notna[floor(how_many_obs*Xperc)]\n",
    "  if (length(keep_up_to)==0){\n",
    "    keep_up_to = 0\n",
    "  }\n",
    "  y_gutted_data[n, (keep_up_to+1):N_timesteps, 1:N_cols] = NA\n",
    "  y_valid[n, 1:(keep_up_to), 1:N_cols] = NA\n",
    "  N_timesteps_t[n, 1:N_cols] = N_timesteps\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "y_gutted_data[,,1] = NSAA_transformer(y_gutted_data[,,1] )\n",
    "y_gutted_data[,,2] = positive_transformer(y_gutted_data[,,2] )\n",
    "y_gutted_data[,,3] = positive_transformer(y_gutted_data[,,3] )\n",
    "\n",
    "#standardise data\n",
    "\n",
    "#don't recalculate this - keeping same sd and means as were in training data\n",
    "#X_max = apply(X_data, 3, max, na.rm = TRUE)\n",
    "#X_min = apply(X_data, 3, min, na.rm = TRUE)\n",
    "#y_mean = apply(y_gutted_data, 3, mean, na.rm = TRUE)\n",
    "#y_sd = apply(y_gutted_data, 3, sd, na.rm = TRUE)\n",
    "\n",
    "X_scale = (X_max-X_min)\n",
    "X_scale[X_scale == 0] = 1 #prevent NAs if only one value\n",
    "X = sweep(sweep(X_data, 3, X_min, \"-\"), 3, X_scale, \"/\")\n",
    "y_gutted = sweep(sweep(y_gutted_data, 3, y_mean, \"-\"), 3, y_sd, \"/\")\n",
    "\n",
    "\n",
    "time_step_multi <- 12/every_x_months\n",
    "\n",
    "\n",
    "#don't want to be modelling the *observations* at each time point, which nimble mgitht ry to do even for all the NAs\n",
    "#so we flatten y into a 1d array only containing the actual observations\n",
    "#but then we need several arrays which allow us to relearn which patient/timestep/output each eentry is:\n",
    "\n",
    "y_gutted_reshape <- as.numeric(y_gutted)\n",
    "n_matrix <- y_gutted\n",
    "for (n in 1:dim(n_matrix)[1]){\n",
    "  n_matrix[n,,] = n\n",
    "}\n",
    "n_reshape <- as.numeric(n_matrix)\n",
    "\n",
    "t_matrix <- y_gutted\n",
    "for (t in 1:dim(t_matrix)[2]){\n",
    "  t_matrix[,t,] = t\n",
    "}\n",
    "t_reshape <- as.numeric(t_matrix)\n",
    "\n",
    "out_matrix <- y_gutted\n",
    "for (out in 1:dim(out_matrix)[3]){\n",
    "  out_matrix[,,out] = out\n",
    "}\n",
    "out_reshape <- as.numeric(out_matrix)\n",
    "\n",
    "y_gutted_reshape_isna = which(!is.na(y_gutted_reshape))\n",
    "y_gutted_reshape = y_gutted_reshape[y_gutted_reshape_isna]\n",
    "n_reshape = n_reshape[y_gutted_reshape_isna]\n",
    "t_reshape = t_reshape[y_gutted_reshape_isna]\n",
    "out_reshape = out_reshape[y_gutted_reshape_isna]\n",
    "\n",
    "#Due to castastrophic difficulties with indexing in nimble I have resorted to using these ad-hoc, hacky indexers to get it to work\n",
    "#I've forgotten what most of them do to be honest but I managed to get it to work somehow\n",
    "#Good luck to anyone in the future tying to figure out what is going on\n",
    "#I've tried to annotate some of it to help out but idk\n",
    "#Feel free to contact me (Victor Applebaum) if you have any questions but I will probaly have forgotten most of it by the time you're looking at this\n",
    "\n",
    "n_data_ids <- rep(NA,N_patients)\n",
    "for (n in 1:N_patients){\n",
    "    n_data_ids[n] <- sum(n_reshape==n)\n",
    "}\n",
    "\n",
    "#Ok so some of the patients have had there results removed for some reason, and the whole thing crashes when this happened\n",
    "#So we create a new number, N_pat_with_points, which is like N_patients but only those that have points\n",
    "#We can then use i_n[n] for 1:N_pat_with_points to point to the nth patient that actually has points\n",
    "n_pat_with_points <- c()\n",
    "for (n in 1:N_patients){\n",
    "    if (length(n_reshape[n_reshape==n])>0){\n",
    "        n_pat_with_points <- append(n_pat_with_points,n)\n",
    "    }\n",
    "}\n",
    "i_n <- rep(NA,length(n_pat_with_points))\n",
    "for (i in 1:length(n_pat_with_points)){\n",
    "    i_n[i] <- (1:N_patients)[n_pat_with_points[i]]\n",
    "}\n",
    "N_pat_with_points <- length(n_pat_with_points)\n",
    "\n",
    "i <- nimMatrix(NA,N_patients,max(n_data_ids))#indexing matrix for patients i[n,i_ind]= position of i_ind'th point for nth patient\n",
    "for (n in 1:N_patients){\n",
    "    if (length((1:length(n_reshape))[n_reshape==n])>0){\n",
    "        data_n <- c()\n",
    "        for (data in 1:length(n_reshape)){\n",
    "            if (n_reshape[data] == n){\n",
    "                data_n <- append(data_n,data)\n",
    "            }\n",
    "        }\n",
    "        for (i_ind in 1:length(data_n)){\n",
    "            i[n,i_ind] <- data_n[i_ind]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "j <- nimArray(NA,dim = c(N_patients,N_cols,max(n_data_ids)))#indexes both patient and outcome j[n,m,i_ind] position of i_ind'th point for nth patient's mth outcome\n",
    "for (n in 1:N_patients){\n",
    "    for (m in 1:N_cols){\n",
    "        if (length((1:length(n_reshape))[n_reshape==n & out_reshape==m])>0){\n",
    "            data_n <- c()\n",
    "            for (data in 1:length(n_reshape)){\n",
    "                if (n_reshape[data] == n & out_reshape[data] == m){\n",
    "                    data_n <- append(data_n,data)\n",
    "                }\n",
    "            }\n",
    "            for (i_ind in 1:length(data_n)){\n",
    "                j[n,m,i_ind] <- data_n[i_ind]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "i_j <- nimMatrix(NA,N_patients,N_cols)#number of points avaliable for the patient n's mth outcome\n",
    "for (n in 1:N_patients){\n",
    "    for (m in 1:N_cols){\n",
    "        i_j[n,m] <- sum(is.na(j[n,m,])==FALSE)\n",
    "    }\n",
    "}\n",
    "y_real_reindexed=nimArray(NA,dim=c(N_patients,N_cols,length(y_gutted_reshape)))#rearranges y which i need for some reason\n",
    "for (n in 1:N_pat_with_points){\n",
    "    for (output in 1:N_cols){\n",
    "      for (data in 1:i_j[i_n[n],output]){\n",
    "          y_real_reindexed[i_n[n],output,data] <- y_gutted_reshape[j[i_n[n],output,data]]\n",
    "\n",
    "      }\n",
    "    }\n",
    "}\n",
    "\n",
    "i_out <- nimMatrix(NA,N_patients,N_cols)\n",
    "i_out_num <- nimArray(NA,dim=c(N_patients))\n",
    "for (n in 1:N_patients){\n",
    "    counter <- 0\n",
    "    for (output in 1:N_cols){\n",
    "        if (i_j[n,output] > 1){\n",
    "            counter <- counter + 1\n",
    "            i_out[n,counter] <- output\n",
    "        }\n",
    "    }\n",
    "    i_out_num[n] <- sum(!is.na(i_out[n,]))\n",
    "}\n",
    "i_out_1 <- nimMatrix(NA,N_patients,N_cols)\n",
    "i_out_num_1 <- nimArray(NA,dim=c(N_patients))\n",
    "for (n in 1:N_patients){\n",
    "    counter <- 0\n",
    "    for (output in 1:N_cols){\n",
    "        if (i_j[n,output] == 1){\n",
    "            counter <- counter + 1\n",
    "            i_out_1[n,counter] <- output\n",
    "        }\n",
    "    }\n",
    "    i_out_num_1[n] <- sum(!is.na(i_out_1[n,]))\n",
    "}\n",
    "\n",
    "\n",
    "starts_mat <- nimArray(NA,c(N_pat_with_points,N_cols))#At some point things have to go in a big matrix, we need these two to tell us the positions we should be working in\n",
    "ends_mat <- nimArray(NA,c(N_pat_with_points,N_cols))\n",
    "for (n in 1:N_pat_with_points){\n",
    "    for (m in 1:N_cols){\n",
    "        if (m == 1 & n == 1){\n",
    "            starts <- c(1)\n",
    "            ends <- c(i_j[i_n[n],m])\n",
    "        }\n",
    "        starts <- append(starts,ends[length(ends)]+1)\n",
    "        ends <- append(ends,i_j[i_n[n],m]+starts[length(starts)]-1)\n",
    "        ends_mat[n,m] <- ends[length(ends)-1]\n",
    "        starts_mat[n,m] <- ends_mat[n,m]-i_j[i_n[n]]+1\n",
    "    }\n",
    "}\n",
    "\n",
    "starts_mat <- nimArray(NA,c(N_pat_with_points,N_cols))#At some point things have to go in a big matrix, we need these two to tell us the positions we should be working in\n",
    "ends_mat <- nimArray(NA,c(N_pat_with_points,N_cols))\n",
    "rolling_sum <- 0\n",
    "for (n in 1:N_pat_with_points){\n",
    "    for (m in 1:N_cols){\n",
    "        starts_mat[n,m] <- rolling_sum + 1\n",
    "        ends_mat[n,m] <- starts_mat[n,m] + i_j[i_n[n],m]-1\n",
    "        rolling_sum <- rolling_sum + i_j[i_n[n],m]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6c02e1-d3d6-46e8-a65c-033b672f33bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit all validation individuals\n",
    "    softplus_nimble <- nimbleFunction(\n",
    "      run = function(x = double(0)){\n",
    "        return(log(1+exp(x)))\n",
    "        returnType(double(0))\n",
    "      })\n",
    "          #nimble function required for getting LKJ correlation matrix\n",
    "      uppertri_mult_diag <- nimbleFunction(\n",
    "        run = function(mat = double(2), vec = double(1)) {\n",
    "          returnType(double(2))\n",
    "          p <- length(vec)\n",
    "          out <- matrix(nrow = p, ncol = p, init = FALSE)\n",
    "          for(i in 1:p)\n",
    "            out[ , i] <- mat[ , i] * vec[i]\n",
    "          return(out)\n",
    "        })\n",
    "      cuppertri_mult_diag <- compileNimble(uppertri_mult_diag)\n",
    "\n",
    "    state_model_consts <- list(N_covs = N_covs, #Number of covariances (something to do with treatments)?\n",
    "                           N_cols = N_cols, #Number of outputs (3)\n",
    "                           N_patients = N_patients, #Number of patients\n",
    "                           X = X,#Something to do with treatments\n",
    "                           N_data = length(y_gutted_reshape), #Number of data points\n",
    "                           n_reshape = n_reshape,#Patient identifiers for each point\n",
    "                           t_reshape = t_reshape,#Time for each point\n",
    "                           out_reshape = out_reshape,#Identifier for output\n",
    "                           timesteps_per_year = 12/every_x_months,\n",
    "                           mature_age_steps = (20-init_age)*12/every_x_months,\n",
    "                           milestone_age_steps = (15-init_age)*12/every_x_months,\n",
    "                           n_data_ids = n_data_ids,#number of points for each patient\n",
    "                           i = i, #indexing matrix for patients i[n,i_ind]= position of i_ind'th point for nth patient\n",
    "                           n_pat_with_points = n_pat_with_points,\n",
    "                           i_n = i_n,\n",
    "                           N_pat_with_points =N_pat_with_points,\n",
    "                           j = j, #indexes both patient and outcome j[n,m,i_ind] position of i_ind'th point for nth patient's mth outcome\n",
    "                           i_j = i_j,\n",
    "                           starts_mat = starts_mat,\n",
    "                           ends_mat = ends_mat,\n",
    "                           i_out = i_out,\n",
    "                           i_out_num = i_out_num,\n",
    "                           i_out_1 = i_out_1,\n",
    "                           i_out_num_1 = i_out_num_1,\n",
    "                               pop_par_mean = pop_par_mean,\n",
    "                               pop_par_cov = pop_par_cov\n",
    "                          )\n",
    "\n",
    "    state_model_data <-  list(y = y_real_reindexed)\n",
    "    \n",
    "    parinit <- rmvnorm(1,pop_par_mean,pop_par_cov)\n",
    "    \n",
    "    inits <- list(gp_rho = array(1,c(N_patients,N_cols)),\n",
    "                  gp_alpha = array(1,c(N_patients,N_cols)),\n",
    "                  gp_sigma = array(1,c(N_patients,N_cols)),\n",
    "                  parameters = parinit\n",
    "                  )\n",
    "\n",
    "    Monitors = c(\"delta\",\n",
    "                      \"Delta\",\n",
    "                      \"beta_1\",\n",
    "                      \"alpha_1\",\n",
    "                      \"disease\",\n",
    "                      \"state\",\n",
    "                      'mature_state',\n",
    "                      \"Treat\",\n",
    "                      'init_disease_when',\n",
    "                     'state',\n",
    "                     'parameters',\n",
    "                     'gp_alpha','gp_rho','gp_sigma'\n",
    "                     )\n",
    "\n",
    "\n",
    "\n",
    "        samples <- nimbleMCMC(code = state_model_code,\n",
    "                   constants = state_model_consts,\n",
    "                   data = state_model_data,\n",
    "                   monitors = Monitors,\n",
    "                   niter = 200000,\n",
    "                   nburnin = 100000,\n",
    "                   thin = 100,\n",
    "                   nchains = 2,\n",
    "                   samplesAsCodaMCMC = TRUE)\n",
    "\n",
    "    save(samples,file = paste0('Samples','.RData'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11dc990-8069-471d-bbbb-92ef299fb3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "load('Samples.RData')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b1416b-4af8-4475-b5d5-4b1f709abab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_merged <- data.frame(do.call('rbind',samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e06cc51-f4d6-4f5c-a284-1290ba50c88b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Start getting plots of results for specific patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620db222-ee4b-4cc3-a68f-afd4f6259a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (load_results == FALSE){\n",
    "    \n",
    "#Function to find a posterior for a gp\n",
    "GP_posterior_sek <- function(X,Y,xstar,prior_func=pm,prior_evaluated=H,rh,alp,sig){\n",
    "  S21 <- ExpSqrKer(xstar,X,alp,rh)\n",
    "  S11 <- ExpSqrKer(X,X,alp,rh) + diag(sig^2,length(X))\n",
    "  mup <- prior_func + (S21) %*% chol2inv(chol(S11)) %*% (Y[!is.na(Y)] - prior_evaluated)\n",
    "  S22 <-ExpSqrKer(xstar,xstar,alp,rh)\n",
    "  Sigmap <-  (S22 - S21 %*% chol2inv(chol(S11)) %*% t(S21))\n",
    "  \n",
    "  return(list(\"mean_func\"=mup,\"uncertainty\"=Sigmap))\n",
    "}\n",
    "#Kernel definition\n",
    "ExpSqrKer <- function(InVector1,InVector2,Alpha,Rho){\n",
    "  return((Alpha^2)*exp(-distance(as.array(InVector1),as.array(InVector2))/(Rho^2)))\n",
    "}\n",
    "softplus_nimble <- nimbleFunction(\n",
    "  run = function(x = double(0)){\n",
    "    return(log(1+exp(x)))\n",
    "    returnType(double(0))\n",
    "  })\n",
    "\n",
    "\n",
    "#plot nsaa trajectory for a patient\n",
    "col_i = 1\n",
    "\n",
    "#counters for checking test points in the intervals\n",
    "test_points_in <- rep(0,99)\n",
    "test_points_tot <- rep(0,99)\n",
    "\n",
    "#observations for sharpnesses at sharpness_interval by number of points\n",
    "sharpness_interval <- 0.95\n",
    "sharpness_interval2 <- 0.7\n",
    "num_points <- array(NA,N_valid)\n",
    "for (individual in 1:N_valid){num_points[individual] = length((1:69)[!is.na(y_gutted_data[individual, , col_i])])}\n",
    "sharpnesses <- array(NA,dim=c(N_valid,max(num_points)+1))\n",
    "sharpnesses2 <- array(NA,dim=c(N_valid,max(num_points)+1))\n",
    "sharpness_count <- array(0,dim=c(max(num_points))+1)\n",
    "\n",
    "\n",
    "for (n in 1:N_valid){\n",
    "\n",
    "    #extract needed parts from model\n",
    "    N_timesteps_t_max = 69\n",
    "    state <- as.matrix(select(select(samples_merged,starts_with(paste0(\"state.\",n, \"..\"))), ends_with(paste0(\"..\",col_i, \".\"))))\n",
    "    gp_alpha <- as.matrix(select(select(samples_merged,contains(paste0(\"gp_alpha.\", n, \"..\"))), ends_with(paste0(\"..\",col_i, \".\"))))\n",
    "    gp_rho <- as.matrix(select(select(samples_merged,contains(paste0(\"gp_rho.\", n, \"..\"))), ends_with(paste0(\"..\",col_i, \".\"))))\n",
    "    gp_sigma <- as.matrix(select(select(samples_merged,contains(paste0(\"gp_sigma.\", n, \"..\"))), ends_with(paste0(\"..\",col_i, \".\"))))\n",
    "    disease = as.matrix(select(samples_merged,contains(paste0(\"disease.\",n, \".\"))))\n",
    "    beta = as.matrix(select(select(samples_merged,contains(paste0(\"beta_1.\", n, \"..\"))), ends_with(paste0(\"..\",col_i, \".\"))))\n",
    "\n",
    "    y_n = state - beta[row(disease)]*softplus_nimble(disease)\n",
    "    for (iter in 1:dim(y_n)[1]){#add GP\n",
    "        if (length(t_reshape[n_reshape == n & out_reshape == col_i]) > 0){\n",
    "            gp = GP_posterior_sek(X = t_reshape[n_reshape == n & out_reshape == col_i],\n",
    "                             Y = y_gutted_reshape[n_reshape == n & out_reshape == col_i],\n",
    "                             xstar = 1:69,\n",
    "                             prior_func= y_n[iter,],\n",
    "                             prior_evaluated= y_n[iter,t_reshape[n_reshape == n & out_reshape == col_i]],\n",
    "                             gp_rho[iter,],\n",
    "                             gp_alpha[iter,],\n",
    "                             gp_sigma[iter,])\n",
    "            y_n[iter,] <- rmvnorm(1,gp$mean_func,gp$uncertainty)\n",
    "        } else {\n",
    "            y_n[iter,] <- rmvnorm(1,y_n[iter,],ExpSqrKer(1:69,1:69,gp_alpha[iter],gp_rho[iter,])+diag(gp_sigma[iter,]^2,69))\n",
    "        }\n",
    "    }\n",
    "    y_n = y_n*y_sd[col_i] + y_mean[col_i]#unstandardise\n",
    "    y_n = NSAA_itransformer(y_n)\n",
    "\n",
    "    q_025_n = apply(y_n[,1:69], 2, quantile, 0.025, na.rm = T)\n",
    "    q_15_n = apply(y_n[,1:69], 2, quantile, 0.15, na.rm = T)\n",
    "    q_5_n = apply(y_n[,1:69], 2, quantile, 0.5, na.rm = T)\n",
    "    q_85_n = apply(y_n[,1:69], 2, quantile, 0.85, na.rm = T)\n",
    "    q_975_n = apply(y_n[,1:69], 2, quantile, 0.975, na.rm = T)\n",
    "\n",
    "    time <- init_age+(1:69)*(every_x_months/12)\n",
    "     N_timesteps_t_max = apply(N_timesteps_t,1, max)\n",
    "    \n",
    "    \n",
    "      #Plot\n",
    "    if (plot_preds == TRUE){\n",
    "  print(\n",
    "    #With GP\n",
    "    ggplot() +\n",
    "      geom_ribbon(aes(x=init_age+(1:69)*(every_x_months/12),\n",
    "                      ymin= q_15_n,\n",
    "                      ymax= q_85_n),\n",
    "                  alpha = 0.5,\n",
    "                  xmin=0,\n",
    "                  xmax=270,\n",
    "                  fill = 'lightseagreen')+\n",
    "      geom_ribbon(aes(x=init_age+(1:69)*(every_x_months/12),\n",
    "                      ymin= q_85_n,\n",
    "                      ymax= q_975_n),\n",
    "                  alpha = 0.5,\n",
    "                  xmin=0,\n",
    "                  xmax=270,\n",
    "                  fill = 'lightskyblue')+\n",
    "      geom_ribbon(aes(x=init_age+(1:69)*(every_x_months/12),\n",
    "                      ymin= q_025_n,\n",
    "                      ymax= q_15_n),\n",
    "                  alpha = 0.5,\n",
    "                  xmin=0,\n",
    "                  xmax=270,\n",
    "                  fill = 'lightskyblue')+\n",
    "      geom_line(aes(x=init_age+(1:N_timesteps_t_max[n])*(every_x_months/12), y = q_5_n), col='black',size=3) +#GP posterior mean\n",
    "      geom_point(aes(x=init_age+(1:N_timesteps)*(every_x_months/12), y = y_data[n, , col_i]), size=4, col='red') +#Test points\n",
    "      geom_point(aes(x=init_age+(1:N_timesteps)*(every_x_months/12), y = NSAA_itransformer(y_gutted_data[n, , col_i])), size=4, col='blue') +#Design points\n",
    "      #ggtitle(paste(\"Patient\", n ,\"NSAA prediction\"))+\n",
    "      coord_cartesian(ylim = c(0,35), xlim = c(min(time),max(time)))+\n",
    "      labs(x='Years since birth', y='NSAA score')+\n",
    "      theme(text = element_text(size = 25,colour='#003D3C'))\n",
    "  )\n",
    "    ggsave(paste0(\"RERUN_NSAA/NSAA_pred\", n, \".pdf\"))\n",
    "\n",
    "    }\n",
    "          #Check number of test points inside each interval\n",
    "      for (interval in 1:99){#for each interval\n",
    "          upper <- apply(y_n[,1:N_timesteps_t_max[n]], 2, quantile, 1-(1-interval/100)/2, na.rm = T)\n",
    "          lower <-  apply(y_n[,1:N_timesteps_t_max[n]], 2, quantile, (1-interval/100)/2, na.rm = T)\n",
    "          for (point in (1:69)[!is.na(y_data[n, , col_i])]){\n",
    "              \n",
    "              if (y_data[n, point, col_i] < upper[point] & y_data[n, point, col_i] > lower[point] & !(point %in% (1:69)[!is.na(y_gutted_data[n, , col_i])])){\n",
    "                  test_points_in[interval] <- test_points_in[interval] +1\n",
    "              }\n",
    "              \n",
    "              if (!is.na(y_data[n, point, col_i]) & !(point %in% (1:69)[!is.na(y_gutted_data[n, , col_i])])){\n",
    "                  test_points_tot[interval] <- test_points_tot[interval] +1\n",
    "              }\n",
    "          }\n",
    "          #also evaluate sharpness\n",
    "          if (interval/100 == sharpness_interval){\n",
    "              sharpnesses[n,length((1:69)[!is.na(y_gutted_data[n, , col_i])])+1] <- mean(upper-lower)\n",
    "              sharpness_count[length((1:69)[!is.na(y_gutted_data[n, , col_i])])+1] <- sharpness_count[length((1:69)[!is.na(y_gutted_data[n, , col_i])])+1] + 1\n",
    "          }\n",
    "          if (interval/100 == sharpness_interval2){\n",
    "              sharpnesses2[n,length((1:69)[!is.na(y_gutted_data[n, , col_i])])+1] <- mean(upper-lower)\n",
    "          }\n",
    "      }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bfad9e-a95c-4f71-accb-2d1e627e2432",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_results <- TRUE\n",
    "\n",
    "if (load_results == TRUE){\n",
    "    load('NSAA_sharpnesses.RData')\n",
    "    load('sharpness_count.RData')\n",
    "    load('test_points_in.RData')\n",
    "    load('test_points_tot.RData')\n",
    "}\n",
    "\n",
    "\n",
    "#plot quantile coverage\n",
    "ggplot()+\n",
    "    geom_line(aes(x=(1:99)/100, y = (1:99)/100), col='black',size=3)+\n",
    "    geom_line(aes(x=(1:99)/100, y = test_points_in/test_points_tot), col='lightseagreen',size=3)+\n",
    "    labs(x='Prediction Interval', y='Proportion Validation Points Contained')+\n",
    "    theme(text = element_text(size = 25,colour='#003D3C'),legend.position=\"top\")+\n",
    "    scale_color_manual(breaks=c('Model', 'Target'),\n",
    "                     values=c('Model'='lightseagreen', 'Target'='black'))#\n",
    "    ggsave(paste0(\"AnalysisPlots/NSAAQuantileCoverage\", \".pdf\"))\n",
    "\n",
    "#Determine sharpness\n",
    "\n",
    "sharpness_means <- array(NA,dim(sharpnesses)[2])\n",
    "for (no_points_s in 1:dim(sharpnesses)[2]){\n",
    "    sharpness_means[no_points_s] <- mean(sharpnesses[,no_points_s],na.rm = TRUE)\n",
    "}\n",
    "sharpness_means2 <- array(NA,dim(sharpnesses2)[2])\n",
    "for (no_points_s in 1:dim(sharpnesses2)[2]){\n",
    "    sharpness_means2[no_points_s] <- mean(sharpnesses2[,no_points_s],na.rm = TRUE)\n",
    "}\n",
    "\n",
    "print(paste('The sum abs differences from desired quantile coverage is',sum(abs(test_points_in/test_points_tot - (1:99)/100))))\n",
    "\n",
    "sharpness_grouped <- array(NA,4)\n",
    "sharpness_grouped[1] <- sharpness_means[1] * sharpness_count[1] / sum(sharpness_count[1])\n",
    "sharpness_grouped[2] <- sum(sharpness_means[2:4] * sharpness_count[2:4]) / sum(sharpness_count[2:4])\n",
    "sharpness_grouped[3] <- sum(sharpness_means[5:8] * sharpness_count[5:8]) / sum(sharpness_count[5:8])\n",
    "sharpness_grouped[4] <- sum(sharpness_means[9:length(sharpness_means)] * sharpness_count[9:length(sharpness_means)],na.rm=TRUE) / sum(sharpness_count[9:length(sharpness_means)],na.rm=TRUE)\n",
    "print('Grouped together, the 95% mean prediction intervals are:')\n",
    "sharpness_grouped\n",
    "print('MCIDs:')\n",
    "sharpness_grouped/3.5\n",
    "\n",
    "sharpness2_grouped <- array(NA,4)\n",
    "sharpness2_grouped[1] <- sharpness_means2[1] * sharpness_count[1] / sum(sharpness_count[1])\n",
    "sharpness2_grouped[2] <- sum(sharpness_means2[2:4] * sharpness_count[2:4]) / sum(sharpness_count[2:4])\n",
    "sharpness2_grouped[3] <- sum(sharpness_means2[5:8] * sharpness_count[5:8]) / sum(sharpness_count[5:8])\n",
    "sharpness2_grouped[4] <- sum(sharpness_means2[9:length(sharpness_means2)] * sharpness_count[9:length(sharpness_means2)],na.rm=TRUE) / sum(sharpness_count[9:length(sharpness_means2)],na.rm=TRUE)\n",
    "print('Grouped together, the 70% mean prediction intervals are:')\n",
    "sharpness2_grouped\n",
    "print('MCIDs:')\n",
    "sharpness2_grouped/3.5\n",
    "\n",
    "if (save_results == TRUE){\n",
    "    save(sharpnesses,file='NSAA_sharpnesses.RData')\n",
    "    save(sharpness_count,file='sharpness_count.RData')\n",
    "    save(test_points_in,file='test_points_in.RData')\n",
    "    save(test_points_tot,file='test_points_tot.RData')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f84b502-ea93-4dc9-814b-abf041921169",
   "metadata": {},
   "source": [
    "#### Walk time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dd296b-3ef1-4128-b811-26d3809e3000",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (load_results == FALSE){\n",
    "    \n",
    "#Function to find a posterior for a gp\n",
    "GP_posterior_sek <- function(X,Y,xstar,prior_func=pm,prior_evaluated=H,rh,alp,sig){\n",
    "  S21 <- ExpSqrKer(xstar,X,alp,rh)\n",
    "  S11 <- ExpSqrKer(X,X,alp,rh) + diag(sig^2,length(X))\n",
    "  mup <- prior_func + (S21) %*% chol2inv(chol(S11)) %*% (Y[!is.na(Y)] - prior_evaluated)\n",
    "  S22 <-ExpSqrKer(xstar,xstar,alp,rh)\n",
    "  Sigmap <-  (S22 - S21 %*% chol2inv(chol(S11)) %*% t(S21))\n",
    "  \n",
    "  return(list(\"mean_func\"=mup,\"uncertainty\"=Sigmap))\n",
    "}\n",
    "#Kernel definition\n",
    "ExpSqrKer <- function(InVector1,InVector2,Alpha,Rho){\n",
    "  return((Alpha^2)*exp(-distance(as.array(InVector1),as.array(InVector2))/(Rho^2)))\n",
    "}\n",
    "softplus_nimble <- nimbleFunction(\n",
    "  run = function(x = double(0)){\n",
    "    return(log(1+exp(x)))\n",
    "    returnType(double(0))\n",
    "  })\n",
    "\n",
    "\n",
    "#plot nsaa trajectory for a patient\n",
    "col_i = 2\n",
    "\n",
    "#counters for checking test points in the intervals\n",
    "test_points_in_w <- rep(0,99)\n",
    "test_points_tot_w <- rep(0,99)\n",
    "\n",
    "    \n",
    "#observations for sharpnesses at sharpness_interval by number of points\n",
    "sharpness_interval <- 0.95\n",
    "sharpness_interval2 <- 0.7\n",
    "num_points_w <- array(NA,N_valid)\n",
    "for (individual in 1:N_valid){num_points_w[individual] = length((1:69)[!is.na(y_gutted_data[individual, , col_i])])}\n",
    "sharpnesses_w <- array(NA,dim=c(N_valid,max(num_points_w)+1))\n",
    "sharpnesses_w2 <- array(NA,dim=c(N_valid,max(num_points_w)+1))\n",
    "sharpness_count_w <- array(0,dim=c(max(num_points_w))+1)\n",
    "\n",
    "\n",
    "for (n in 1:N_valid){\n",
    "\n",
    "    #extract needed parts from model\n",
    "    N_timesteps_t_max = 69\n",
    "    state <- as.matrix(select(select(samples_merged,starts_with(paste0(\"state.\",n, \"..\"))), ends_with(paste0(\"..\",col_i, \".\"))))\n",
    "    gp_alpha <- as.matrix(select(select(samples_merged,contains(paste0(\"gp_alpha.\", n, \"..\"))), ends_with(paste0(\"..\",col_i, \".\"))))\n",
    "    gp_rho <- as.matrix(select(select(samples_merged,contains(paste0(\"gp_rho.\", n, \"..\"))), ends_with(paste0(\"..\",col_i, \".\"))))\n",
    "    gp_sigma <- as.matrix(select(select(samples_merged,contains(paste0(\"gp_sigma.\", n, \"..\"))), ends_with(paste0(\"..\",col_i, \".\"))))\n",
    "    disease = as.matrix(select(samples_merged,contains(paste0(\"disease.\",n, \".\"))))\n",
    "    beta = as.matrix(select(select(samples_merged,contains(paste0(\"beta_1.\", n, \"..\"))), ends_with(paste0(\"..\",col_i, \".\"))))\n",
    "\n",
    "    y_n = state - beta[row(disease)]*softplus_nimble(disease)\n",
    "    for (iter in 1:dim(y_n)[1]){#add GP\n",
    "        if (length(t_reshape[n_reshape == n & out_reshape == col_i]) > 0){\n",
    "            gp = GP_posterior_sek(X = t_reshape[n_reshape == n & out_reshape == col_i],\n",
    "                             Y = y_gutted_reshape[n_reshape == n & out_reshape == col_i],\n",
    "                             xstar = 1:69,\n",
    "                             prior_func= y_n[iter,],\n",
    "                             prior_evaluated= y_n[iter,t_reshape[n_reshape == n & out_reshape == col_i]],\n",
    "                             gp_rho[iter,],\n",
    "                             gp_alpha[iter,],\n",
    "                             gp_sigma[iter,])\n",
    "            y_n[iter,] <- rmvnorm(1,gp$mean_func,gp$uncertainty)\n",
    "        } else {\n",
    "            y_n[iter,] <- rmvnorm(1,y_n[iter,],ExpSqrKer(1:69,1:69,gp_alpha[iter],gp_rho[iter,])+diag(gp_sigma[iter,]^2,69))\n",
    "        }\n",
    "    }\n",
    "    y_n = y_n*y_sd[col_i] + y_mean[col_i]#unstandardise\n",
    "    y_n = positive_itransformer(y_n)\n",
    "\n",
    "    q_025_n = apply(y_n[,1:69], 2, quantile, 0.025, na.rm = T)\n",
    "    q_15_n = apply(y_n[,1:69], 2, quantile, 0.15, na.rm = T)\n",
    "    q_5_n = apply(y_n[,1:69], 2, quantile, 0.5, na.rm = T)\n",
    "    q_85_n = apply(y_n[,1:69], 2, quantile, 0.85, na.rm = T)\n",
    "    q_975_n = apply(y_n[,1:69], 2, quantile, 0.975, na.rm = T)\n",
    "\n",
    "    time <- init_age+(1:69)*(every_x_months/12)\n",
    "     N_timesteps_t_max = apply(N_timesteps_t,1, max)\n",
    "      #Plot\n",
    "    if (plot_preds == TRUE){\n",
    "  print(\n",
    "    #With GP\n",
    "    ggplot() +\n",
    "      geom_ribbon(aes(x=time,\n",
    "                      ymin= q_15_n,\n",
    "                      ymax= q_85_n),\n",
    "                  alpha = 0.5,\n",
    "                  xmin=0,\n",
    "                  xmax=270,\n",
    "                  fill = 'lightseagreen')+\n",
    "            geom_ribbon(aes(x=time,\n",
    "                      ymin= q_85_n,\n",
    "                      ymax= q_975_n),\n",
    "                  alpha = 0.5,\n",
    "                  xmin=0,\n",
    "                  xmax=270,\n",
    "                  fill = 'lightskyblue')+\n",
    "      geom_ribbon(aes(x=time,\n",
    "                      ymin= q_025_n,\n",
    "                      ymax= q_15_n),\n",
    "                  alpha = 0.5,\n",
    "                  xmin=0,\n",
    "                  xmax=270,\n",
    "                  fill = 'lightskyblue')+\n",
    "      geom_line(aes(x=init_age+(1:N_timesteps)*(every_x_months/12), y = q_5_n), col='black',size=3) +#GP posterior mean\n",
    "      geom_point(aes(x=init_age+(1:N_timesteps)*(every_x_months/12), y = y_data[n, , col_i]), size=4, col='red') +#Test points\n",
    "      geom_point(aes(x=init_age+(1:N_timesteps)*(every_x_months/12), y = positive_itransformer(y_gutted_data[n, , col_i])), size=4, col='blue') +#Design points\n",
    "      #ggtitle(paste(\"Patient\", n ,\"rise from floor time prediction\"))+\n",
    "      \n",
    "      coord_cartesian(ylim = c(0,35), xlim = c(min(time),max(time)))+\n",
    "      labs(x='Years since birth', y='Walk time (s)')+\n",
    "      theme(text = element_text(size = 25,colour='#003D3C'))\n",
    "  )\n",
    "      ggsave(paste0(\"RERUN_walk/walk_pred\", n, \".pdf\"))\n",
    "\n",
    "    }\n",
    "\n",
    "              #Check number of test points inside each interval\n",
    "      for (interval in 1:99){#for each interval\n",
    "          upper <- apply(y_n[,1:N_timesteps], 2, quantile, 1-(1-interval/100)/2, na.rm = T)\n",
    "          lower <-  apply(y_n[,1:N_timesteps], 2, quantile, (1-interval/100)/2, na.rm = T)\n",
    "          for (point in (1:69)[!is.na(y_data[n, , col_i])]){\n",
    "              \n",
    "              if (y_data[n, point, col_i] < upper[point] & y_data[n, point, col_i] > lower[point] & !(point %in% (1:69)[!is.na(y_gutted_data[n, , col_i])])){\n",
    "                  test_points_in_w[interval] <- test_points_in_w[interval] +1\n",
    "              }\n",
    "              \n",
    "              if (!is.na(y_data[n, point, col_i]) & !(point %in% (1:69)[!is.na(y_gutted_data[n, , col_i])])){\n",
    "                  test_points_tot_w[interval] <- test_points_tot_w[interval] +1\n",
    "              }\n",
    "          }\n",
    "          #also evaluate sharpness\n",
    "          if (interval/100 == sharpness_interval){\n",
    "              sharpnesses_w[n,length((1:69)[!is.na(y_gutted_data[n, , col_i])])+1] <- mean(upper-lower)\n",
    "              sharpness_count_w[length((1:69)[!is.na(y_gutted_data[n, , col_i])])+1] <- sharpness_count_w[length((1:69)[!is.na(y_gutted_data[n, , col_i])])+1] + 1\n",
    "          }\n",
    "          if (interval/100 == sharpness_interval2){\n",
    "              sharpnesses_w2[n,length((1:69)[!is.na(y_gutted_data[n, , col_i])])+1] <- mean(upper-lower)\n",
    "          }\n",
    "      }\n",
    "    \n",
    "    \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a93f6f9-25e0-48fd-9947-d2faf5bc2f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results <- TRUE\n",
    "\n",
    "\n",
    "if (load_results == TRUE){\n",
    "    load('Walk_sharpnesses.RData')\n",
    "    load('sharpness_count_w.RData')\n",
    "    load('test_points_in_w.RData')\n",
    "    load('test_points_tot_w.RData')\n",
    "}\n",
    "\n",
    "\n",
    "#plot quantile coverage\n",
    "ggplot()+\n",
    "    geom_line(aes(x=(1:99)/100, y = (1:99)/100), col='black',size=3)+\n",
    "    geom_line(aes(x=(1:99)/100, y = test_points_in_w/test_points_tot_w), col='lightseagreen',size=3)+\n",
    "    labs(x='Prediction Interval', y='Proportion Validation Points Contained')+\n",
    "    theme(text = element_text(size = 25,colour='#003D3C'),legend.position=\"top\")+\n",
    "    scale_color_manual(breaks=c('Model', 'Target'),\n",
    "                     values=c('Model'='lightseagreen', 'Target'='black'))\n",
    "    ggsave(\"AnalysisPlots/WalkTimeQuantileCoverage.pdf\")\n",
    "\n",
    "#Determine sharpness\n",
    "sharpness_means_w <- array(NA,dim(sharpnesses_w)[2])\n",
    "for (no_points_s in 1:dim(sharpnesses_w)[2]){\n",
    "    sharpness_means_w[no_points_s] <- mean(sharpnesses_w[,no_points_s],na.rm = TRUE)\n",
    "}\n",
    "sharpness_means_w2 <- array(NA,dim(sharpnesses_w2)[2])\n",
    "for (no_points_s in 1:dim(sharpnesses_w2)[2]){\n",
    "    sharpness_means_w2[no_points_s] <- mean(sharpnesses_w2[,no_points_s],na.rm = TRUE)\n",
    "}\n",
    "\n",
    "sharpness_grouped_w <- array(NA,4)\n",
    "sharpness_grouped_w[1] <- sharpness_means_w[1] * sharpness_count_w[1] / sum(sharpness_count_w[1])\n",
    "sharpness_grouped_w[2] <- sum(sharpness_means_w[2:4] * sharpness_count_w[2:4]) / sum(sharpness_count_w[2:4])\n",
    "sharpness_grouped_w[3] <- sum(sharpness_means_w[5:8] * sharpness_count_w[5:8]) / sum(sharpness_count_w[5:8])\n",
    "sharpness_grouped_w[4] <- sum(sharpness_means_w[9:length(sharpness_means_w)] * sharpness_count_w[9:length(sharpness_means_w)],na.rm=TRUE) / sum(sharpness_count_w[9:length(sharpness_means_w)],na.rm=TRUE)\n",
    "print('Grouped together, the 95% mean prediction intervals are:')\n",
    "sharpness_grouped_w\n",
    "print('MCIDs:')\n",
    "sharpness_grouped_w/3.5\n",
    "\n",
    "sharpness_grouped_w2 <- array(NA,4)\n",
    "sharpness_grouped_w2[1] <- sharpness_means_w2[1] * sharpness_count_w[1] / sum(sharpness_count_w[1])\n",
    "sharpness_grouped_w2[2] <- sum(sharpness_means_w2[2:4] * sharpness_count_w[2:4]) / sum(sharpness_count_w[2:4])\n",
    "sharpness_grouped_w2[3] <- sum(sharpness_means_w2[5:8] * sharpness_count_w[5:8]) / sum(sharpness_count_w[5:8])\n",
    "sharpness_grouped_w2[4] <- sum(sharpness_means_w2[9:length(sharpness_means_w2)] * sharpness_count_w[9:length(sharpness_means_w2)],na.rm=TRUE) / sum(sharpness_count_w[9:length(sharpness_means_w2)],na.rm=TRUE)\n",
    "print('Grouped together, the 70% mean prediction intervals are:')\n",
    "sharpness_grouped_w2\n",
    "print('MCIDs:')\n",
    "sharpness_grouped_w2/3.5\n",
    "\n",
    "\n",
    "print(paste('The sum abs differences from desired quantile coverage is',sum(abs(test_points_in_w/test_points_tot_w - (1:99)/100))))\n",
    "\n",
    "\n",
    "if (save_results == TRUE){\n",
    "    save(sharpnesses,file='Walk_sharpnesses.RData')\n",
    "    save(sharpness_count_w,file='sharpness_count_w.RData')\n",
    "    save(test_points_in_w,file='test_points_in_w.RData')\n",
    "    save(test_points_tot_w,file='test_points_tot_w.RData')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284f6b95-7dcc-4ee8-b920-2a1d1cbf1516",
   "metadata": {},
   "source": [
    "#### Rise from floor time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e55c105-2ebd-4e67-a757-b414378ea6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (load_results == FALSE){\n",
    "    \n",
    "#Function to find a posterior for a gp\n",
    "GP_posterior_sek <- function(X,Y,xstar,prior_func=pm,prior_evaluated=H,rh,alp,sig){\n",
    "  S21 <- ExpSqrKer(xstar,X,alp,rh)\n",
    "  S11 <- ExpSqrKer(X,X,alp,rh) + diag(sig^2,length(X))\n",
    "  mup <- prior_func + (S21) %*% chol2inv(chol(S11)) %*% (Y[!is.na(Y)] - prior_evaluated)\n",
    "  S22 <-ExpSqrKer(xstar,xstar,alp,rh)\n",
    "  Sigmap <-  (S22 - S21 %*% chol2inv(chol(S11)) %*% t(S21))\n",
    "  \n",
    "  return(list(\"mean_func\"=mup,\"uncertainty\"=Sigmap))\n",
    "}\n",
    "#Kernel definition\n",
    "ExpSqrKer <- function(InVector1,InVector2,Alpha,Rho){\n",
    "  return((Alpha^2)*exp(-distance(as.array(InVector1),as.array(InVector2))/(Rho^2)))\n",
    "}\n",
    "softplus_nimble <- nimbleFunction(\n",
    "  run = function(x = double(0)){\n",
    "    return(log(1+exp(x)))\n",
    "    returnType(double(0))\n",
    "  })\n",
    "\n",
    "\n",
    "#plot nsaa trajectory for a patient\n",
    "col_i = 3\n",
    "\n",
    "#counters for checking test points in the intervals\n",
    "test_points_in_rff <- rep(0,99)\n",
    "test_points_tot_rff <- rep(0,99)\n",
    "\n",
    "    \n",
    "#observations for sharpnesses at sharpness_interval by number of points\n",
    "sharpness_interval <- 0.95\n",
    "sharpness_interval2 <- 0.7\n",
    "num_points_rff <- array(NA,N_valid)\n",
    "for (individual in 1:N_valid){num_points_rff[individual] = length((1:69)[!is.na(y_gutted_data[individual, , col_i])])}\n",
    "sharpnesses_rff <- array(NA,dim=c(N_valid,max(num_points_rff)+1))\n",
    "sharpnesses_rff2 <- array(NA,dim=c(N_valid,max(num_points_rff)+1))\n",
    "sharpness_count_rff <- array(0,dim=c(max(num_points_rff))+1)\n",
    "\n",
    "\n",
    "for (n in 1:N_valid){\n",
    "\n",
    "    #extract needed parts from model\n",
    "    N_timesteps_t_max = 69\n",
    "    state <- as.matrix(select(select(samples_merged,starts_with(paste0(\"state.\",n, \"..\"))), ends_with(paste0(\"..\",col_i, \".\"))))\n",
    "    gp_alpha <- as.matrix(select(select(samples_merged,contains(paste0(\"gp_alpha.\", n, \"..\"))), ends_with(paste0(\"..\",col_i, \".\"))))\n",
    "    gp_rho <- as.matrix(select(select(samples_merged,contains(paste0(\"gp_rho.\", n, \"..\"))), ends_with(paste0(\"..\",col_i, \".\"))))\n",
    "    gp_sigma <- as.matrix(select(select(samples_merged,contains(paste0(\"gp_sigma.\", n, \"..\"))), ends_with(paste0(\"..\",col_i, \".\"))))\n",
    "    disease = as.matrix(select(samples_merged,contains(paste0(\"disease.\",n, \".\"))))\n",
    "    beta = as.matrix(select(select(samples_merged,contains(paste0(\"beta_1.\", n, \"..\"))), ends_with(paste0(\"..\",col_i, \".\"))))\n",
    "\n",
    "    y_n = state - beta[row(disease)]*softplus_nimble(disease)\n",
    "    for (iter in 1:dim(y_n)[1]){#add GP\n",
    "        if (length(t_reshape[n_reshape == n & out_reshape == col_i]) > 0){\n",
    "            gp = GP_posterior_sek(X = t_reshape[n_reshape == n & out_reshape == col_i],\n",
    "                             Y = y_gutted_reshape[n_reshape == n & out_reshape == col_i],\n",
    "                             xstar = 1:69,\n",
    "                             prior_func= y_n[iter,],\n",
    "                             prior_evaluated= y_n[iter,t_reshape[n_reshape == n & out_reshape == col_i]],\n",
    "                             gp_rho[iter,],\n",
    "                             gp_alpha[iter,],\n",
    "                             gp_sigma[iter,])\n",
    "            y_n[iter,] <- rmvnorm(1,gp$mean_func,gp$uncertainty)\n",
    "        } else {\n",
    "            y_n[iter,] <- rmvnorm(1,y_n[iter,],ExpSqrKer(1:69,1:69,gp_alpha[iter],gp_rho[iter,])+diag(gp_sigma[iter,]^2,69))\n",
    "        }\n",
    "    }\n",
    "    y_n = y_n*y_sd[col_i] + y_mean[col_i]#unstandardise\n",
    "    y_n = positive_itransformer(y_n)\n",
    "\n",
    "    q_025_n = apply(y_n[,1:69], 2, quantile, 0.025, na.rm = T)\n",
    "    q_15_n = apply(y_n[,1:69], 2, quantile, 0.15, na.rm = T)\n",
    "    q_5_n = apply(y_n[,1:69], 2, quantile, 0.5, na.rm = T)\n",
    "    q_85_n = apply(y_n[,1:69], 2, quantile, 0.85, na.rm = T)\n",
    "    q_975_n = apply(y_n[,1:69], 2, quantile, 0.975, na.rm = T)\n",
    "\n",
    "    time <- init_age+(1:69)*(every_x_months/12)\n",
    "     N_timesteps_t_max = apply(N_timesteps_t,1, max)\n",
    "      #Plot\n",
    "    if (plot_preds == TRUE){\n",
    "  print(\n",
    "    #With GP\n",
    "    ggplot() +\n",
    "      geom_ribbon(aes(x=time,\n",
    "                      ymin= q_15_n,\n",
    "                      ymax= q_85_n),\n",
    "                  alpha = 0.5,\n",
    "                  xmin=0,\n",
    "                  xmax=270,\n",
    "                  fill = 'lightseagreen')+\n",
    "            geom_ribbon(aes(x=time,\n",
    "                      ymin= q_85_n,\n",
    "                      ymax= q_975_n),\n",
    "                  alpha = 0.5,\n",
    "                  xmin=0,\n",
    "                  xmax=270,\n",
    "                  fill = 'lightskyblue')+\n",
    "      geom_ribbon(aes(x=time,\n",
    "                      ymin= q_025_n,\n",
    "                      ymax= q_15_n),\n",
    "                  alpha = 0.5,\n",
    "                  xmin=0,\n",
    "                  xmax=270,\n",
    "                  fill = 'lightskyblue')+\n",
    "      geom_line(aes(x=init_age+(1:N_timesteps)*(every_x_months/12), y = q_5_n), col='black',size=3) +#GP posterior mean\n",
    "      geom_point(aes(x=init_age+(1:N_timesteps)*(every_x_months/12), y = y_data[n, , col_i]), size=4, col='red') +#Test points\n",
    "      geom_point(aes(x=init_age+(1:N_timesteps)*(every_x_months/12), y = positive_itransformer(y_gutted_data[n, , col_i])), size=4, col='blue') +#Design points\n",
    "      #ggtitle(paste(\"Patient\", n ,\"rise from floor time prediction\"))+\n",
    "      \n",
    "      coord_cartesian(ylim = c(0,35), xlim = c(min(time),max(time)))+\n",
    "      labs(x='Years since birth', y='Rise from floor time (s)')+\n",
    "      theme(text = element_text(size = 25,colour='#003D3C'))\n",
    "  )\n",
    "      ggsave(paste0(\"RERUN_rff/rff_pred\", n, \".pdf\"))\n",
    "\n",
    "    }\n",
    "\n",
    "              #Check number of test points inside each interval\n",
    "      for (interval in 1:99){#for each interval\n",
    "          upper <- apply(y_n[,1:N_timesteps], 2, quantile, 1-(1-interval/100)/2, na.rm = T)\n",
    "          lower <-  apply(y_n[,1:N_timesteps], 2, quantile, (1-interval/100)/2, na.rm = T)\n",
    "          for (point in (1:69)[!is.na(y_data[n, , col_i])]){\n",
    "              \n",
    "              if (y_data[n, point, col_i] < upper[point] & y_data[n, point, col_i] > lower[point] & !(point %in% (1:69)[!is.na(y_gutted_data[n, , col_i])])){\n",
    "                  test_points_in_rff[interval] <- test_points_in_rff[interval] +1\n",
    "              }\n",
    "              \n",
    "              if (!is.na(y_data[n, point, col_i]) & !(point %in% (1:69)[!is.na(y_gutted_data[n, , col_i])])){\n",
    "                  test_points_tot_rff[interval] <- test_points_tot_rff[interval] +1\n",
    "              }\n",
    "          }\n",
    "          #also evaluate sharpness\n",
    "          if (interval/100 == sharpness_interval){\n",
    "              sharpnesses_rff[n,length((1:69)[!is.na(y_gutted_data[n, , col_i])])+1] <- mean(upper-lower)\n",
    "              sharpness_count_rff[length((1:69)[!is.na(y_gutted_data[n, , col_i])])+1] <- sharpness_count_rff[length((1:69)[!is.na(y_gutted_data[n, , col_i])])+1] + 1\n",
    "          }\n",
    "          if (interval/100 == sharpness_interval2){\n",
    "              sharpnesses_rff2[n,length((1:69)[!is.na(y_gutted_data[n, , col_i])])+1] <- mean(upper-lower)\n",
    "          }\n",
    "      }\n",
    "    \n",
    "    \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fb8606-54ed-4227-8459-3525c7bef48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if (load_results == TRUE){\n",
    "    load('RFF_sharpnesses.RData')\n",
    "    load('sharpness_count_rff.RData')\n",
    "    load('test_points_in_rff.RData')\n",
    "    load('test_points_tot_rff.RData')\n",
    "}\n",
    "\n",
    "#plot quantile coverage\n",
    "ggplot()+\n",
    "    geom_line(aes(x=(1:99)/100, y = (1:99)/100), col='black',size=3)+\n",
    "    geom_line(aes(x=(1:99)/100, y = test_points_in_rff/test_points_tot_rff), col='lightseagreen',size=3)+\n",
    "    labs(x='Prediction Interval', y='Proportion Validation Points Contained')+\n",
    "    theme(text = element_text(size = 25,colour='#003D3C'),legend.position=\"top\")+\n",
    "    scale_color_manual(breaks=c('Model', 'Target'),\n",
    "                     values=c('Model'='lightseagreen', 'Target'='black'))\n",
    "    ggsave(\"AnalysisPlots/RFFQuantileCoverage.pdf\")\n",
    "\n",
    "#Determine sharpness\n",
    "sharpness_means_rff <- array(NA,dim(sharpnesses_rff)[2])\n",
    "for (no_points_s in 1:dim(sharpnesses_rff)[2]){\n",
    "    sharpness_means_rff[no_points_s] <- mean(sharpnesses_rff[,no_points_s],na.rm = TRUE)\n",
    "}\n",
    "sharpness_means_rff2 <- array(NA,dim(sharpnesses_rff2)[2])\n",
    "for (no_points_s in 1:dim(sharpnesses_rff2)[2]){\n",
    "    sharpness_means_rff2[no_points_s] <- mean(sharpnesses_rff2[,no_points_s],na.rm = TRUE)\n",
    "}\n",
    "\n",
    "sharpness_grouped_rff <- array(NA,4)\n",
    "sharpness_grouped_rff[1] <- sharpness_means_rff[1] * sharpness_count_rff[1] / sum(sharpness_count_rff[1])\n",
    "sharpness_grouped_rff[2] <- sum(sharpness_means_rff[2:4] * sharpness_count_rff[2:4]) / sum(sharpness_count_rff[2:4])\n",
    "sharpness_grouped_rff[3] <- sum(sharpness_means_rff[5:8] * sharpness_count_rff[5:8]) / sum(sharpness_count_rff[5:8])\n",
    "sharpness_grouped_rff[4] <- sum(sharpness_means_rff[9:length(sharpness_means_rff)] * sharpness_count_rff[9:length(sharpness_means_rff)],na.rm=TRUE) / sum(sharpness_count_rff[9:length(sharpness_means_rff)],na.rm=TRUE)\n",
    "print('Grouped together, the 95% mean prediction intervals are:')\n",
    "sharpness_grouped_rff\n",
    "print('MCIDs:')\n",
    "sharpness_grouped_rff/3.5\n",
    "\n",
    "sharpness_grouped_rff2 <- array(NA,4)\n",
    "sharpness_grouped_rff2[1] <- sharpness_means_rff2[1] * sharpness_count_rff[1] / sum(sharpness_count_rff[1])\n",
    "sharpness_grouped_rff2[2] <- sum(sharpness_means_rff2[2:4] * sharpness_count_rff[2:4]) / sum(sharpness_count_rff[2:4])\n",
    "sharpness_grouped_rff2[3] <- sum(sharpness_means_rff2[5:8] * sharpness_count_rff[5:8]) / sum(sharpness_count_rff[5:8])\n",
    "sharpness_grouped_rff2[4] <- sum(sharpness_means_rff2[9:length(sharpness_means_rff2)] * sharpness_count_rff[9:length(sharpness_means_rff2)],na.rm=TRUE) / sum(sharpness_count_rff[9:length(sharpness_means_rff2)],na.rm=TRUE)\n",
    "print('Grouped together, the 70% mean prediction intervals are:')\n",
    "sharpness_grouped_rff2\n",
    "print('MCIDs:')\n",
    "sharpness_grouped_rff2/3.5\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(paste('The sum abs differences from desired quantile coverage is',sum(abs(test_points_in_rff/test_points_tot_rff - (1:99)/100))))\n",
    "\n",
    "\n",
    "if (save_results == TRUE){\n",
    "    save(sharpnesses,file='RFF_sharpnesses.RData')\n",
    "    save(sharpness_count,file='sharpness_count_rff.RData')\n",
    "    save(test_points_in_rff,file='test_points_in_rff.RData')\n",
    "    save(test_points_tot_rff,file='test_points_tot_rff.RData')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b7ee97-5f89-4862-b9ae-d16e9b4752cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "    softplus_nimble <- nimbleFunction(\n",
    "      run = function(x = double(0)){\n",
    "        return(log(1+exp(x)))\n",
    "        returnType(double(0))\n",
    "      })\n",
    "          #nimble function required for getting LKJ correlation matrix\n",
    "      uppertri_mult_diag <- nimbleFunction(\n",
    "        run = function(mat = double(2), vec = double(1)) {\n",
    "          returnType(double(2))\n",
    "          p <- length(vec)\n",
    "          out <- matrix(nrow = p, ncol = p, init = FALSE)\n",
    "          for(i in 1:p)\n",
    "            out[ , i] <- mat[ , i] * vec[i]\n",
    "          return(out)\n",
    "        })\n",
    "\n",
    "\n",
    "Generate_Trajectory <- function(){\n",
    "    N_covs = N_covs #Number of covariances (something to do with treatments)?\n",
    "                               N_cols = N_cols #Number of outputs (3)\n",
    "                               N_timesteps = 69 #Number of timesteps\n",
    "                               N_timesteps_t = 69 \n",
    "                               N_timesteps_t_max = 69\n",
    "                               N_patients = 1 #Number of patients\n",
    "                               X = X_train[sample(dim(X_train)[1],1),,]#Something to do with treatments\n",
    "                               N_data = length(y_gutted_reshape[n_reshape == individual]) #Number of data points\n",
    "                               n_reshape = rep(1,length(n_reshape[n_reshape == individual]))#Patient identifiers for each point\n",
    "                               t_reshape = as.array(t_reshape[n_reshape == individual])#Time for each point\n",
    "                               out_reshape = as.array(out_reshape[n_reshape == individual])#Identifier for output\n",
    "                               timesteps_per_year = 12/every_x_months\n",
    "                               mature_age_steps = (20-init_age)*12/every_x_months\n",
    "                               milestone_age_steps = (15-init_age)*12/every_x_months\n",
    "    \n",
    "    parameters <- array(NA,54)\n",
    "    parameters <- rmvnorm(1,pop_par_mean,pop_par_cov)\n",
    "    \n",
    "    #first we have to extract parameters from normal distribution using the same order that we put the in with\n",
    "    #so im writing these out manually\n",
    "    #also have to take exp of sd parameters as we logged them earlier\n",
    "    Delta_unscaled_mean <- parameters[1]\n",
    "    Delta_unscaled_sd <- exp(parameters[2])\n",
    "    init_disease_when_mean <- parameters[3]\n",
    "    init_disease_when_sd <- exp(parameters[4])\n",
    "    beta_1_unscaled_mean <- parameters[5:7]\n",
    "    beta_1_unscaled_sd <- exp(parameters[8:10])\n",
    "    alpha_1_unscaled_mean <- parameters[11:13]\n",
    "    alpha_1_unscaled_sd <- exp(parameters[14:16])\n",
    "    gp_alpha_mean <- exp(parameters[17:19])\n",
    "    gp_alpha_sd <- exp(parameters[20:22])\n",
    "    gp_rho_mean <- exp(parameters[23:25])\n",
    "    gp_rho_sd <- exp(parameters[26:28])\n",
    "    init_state_mean <- parameters[29:31]\n",
    "    init_state_sd <- exp(parameters[32:34])\n",
    "    mature_state_mean <- parameters[35:37]\n",
    "    mature_state_sd <- exp(parameters[38:40])\n",
    "    \n",
    "    cov_unscaled_mean <- parameters[41:44]\n",
    "    cov_unscaled_sd <- exp(parameters[45:48])\n",
    "    \n",
    "    gp_sigma_mean <- exp(parameters[49:51])\n",
    "    gp_sigma_sd <- exp(parameters[52:54])\n",
    "\n",
    "\n",
    "  #total up these effects (not essential code, just clearer\n",
    "    cov_effect_unscaled <- array(NA,N_covs)\n",
    "    cov_effect <- array(NA,N_covs)\n",
    "    for (cov in 1:N_covs){\n",
    "        cov_effect_unscaled[cov] <- rnorm(1,cov_unscaled_mean[cov],cov_unscaled_sd[cov])\n",
    "        cov_effect[cov] <- softplus_nimble(cov_effect_unscaled[cov])\n",
    "\n",
    "    }\n",
    "    Treat <- array(NA,69)\n",
    "    Treat[1] <-  0\n",
    "    for (t in 2:69) {\n",
    "      Treat[t] <-  inprod( (cov_effect[1:(N_covs)]), X[t - 1, 1:(N_covs)])  \n",
    "    }\n",
    "\n",
    "    \n",
    "  #disease rate of decay\n",
    "  #Delta_unscaled_mean ~ dnorm(0, sd = 1)\n",
    "  #Delta_unscaled_sd ~ T(dnorm(0, sd = 1), 0, )\n",
    "  for (n in 1:N_patients){\n",
    "    Delta_unscaled <- rnorm(1,Delta_unscaled_mean, sd = Delta_unscaled_sd)\n",
    "    Delta <- softplus_nimble(Delta_unscaled)\n",
    "  }\n",
    "  \n",
    "  #initial disease state (phi)\n",
    "  #When disease = 0?        \n",
    "    init_disease_when_unscaled <-rnorm(1,init_disease_when_mean, sd = init_disease_when_sd)\n",
    "    init_disease_when <- init_disease_when_unscaled[n]\n",
    "\n",
    "  \n",
    "  #calculate what the initial disease is for each patient\n",
    "    disease <- array(NA,69)\n",
    "  disease[1] <- -init_disease_when*Delta\n",
    "\n",
    "  #disease states (phi:)\n",
    "    \n",
    "    for (t in 2:69) {\n",
    "      disease[t] <- disease[t - 1]  + Delta - Treat[t]\n",
    "    }\n",
    "\n",
    "  \n",
    "  \n",
    "beta_1_unscaled <- array(NA,3)\n",
    "        alpha_1_unscaled <- array(NA,3)\n",
    "\n",
    " #how disease affects the different outputs\n",
    "    for (output in 1:N_cols){\n",
    "        beta_1_unscaled[output] <- rnorm(1,beta_1_unscaled_mean[output], beta_1_unscaled_sd[output] )\n",
    "    }\n",
    "  \n",
    "  #the first beta_1 can be set to 1 (note that this means, technically, the beta_params could have been 1 fewer above\n",
    "  #but nimble doesnt like 1D correlation matrices, even tho its possible)\n",
    "   beta_1 <- array(NA,N_cols)\n",
    "    beta_1[1] <- 1\n",
    " \n",
    "  for (output in 2:N_cols) {\n",
    "      beta_1[output] <- beta_1_unscaled[output]\n",
    "  }\n",
    "  \n",
    "  \n",
    "  #shape parameter for how healthy state changes over time\n",
    "    for (output in 1:N_cols){\n",
    "        alpha_1_unscaled[output] <- rnorm(1,beta_1_unscaled_mean[output], beta_1_unscaled_sd[output] )\n",
    "    }\n",
    "alpha_1 <- array(NA,N_cols)\n",
    "  for (output in 1:N_cols){\n",
    "      alpha_1[output] <- ilogit(alpha_1_unscaled[output])\n",
    "  }\n",
    "  \n",
    "  #healthy state at mature age\n",
    "    mature_state <- array(NA,3)\n",
    "      for (output in 1:N_cols){\n",
    "        mature_state[output] <- rnorm(1,mature_state_mean[output], mature_state_sd[output] )\n",
    "    }\n",
    "\n",
    "\n",
    "  \n",
    "  \n",
    "  \n",
    "  #initial healthy state (theta)\n",
    "    state <- array(NA,c(69,3))\n",
    "    for (output in 1:N_cols){\n",
    "        state[1,output] <- rnorm(1,init_state_mean[output], init_state_sd[output] )\n",
    "    }\n",
    "\n",
    "  #for (n in 1:N_patients) {\n",
    "  #  state[n, 1, 1:N_cols] ~ dmnorm(init_state_mean[1:N_cols], cholesky = init_state_cov[1:N_cols, 1:N_cols], prec_param = 0)\n",
    "  #}\n",
    "  \n",
    "  \n",
    "  #healthy states (theta):\n",
    "                   delta <- array(NA,3)\n",
    "  for (output in 1:N_cols) {\n",
    "      #from state_0, alpha_1 and the \"final\" state, we can infer what delta should be\n",
    "      #mature_state = delta + alpha*delta + alpha^2*delta + .... + alpha^(steps-1)*delta + alpha^(steps)*state_0\n",
    "      #which is a geometric series (+ alpha^(steps)*state_0)\n",
    "      \n",
    "      delta[output] <- (mature_state[output] - (alpha_1[output]^mature_age_steps)*state[1, output])/ ( (1- (alpha_1[output]^mature_age_steps)) / (1 - alpha_1[output]) )\n",
    "      for (t in 2:69) {\n",
    "        state[t, output] <- alpha_1[output]*state[t-1, output] + delta[output]\n",
    "      }\n",
    "  }\n",
    "  \n",
    "  \n",
    "  #gp\n",
    "    K <- array(NA,c(N_cols,69,69))\n",
    "    gp_alpha <- array(NA,N_cols)\n",
    "    gp_rho <- array(NA,N_cols)\n",
    "    gp_sigma <- array(NA,N_cols)\n",
    "\n",
    "    for (output in 1:N_cols){\n",
    "        gp_alpha[output] <- rnorm(1,gp_alpha_mean[output],gp_alpha_sd[output])\n",
    "        gp_rho[output] <- rnorm(1,gp_rho_mean[output],gp_rho_sd[output])\n",
    "        gp_sigma[output] <- rnorm(1,gp_sigma_mean[output],gp_sigma_sd[output])\n",
    "        for (i_ind in 1:69){\n",
    "            for (j_ind in 1:69){\n",
    "                K[output,i_ind,j_ind] <- (gp_alpha[output]^2) *exp(-((i_ind-j_ind)^2)/(gp_rho[output]^2)) + exp(-10000*(i_ind-j_ind)^2) * gp_sigma[output]^2\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "  #observations:\n",
    "  #as we have only one point - remove data indexing\n",
    "    y_state <- array(NA,c(69,3))\n",
    "    for (output in 1:3){\n",
    "      for (t in 1:69){\n",
    "          y_state[t,output] <- state[t, output] + beta_1[output]*(-softplus_nimble(disease[t]))\n",
    "      }\n",
    "      y_state[,output] <- rmvnorm(1,y_state[,output],K[output,,])\n",
    "    }\n",
    "\n",
    "  return(y_state)\n",
    "}\n",
    "\n",
    "softplus_nimble <- nimbleFunction(\n",
    "    run = function(x = double(0)){\n",
    "      return(log(1+exp(x)))\n",
    "      returnType(double(0))\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190778fc-2c93-45e1-96dd-c03f4cae644e",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(MASS)\n",
    "\n",
    "#extracting trajectories\n",
    "\n",
    "    set.seed(10)\n",
    "KL_score <- array(NA,100)\n",
    "LC_score <- array(NA,100)\n",
    "for (synth_run in 1:100){    while(TRUE){ df <- try({\n",
    "        N_synth_trajs <- N_valid\n",
    "        N_show <- 50 #number of trajectories shown in the plots\n",
    "\n",
    "        Synth_trajs <- array(NA,c(N_synth_trajs,69,3))\n",
    "        for (synth_traj in 1:N_synth_trajs){\n",
    "            Synth_trajs[synth_traj,,] <- Generate_Trajectory()\n",
    "        }\n",
    "        #de-reparameterise and round results, and only interested in NSAA score\n",
    "        Synth_trajs <- round(NSAA_itransformer(Synth_trajs[,,1] * y_sd[1] + y_mean[1]))\n",
    "\n",
    "        #sample initial points\n",
    "        synth_start_time <- array(NA,N_synth_trajs)\n",
    "        for (i in 1:N_synth_trajs){\n",
    "            synth_start_time[i] <- sample(start_points,1)\n",
    "        }\n",
    "        #sampling rates\n",
    "        synth_rate <- array(NA,N_synth_trajs)\n",
    "        for (i in 1:N_synth_trajs){\n",
    "            synth_rate[i] <- round(sample(rates,1))\n",
    "        }\n",
    "        #if it is already at zero, trajectory doesn't exist, so resample\n",
    "        for (i in 1:N_synth_trajs){\n",
    "            no_zeroes <- FALSE\n",
    "            while (no_zeroes == FALSE){\n",
    "                if (Synth_trajs[i,synth_start_time[i]] == 0 | Synth_trajs[i,synth_start_time[i] + synth_rate[i]] == 0){\n",
    "                    Synth_trajs[i,] <- round(NSAA_itransformer(Generate_Trajectory()[,1] * y_sd[1] + y_mean[1]))\n",
    "                } else {\n",
    "                    no_zeroes <- TRUE\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        Synth_trajs_reshape <- reshape2::melt(Synth_trajs,varnames=c('individual','time'))\n",
    "        Synth_trajs_reshape_limited <- Synth_trajs_reshape[Synth_trajs_reshape[,1] %in% 1:N_show,]\n",
    "        if (synth_run == 1){\n",
    "            synth_plot <- ggplot(Synth_trajs_reshape_limited) +\n",
    "                geom_line(aes(x=(init_age+(1:N_timesteps)*(every_x_months/12))[time],y=value,group=individual,colour=factor(individual))) +\n",
    "                #theme_bw() +\n",
    "                labs(x='Years since birth', y='NSAA score')+\n",
    "                theme(text = element_text(size = 25,colour='#003D3C'),legend.position=\"none\") +\n",
    "                xlim(3.25,20.25) +\n",
    "                ylim(0,35)\n",
    "            synth_plot\n",
    "                ggsave(\"SynthTrajectoriesExampleStep1.pdf\")\n",
    "            }\n",
    "\n",
    "        #now set initial points\n",
    "        for (i in 1:N_synth_trajs){\n",
    "            Synth_trajs_reshape <- Synth_trajs_reshape[!(Synth_trajs_reshape$individual == i & Synth_trajs_reshape$time < synth_start_time[i]),]\n",
    "        }\n",
    "        Synth_trajs_reshape_limited <- Synth_trajs_reshape[Synth_trajs_reshape[,1] %in% 1:N_show,]\n",
    "        if (synth_run == 1){\n",
    "            synth_plot <- ggplot(Synth_trajs_reshape_limited) +\n",
    "                geom_line(aes(x=(init_age+(1:N_timesteps)*(every_x_months/12))[time],y=value,group=individual,colour=factor(individual))) +\n",
    "                #theme_bw() +\n",
    "                labs(x='Years since birth', y='NSAA score')+\n",
    "                theme(text = element_text(size = 25,colour='#003D3C'),legend.position=\"none\") +\n",
    "                xlim(3.25,20.25) +\n",
    "                ylim(0,35)\n",
    "            synth_plot\n",
    "                ggsave(\"SynthTrajectoriesExampleStep2.pdf\")\n",
    "        }\n",
    "\n",
    "        #now do regularities\n",
    "        for (i in 1:N_synth_trajs){\n",
    "            Synth_trajs_reshape <- Synth_trajs_reshape[!(Synth_trajs_reshape$individual == i & Synth_trajs_reshape$time %in% (synth_start_time[i]+synth_rate[i]*(1:69))),]\n",
    "        }\n",
    "        Synth_trajs_reshape_limited <- Synth_trajs_reshape[Synth_trajs_reshape[,1] %in% 1:N_show,]\n",
    "        if (synth_run == 1){\n",
    "            synth_plot <- ggplot(Synth_trajs_reshape_limited) +\n",
    "                geom_line(aes(x=(init_age+(1:N_timesteps)*(every_x_months/12))[time],y=value,group=individual,colour=factor(individual))) +\n",
    "                #theme_bw() +\n",
    "                labs(x='Years since birth', y='NSAA score')+\n",
    "                theme(text = element_text(size = 25,colour='#003D3C'),legend.position=\"none\") +\n",
    "                xlim(3.25,20.25) +\n",
    "                ylim(0,35)\n",
    "            synth_plot\n",
    "                ggsave(\"SynthTrajectoriesExampleStep3.pdf\")\n",
    "            }\n",
    "\n",
    "        #stopping points\n",
    "        last_point <- array(FALSE,dim(Synth_trajs_reshape)[1])\n",
    "            for (i in 1:grid_height){\n",
    "                for (j in 1:grid_width){\n",
    "                    #Find box locations\n",
    "                    age_min <- (j-1)*70/grid_width\n",
    "                    age_max <- j*70/grid_width\n",
    "                    nsaa_min <- (i-1)*35/grid_height\n",
    "                    nsaa_max <- i*35/grid_height\n",
    "                    for (point in 1:dim(Synth_trajs_reshape)[1]){\n",
    "                        if (Synth_trajs_reshape$time[point] <= age_max & Synth_trajs_reshape$time[point] > age_min & Synth_trajs_reshape$value[point] <= nsaa_max & Synth_trajs_reshape$value[point] > nsaa_min){\n",
    "                            last_point[point] <- sample(c(TRUE,FALSE),1,prob=c(stopping_grid[i,j],1-stopping_grid[i,j]))\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        #remove points after these points\n",
    "        remove_points <- c()\n",
    "        for (point in 1:dim(Synth_trajs_reshape)[1]){\n",
    "            if (last_point[point] == TRUE){\n",
    "                for (point2 in 1:dim(Synth_trajs_reshape)[1]){\n",
    "                    if (Synth_trajs_reshape$individual[point2] == Synth_trajs_reshape$individual[point] & Synth_trajs_reshape$time[point2] > Synth_trajs_reshape$time[point]){\n",
    "                        remove_points <- append(remove_points,point2)\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "            if (Synth_trajs_reshape$value[point] == 0){\n",
    "                for (point2 in 1:dim(Synth_trajs_reshape)[1]){\n",
    "                    if (Synth_trajs_reshape$individual[point2] == Synth_trajs_reshape$individual[point] & Synth_trajs_reshape$time[point2] >= Synth_trajs_reshape$time[point]){\n",
    "                        remove_points <- append(remove_points,point2)\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        Synth_trajs_reshape <- Synth_trajs_reshape[! (1:dim(Synth_trajs_reshape)[1] %in% remove_points),]\n",
    "        Synth_trajs_reshape_limited <- Synth_trajs_reshape[Synth_trajs_reshape[,1] %in% 1:N_show,]\n",
    "            if (synth_run == 1){\n",
    "        synth_plot <- ggplot(Synth_trajs_reshape_limited) +\n",
    "            geom_line(aes(x=(init_age+(1:N_timesteps)*(every_x_months/12))[time],y=value,group=individual,colour=factor(individual))) +\n",
    "            #theme_bw() +\n",
    "            labs(x='Years since birth', y='NSAA score')+\n",
    "            theme(text = element_text(size = 25,colour='#003D3C'),legend.position=\"none\") +\n",
    "            xlim(3.25,20.25) +\n",
    "            ylim(0,35)\n",
    "        synth_plot\n",
    "            ggsave(\"SynthTrajectoriesExampleStep4.pdf\")\n",
    "                }\n",
    "\n",
    "        #combine fake and real trajectories\n",
    "        y_data_reshape <- reshape2::melt(unname(y_data[,,1]),varnames=c('id','age'))[!is.na(reshape2::melt(unname(y_data[,,1]),varnames=c('id','age'))$value),]\n",
    "        y_data_reshape$real <- TRUE\n",
    "        y_test_real_reshape <- reshape2::melt(unname(NSAA_itransformer(y_gutted_data[, , 1])),varnames=c('id','age'))[!is.na(reshape2::melt(unname(NSAA_itransformer(y_gutted_data[, , 1])),varnames=c('id','age'))$value),]\n",
    "        y_test_real_reshape$real <- TRUE\n",
    "        Synth_trajs_reshape$real <- FALSE\n",
    "        names(Synth_trajs_reshape) = c('id','age','value','real')\n",
    "        Synth_trajs_reshape$id <- Synth_trajs_reshape$id + max(y_test_real_reshape$id,y_data_reshape$id)\n",
    "\n",
    "        Trajs_together <- rbind(y_data_reshape,y_test_real_reshape,Synth_trajs_reshape)\n",
    "\n",
    "        ng = 4\n",
    "\n",
    "        # Run latent class model (takes time)\n",
    "        LatC8 <- lcmm(value ~ age + I(age^2), mixture=~age, maxiter = 1000, idiag = TRUE, subject='id', ng=ng, data=Trajs_together)\n",
    "\n",
    "       pred_ages = seq(1, max(Trajs_together$age,na.rm = TRUE),length=max(Trajs_together$age,na.rm = TRUE))\n",
    "        dn <- data.frame(age=pred_ages)\n",
    "        lcT8 <- predictY(LatC8, newdata = dn, var.time = \"age\", draws = TRUE)\n",
    "        lcT8$age <- dn$age\n",
    "\n",
    "        classes <- LatC8$pprob$class\n",
    "        patNum <- LatC8$pprob$id\n",
    "\n",
    "        tmp <- do.call(rbind, Map(data.frame, A=classes, B=patNum))\n",
    "\n",
    "        lcT <- lcT8\n",
    "        times = lcT$times[,1]\n",
    "        pred = lcT$pred\n",
    "        pred = data.frame(pred)\n",
    "\n",
    "        group.colors <- c(\"Class 1\" = \"red\", \"Class 2\" = \"yellow\", \"Class 3\" =\"blue\", \"Class 4\" = \"darkgreen\")\n",
    "\n",
    "        i = 1\n",
    "        for (x in tmp[[\"B\"]]){\n",
    "            Trajs_together[Trajs_together$id == x, \"labels\"] = tmp[[\"A\"]][i]\n",
    "            i = i +1\n",
    "        }\n",
    "\n",
    "        #need to remove patIDNum to maintain consistency with kmeans output\n",
    "        #Trajs_together = select(Trajs_together, -id)\n",
    "\n",
    "        #and make classes 0-3 rather than 1-4, again for kmeans consistency\n",
    "        Trajs_together[\"labels\"] = Trajs_together[\"labels\"] -1 \n",
    "\n",
    "        data <- Trajs_together[which(!is.na(Trajs_together$labels)),] #remove na classes (why do these exist?)\n",
    "\n",
    "        data$labels <- as.factor(data$labels)\n",
    "        levels(data$labels) <- c(\"Class 4\", \"Class 3\", \"Class 2\", \"Class 1\")\n",
    "\n",
    "\n",
    "        data.real <- data[data[,4] == TRUE,]\n",
    "        data.synth <- data[data[,4] == FALSE,]\n",
    "\n",
    "        #For first run only, we plot synthetic and real data\n",
    "            if (synth_run == 1){\n",
    "        print(\n",
    "        ggplot(data)+\n",
    "            geom_line(aes(x=init_age+age*(every_x_months/12), y= value, group = id, color = labels))+\n",
    "            xlab(\"age\")+\n",
    "            scale_color_manual(values=group.colors)+\n",
    "            theme(legend.position = \"none\",\n",
    "            axis.text=element_text(size=16),\n",
    "            axis.title=element_text(size=16))+\n",
    "            ylab(\"NSAA\")+\n",
    "            xlab(\"Age (Years)\")+\n",
    "            coord_cartesian(ylim=c(0,35)))\n",
    "            #ggtitle('Groupings of both real and synthetic data together'))\n",
    "            #coord_cartesian(xlim=c(0, 69),ylim=c(-3,3))+\n",
    "            #scale_y_continuous(breaks=seq(0,35,5), limits = c(0, 35))\n",
    "        ggsave(\"NSAA_prediction_plots/data_all_clustered.out.png\",width = 16, height = 14, units = \"cm\")\n",
    "\n",
    "        print(\n",
    "        ggplot(data.real)+\n",
    "            geom_line(aes(x=init_age+age*(every_x_months/12), y= value, group = id, color = labels))+\n",
    "            xlab(\"age\")+\n",
    "            scale_color_manual(values=group.colors)+\n",
    "            theme(legend.position = \"none\",\n",
    "            axis.text=element_text(size=16),\n",
    "            axis.title=element_text(size=16))+\n",
    "            ylab(\"NSAA\")+\n",
    "            xlab(\"Age (Years)\")+\n",
    "            coord_cartesian(ylim=c(0,35)))\n",
    "            #ggtitle('Groupings of real data'))\n",
    "            #coord_cartesian(xlim=c(0, 69),ylim=c(-3,3))+\n",
    "            #scale_y_continuous(breaks=seq(0,35,5), limits = c(0, 35))\n",
    "        ggsave(\"NSAA_prediction_plots/data_real_clustered.out.png\",width = 16, height = 14, units = \"cm\")\n",
    "\n",
    "        print(\n",
    "        ggplot(data.synth)+\n",
    "            geom_line(aes(x=init_age+age*(every_x_months/12), y= value, group = id, color = labels))+\n",
    "            xlab(\"age\")+\n",
    "            scale_color_manual(values=group.colors)+\n",
    "            theme(legend.position = \"none\",\n",
    "            axis.text=element_text(size=16),\n",
    "            axis.title=element_text(size=16))+\n",
    "            ylab(\"NSAA\")+\n",
    "            xlab(\"Age (Years)\")+\n",
    "            coord_cartesian(ylim=c(0,35)))\n",
    "            #ggtitle('Groupings of synthetic data')\n",
    "            #coord_cartesian(xlim=c(0, 69),ylim=c(-3,3))+\n",
    "            #scale_y_continuous(breaks=seq(0,35,5), limits = c(0, 35))\n",
    "                ggsave(\"NSAA_prediction_plots/data_synth_clustered.out.png\",width = 16, height = 14, units = \"cm\")\n",
    "    }\n",
    "\n",
    "        classifications <- data.frame(patNum,classes)\n",
    "        classifications.real <- classifications[patNum <= max(n_reshape[out_reshape==1]),]\n",
    "        classifications.synth <- classifications[patNum > max(n_reshape[out_reshape==1]),]\n",
    "\n",
    "        g.real <- array(NA,4)\n",
    "        g.synth <- array(NA,4)\n",
    "        for (group in 1:ng){\n",
    "            g.real[group] <- length(rep(1:dim(classifications.real)[1])[classifications.real$classes==group])\n",
    "            g.synth[group] <- length(rep(1:dim(classifications.synth)[1])[classifications.synth$classes==group])\n",
    "        }\n",
    "\n",
    "        LC_score[synth_run] <- log((1/ng) * sum((g.real/(g.real+g.synth) - sum(g.real)/(sum(g.real)+sum(g.synth)))^2))\n",
    "\n",
    "\n",
    "\n",
    "        esti1 <- kde2d(data.real$age,data.real$value,lims=c(0,69,0,35))\n",
    "        esti1df <- expand.grid(X=esti1$x, Y=esti1$y)\n",
    "        esti1df$Z <- c(esti1$z)\n",
    "\n",
    "        esti2 <- kde2d(data.synth$age,data.synth$value,lims=c(0,69,0,35))\n",
    "        esti2df <- expand.grid(X=esti2$x, Y=esti2$y)\n",
    "        esti2df$Z <- c(esti2$z)\n",
    "\n",
    "\n",
    "        KL_score[synth_run] <- KL(rbind(c(esti1$z)/sum(c(esti1$z)),c(esti2$z)/sum(c(esti2$z))))\n",
    "\n",
    "    })\n",
    "    if(!is(df, 'try-error')) break }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e064439b-1064-4b96-8579-05497eb06f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(LC_score)\n",
    "mean(KL_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
